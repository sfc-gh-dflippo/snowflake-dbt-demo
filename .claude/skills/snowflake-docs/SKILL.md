---
name: snowflake-docs
description: Reference documentation scraped from Snowflake's official documentation
version: 1.1.0
author: Snowflake Inc.
auto_generated: true
last_updated: "2026-01-14"
---

# Snowflake Docs

Reference documentation scraped from Snowflake's official documentation.

## All Documents (1000 total)

- [Untitled](en/_downloads/62b8c258bb35353bbc7914de3d0095d2/end_to_end_lab_source_code.zip.md) - Reference documentation from Snowflake
- [API Reference | Snowflake Documentation](en/api-reference.md) - These topics provide reference information for the APIs available in Snowflake.
- [About listings | Snowflake Documentation](en/collaboration/collaboration-listings-about.md) - With listings, you can provide data and other information to other Snowflake users, and you can access data and other information shared by Snowflake providers.
- [Snowflake data types | Snowflake Documentation](en/data-types.md) - Snowflake supports most basic SQL data types (with some restrictions) for use in columns, local variables, expressions, parameters, and any other appropriate locations.
- [Logging messages in Snowflake Scripting | Snowflake Documentation](en/developer-guide/logging-tracing/logging-snowflake-scripting.md) - You can log messages from a stored procedure handler written in Snowflake Scripting by using the Snowflake SYSTEM$LOG, SYSTEM$LOG_<level> (for Snowflake Scripting) function. When you’ve set up an even
- [Logging, tracing, and metrics | Snowflake Documentation](en/developer-guide/logging-tracing/logging-tracing-overview.md) - You can record the activity of your Snowflake function and procedure handler code (including code you write using Snowpark APIs) by capturing log messages and trace events from the code as it executes
- [Logging messages from functions and procedures | Snowflake Documentation](en/developer-guide/logging-tracing/logging.md) - You can log messages (such as warning or error messages) from a stored procedure, UDF, or UDTF, including those you write using Snowpark APIs. You can access the logged messages from an event table (a
- [Integrating CI/CD with Snowflake CLI | Snowflake Documentation](en/developer-guide/snowflake-cli/cicd/integrate-ci-cd.md) - Snowflake CLI integrates popular CI/CD (continuous integration and continuous delivery) systems and frameworks, such as GitHub Actions, to efficiently automate your Snowflake workflows for SQL, Snowpa
- [Snowflake CLI | Snowflake Documentation](en/developer-guide/snowflake-cli/index.md) - Snowflake CLI is an open-source command-line tool explicitly designed for developer-centric workloads in addition to SQL operations. It is a flexible and extensible tool that can accommodate modern de
- [Working with cursors | Snowflake Documentation](en/developer-guide/snowflake-scripting/cursors.html.md) - You can use a cursor to iterate through query results one row at a time.
- [Determining the number of rows affected by DML commands | Snowflake Documentation](en/developer-guide/snowflake-scripting/dml-status.md) - After a DML command is executed (excluding the TRUNCATE TABLE command), Snowflake Scripting sets the following global variables. You can use these variables to determine if the last DML statement affe
- [Handling exceptions | Snowflake Documentation](en/developer-guide/snowflake-scripting/exceptions.md) - In a Snowflake Scripting block, you can raise an exception if an error occurs. You can also handle exceptions that occur in your Snowflake Scripting code.
- [Snowflake Scripting Developer Guide | Snowflake Documentation](en/developer-guide/snowflake-scripting/index.md) - Snowflake Scripting is an extension to Snowflake SQL that adds support for procedural logic. You can use Snowflake Scripting syntax in stored procedures and user-defined functions (UDFs). You can also
- [Working with RESULTSETs | Snowflake Documentation](en/developer-guide/snowflake-scripting/resultsets.html.md) - This topic explains how to use a RESULTSET in Snowflake Scripting.
- [Using Snowflake Scripting in Snowflake CLI, SnowSQL, and Python Connector | Snowflake Documentation](en/developer-guide/snowflake-scripting/running-examples.md) - This topic explains how to run the Snowflake Scripting examples in Snowflake CLI, SnowSQL, and the Python Connector.
- [Working with variables | Snowflake Documentation](en/developer-guide/snowflake-scripting/variables.md) - In Snowflake Scripting, you can use variables in expressions, Snowflake Scripting statements, and SQL statements.
- [Development clients for Snowpark Connect for Spark | Snowflake Documentation](en/developer-guide/snowpark-connect/snowpark-connect-clients.md) - You can run Spark workloads interactively from clients such as Snowflake Notebooks, Jupyter Notebooks, VS Code, or any Python-based interface without needing to manage a Spark cluster. The workloads r
- [Snowpark Connect for Spark compatibility guide | Snowflake Documentation](en/developer-guide/snowpark-connect/snowpark-connect-compatibility.md) - This guide documents the compatibility between the Snowpark Connect for Spark implementation of the Spark DataFrame APIs and native Apache Spark. It is intended to help users understand the key differ
- [Access to cloud service file data with Snowpark Connect for Spark | Snowflake Documentation](en/developer-guide/snowpark-connect/snowpark-connect-file-data.md) - With Snowpark Connect for Spark, you can interact directly with external cloud storage systems such as Amazon S3, Google Cloud Storage, and Azure Blob. You can read data from cloud storage into Snowfl
- [Run Apache Spark™ workloads on Snowflake with Snowpark Connect for Spark | Snowflake Documentation](en/developer-guide/snowpark-connect/snowpark-connect-overview.md) - With Snowpark Connect for Apache Spark™, you can connect your existing Spark workloads directly to Snowflake and run them on the Snowflake compute engine. Snowpark Connect for Spark supports using the
- [Executing Snowflake SQL with Snowpark Connect for Spark | Snowflake Documentation](en/developer-guide/snowpark-connect/snowpark-connect-snowflake-sql.md) - To execute SQL commands specific to Snowflake, you can use the SnowflakeSession interface. As with the spark.sql method, query results are returned as Spark DataFrames with which you can continue appl
- [Run Spark workloads from VS Code, Jupyter Notebooks, or a terminal | Snowflake Documentation](en/developer-guide/snowpark-connect/snowpark-connect-workloads-jupyter.md) - You can run Spark workloads interactively from Jupyter Notebooks, VS Code, or any Python-based interface without needing to manage a Spark cluster. The workloads run on the Snowflake infrastructure.
- [Run Spark batch workloads from Snowpark Submit | Snowflake Documentation](en/developer-guide/snowpark-connect/snowpark-submit.md) - You can run Spark workloads in a non-interactive, asynchronous way directly on Snowflake’s infrastructure while you use familiar Spark semantics. With Snowpark Submit, you can submit production-ready 
- [Snowpark Container Services costs | Snowflake Documentation](en/developer-guide/snowpark-container-services/accounts-orgs-usage-views.md) - Feature — Generally Available
- [Snowpark Container Services | Snowflake Documentation](en/developer-guide/snowpark-container-services/overview.md) - Feature — Generally Available
- [Snowpark API | Snowflake Documentation](en/developer-guide/snowpark/index.md) - The Snowpark API provides an intuitive library for querying and processing data at scale in Snowflake. Using a library for any of three languages, you can build applications that process data in Snowf
- [Snowpark Developer Guide for Java | Snowflake Documentation](en/developer-guide/snowpark/java/index.md) - The Snowpark library provides an intuitive API for querying and processing data in a data pipeline. Using the Snowpark library, you can build applications that process data in Snowflake without moving
- [Creating a Session for Snowpark Python | Snowflake Documentation](en/developer-guide/snowpark/python/creating-session.md) - To use Snowpark in your application, you need to create a session. For convenience in writing code, you can also import the names of packages and objects.
- [Snowpark Developer Guide for Python | Snowflake Documentation](en/developer-guide/snowpark/python/index.md) - The Snowpark library provides an intuitive API for querying and processing data in a data pipeline. Using the Snowpark library, you can build applications that process data in Snowflake without moving
- [Snowpark Checkpoints | Snowflake Documentation](en/developer-guide/snowpark/python/snowpark-checkpoints-library.md) - Preview Feature — Open
- [snowflake.snowpark.DataFrameReader | Snowflake Documentation](en/developer-guide/snowpark/reference/python/1.23.0/snowpark/api/snowflake.snowpark.DataFrameReader.md) - Bases: object
- [snowflake.snowpark.DataFrameReader.schema | Snowflake Documentation](en/developer-guide/snowpark/reference/python/1.23.0/snowpark/api/snowflake.snowpark.DataFrameReader.schema.md) - Define the schema for CSV files that you want to read.
- [snowflake.snowpark.DataFrameWriter.copy_into_location | Snowflake Documentation](en/developer-guide/snowpark/reference/python/1.23.0/snowpark/api/snowflake.snowpark.DataFrameWriter.copy_into_location.md) - Executes a COPY INTO <location> to unload data from a DataFrame into one or more files in a stage or external stage.
- [snowflake.snowpark.DataFrameWriter.csv | Snowflake Documentation](en/developer-guide/snowpark/reference/python/1.23.0/snowpark/api/snowflake.snowpark.DataFrameWriter.csv.md) - Executes internally a COPY INTO <location> to unload data from a DataFrame into one or more CSV files in a stage or external stage.
- [snowflake.snowpark.Session | Snowflake Documentation](en/developer-guide/snowpark/reference/python/1.23.0/snowpark/api/snowflake.snowpark.Session.md) - Bases: object
- [snowflake.snowpark.functions.call_function | Snowflake Documentation](en/developer-guide/snowpark/reference/python/1.3.0/api/snowflake.snowpark.functions.call_function.md) - Invokes a Snowflake system-defined function (built-in function) with the specified name and arguments.
- [snowflake.snowpark.DataFrame.approxQuantile | Snowflake Documentation](en/developer-guide/snowpark/reference/python/latest/snowpark/api/snowflake.snowpark.DataFrame.approxQuantile.md) - For a specified numeric column and a list of desired quantiles, returns an approximate value for the column at each of the desired quantiles. This function uses the t-Digest algorithm.
- [snowflake.snowpark.DataFrameReader.option | Snowflake Documentation](en/developer-guide/snowpark/reference/python/latest/snowpark/api/snowflake.snowpark.DataFrameReader.option.md) - Sets the specified option in the DataFrameReader.
- [snowflake.snowpark.DataFrameReader.options | Snowflake Documentation](en/developer-guide/snowpark/reference/python/latest/snowpark/api/snowflake.snowpark.DataFrameReader.options.md) - Sets multiple specified options in the DataFrameReader.
- [snowflake.snowpark.DataFrameWriter.copy_into_location | Snowflake Documentation](en/developer-guide/snowpark/reference/python/latest/snowpark/api/snowflake.snowpark.DataFrameWriter.copy_into_location.md) - Executes a COPY INTO <location> to unload data from a DataFrame into one or more files in a stage or external stage.
- [snowflake.snowpark.DataFrameWriter.csv | Snowflake Documentation](en/developer-guide/snowpark/reference/python/latest/snowpark/api/snowflake.snowpark.DataFrameWriter.csv.md) - Executes internally a COPY INTO <location> to unload data from a DataFrame into one or more CSV files in a stage or external stage.
- [snowflake.snowpark.DataFrameWriter.mode | Snowflake Documentation](en/developer-guide/snowpark/reference/python/latest/snowpark/api/snowflake.snowpark.DataFrameWriter.mode.md) - Set the save mode of this DataFrameWriter.
- [snowflake.snowpark.functions.call_builtin | Snowflake Documentation](en/developer-guide/snowpark/reference/python/latest/snowpark/api/snowflake.snowpark.functions.call_builtin.md) - Invokes a Snowflake system-defined function (built-in function) with the specified name and arguments.
- [snowflake.snowpark.functions.call_function | Snowflake Documentation](en/developer-guide/snowpark/reference/python/latest/snowpark/api/snowflake.snowpark.functions.call_function.md) - Invokes a Snowflake system-defined function (built-in function) with the specified name and arguments.
- [snowflake.snowpark.functions.charindex | Snowflake Documentation](en/developer-guide/snowpark/reference/python/latest/snowpark/api/snowflake.snowpark.functions.charindex.md) - Searches for target_expr in source_expr and, if successful, returns the position (1-based) of the target_expr in source_expr.
- [snowflake.snowpark.functions.date_add | Snowflake Documentation](en/developer-guide/snowpark/reference/python/latest/snowpark/api/snowflake.snowpark.functions.date_add.md) - Adds a number of days to a date column.
- [snowflake.snowpark.functions.date_sub | Snowflake Documentation](en/developer-guide/snowpark/reference/python/latest/snowpark/api/snowflake.snowpark.functions.date_sub.md) - Subtracts a number of days from a date column.
- [snowflake.snowpark.functions.daydiff | Snowflake Documentation](en/developer-guide/snowpark/reference/python/latest/snowpark/api/snowflake.snowpark.functions.daydiff.md) - Calculates the difference between two dates, or timestamp columns based in days. The result will reflect the difference between col1 - col2
- [snowflake.snowpark.functions.udf | Snowflake Documentation](en/developer-guide/snowpark/reference/python/latest/snowpark/api/snowflake.snowpark.functions.udf.md) - Registers a Python function as a Snowflake Python UDF and returns the UDF.
- [Snowpark Developer Guide for Scala | Snowflake Documentation](en/developer-guide/snowpark/scala/index.md) - The Snowpark library provides an intuitive API for querying and processing data in a data pipeline. Using the Snowpark library, you can build applications that process data in Snowflake without moving
- [Writing stored procedures in JavaScript | Snowflake Documentation](en/developer-guide/stored-procedure/stored-procedures-javascript.md) - This topic explains how to write the JavaScript code for a stored procedure.
- [Selecting from a stored procedure | Snowflake Documentation](en/developer-guide/stored-procedure/stored-procedures-selecting-from.md) - Some stored procedures return tabular data. To select and manipulate this tabular data, you can call these stored procedures in the FROM clause of a SELECT statement.
- [Introduction to JavaScript UDFs | Snowflake Documentation](en/developer-guide/udf/javascript/udf-javascript-introduction.md) - You can write the handler for a user-defined function (UDF) in JavaScript. Topics in this section describe how to design and write a JavaScript handler.
- [Scalar JavaScript UDFs | Snowflake Documentation](en/developer-guide/udf/javascript/udf-javascript-scalar-functions.md) - This topic covers Scalar JavaScript UDFs (user-defined function).
- [Using third-party packages | Snowflake Documentation](en/developer-guide/udf/python/udf-python-packages.html.md) - Stages can be used to import third-party packages. You can also specify Anaconda packages to install when you create Python UDFs.
- [Snowflake Scripting UDFs | Snowflake Documentation](en/developer-guide/udf/sql/udf-sql-procedural-functions.md) - Snowflake supports SQL user-defined functions (UDFs) that contain Snowflake Scripting procedural language. These UDFs are called Snowflake Scripting UDFs.
- [Scalar SQL UDFs | Snowflake Documentation](en/developer-guide/udf/sql/udf-sql-scalar-functions.html.md) - This topic covers concepts and usage details that are specific to SQL UDFs (user-defined functions).
- [User-defined functions overview | Snowflake Documentation](en/developer-guide/udf/udf-overview.md) - You can write user-defined functions (UDFs) to extend the system to perform operations that are not available through the built-in system-defined functions provided by Snowflake. Once you create a UDF
- [Develop Apps and Extensions](en/developer.md) - Write applications that extend Snowflake, act as a client, or act as an integrating component.
- [User Guides](en/guides/README.md) - Instructions on performing various Snowflake operations
- [Snowflake AI and ML | Snowflake Documentation](en/guides/overview-ai-features.md) - Snowflake offers two broad categories of powerful, intelligent features based on Artificial Intelligence (AI) and Machine Learning (ML). These features can help you do more with your data in less time
- [Alerts and Notifications | Snowflake Documentation](en/guides/overview-alerts.md) - You can use Snowflake alerts to send notifications and perform actions automatically. In SQL, you can send a notification to an email address or queue by calling a built-in stored procedure.
- [Applications and tools for connecting to Snowflake | Snowflake Documentation](en/guides/overview-connecting.md) - Snowflake provides several different applications and tools that you can use to access databases in Snowflake.
- [Cost & billing | Snowflake Documentation](en/guides/overview-cost.md) - Snowflake provides a robust framework to manage costs. You can also obtain monthly usage statements and reconcile those statements with usage data in views.
- [Databases, Tables and Views - Overview | Snowflake Documentation](en/guides/overview-db.md) - All data in Snowflake is maintained in databases. Each database consists of one or more schemas, which are logical groupings of database objects, such as tables and views. Snowflake does not place any
- [Data Governance in Snowflake | Snowflake Documentation](en/guides/overview-govern.md) - Snowflake provides industry-leading features that ensure the highest levels of governance for your account and users, as well as all the data you store and access in Snowflake.
- [Load data into Snowflake | Snowflake Documentation](en/guides/overview-loading-data.md) - Data can be loaded into Snowflake in a number of ways. The following topics provide an overview of data loading concepts, tasks, tools, and techniques to quick and easily load data into your Snowflake
- [Working with organizations and accounts | Snowflake Documentation](en/guides/overview-manage.md) - The following topics describe how to manage Snowflake organizations and accounts.
- [Optimizing performance in Snowflake | Snowflake Documentation](en/guides/overview-performance.md) - The following topics help guide efforts to improve the performance of Snowflake.
- [Privacy in Snowflake | Snowflake Documentation](en/guides/overview-privacy.md) - Snowflake provides industry-leading features that maintain the privacy of individuals and sensitive data.
- [Query Data in Snowflake | Snowflake Documentation](en/guides/overview-queries.md) - Snowflake supports standard SQL, including a subset of ANSI SQL:1999 and the SQL:2003 analytic extensions. Snowflake also supports common variations for a number of commands where those variations do 
- [Securing Snowflake | Snowflake Documentation](en/guides/overview-secure.md) - Snowflake provides industry-leading features that help ensure you can configure the highest levels of security for your account and users, as well as all the data you store in Snowflake.
- [Data sharing and collaboration in Snowflake | Snowflake Documentation](en/guides/overview-sharing.md) - There are many ways to share data from your Snowflake account with users in other Snowflake accounts, including collaborating with other parties in a secure environment.
- [Unload Data from Snowflake | Snowflake Documentation](en/guides/overview-unloading-data.md) - Snowflake supports bulk unloading of data from a database table into flat, delimited text files. The following topics detail the processes and procedures associated with unloading data.
- [Snowflake Migration Tools | Snowflake Documentation](en/migrations/README.md) - Snowflake offers two powerful migration tools to help organizations modernize their data platforms:
- [Azure Synapse to Snowflake Migration Guide | Snowflake Documentation](en/migrations/guides/azuresynapse.md) - A typical Azure Synapse-to-Snowflake migration can be broken down into nine key phases. This guide provides a comprehensive framework to navigate the technical and strategic challenges involved, ensur
- [Databricks to Snowflake Migration Guide | Snowflake Documentation](en/migrations/guides/databricks.md)
- [Oracle to Snowflake Migration Guide | Snowflake Documentation](en/migrations/guides/oracle.md) - A typical Oracle-to-Snowflake migration can be broken down into nine key phases. This guide provides a comprehensive framework to navigate the technical and strategic challenges involved, ensuring a s
- [Amazon Redshift to Snowflake Migration Guide | Snowflake Documentation](en/migrations/guides/redshift.md) - A typical Amazon Redshift-to-Snowflake migration can be broken down into nine key phases. This guide provides a comprehensive framework to navigate the technical and strategic challenges involved, ens
- [SQL Server to Snowflake Migration Guide | Snowflake Documentation](en/migrations/guides/sqlserver.md)
- [Teradata to Snowflake Migration Guide | Snowflake Documentation](en/migrations/guides/teradata.md)
- [Snowpark Migration Accelerator Documentation | Snowflake Documentation](en/migrations/sma-docs/README.md) - Traditional data platforms and big data solutions often fail to achieve their main goal: allowing users to work with data without restrictions on size, speed, or adaptability. Snowflake’s Data Cloud o
- [Snowpark Migration Accelerator:  Conversion Software Terms of Use | Snowflake Documentation](en/migrations/sma-docs/general/conversion-software-terms-of-use/README.md) - For the most current and authoritative version of the Conversion Software Terms of Use, please visit the official Snowflake legal site:
- [Snowpark Migration Accelerator:  Open Source Libraries | Snowflake Documentation](en/migrations/sma-docs/general/conversion-software-terms-of-use/open-source-libraries.md) - The open-source libraries used in the Snowpark Migration Accelerator Include:\
- [Snowpark Migration Accelerator: Getting Started | Snowflake Documentation](en/migrations/sma-docs/general/getting-started/README.md) - Getting started with a migration project can be challenging. The Snowpark Migration Accelerator (SMA) simplifies this process by automatically analyzing your code and converting it to Snowpark, making
- [Snowpark Migration Accelerator: Downloading and Getting Access | Snowflake Documentation](en/migrations/sma-docs/general/getting-started/download-and-access.html.md) - The Snowpark Migration Accelerator (SMA) is a desktop application that helps you to convert your existing code to Snowflake’s Snowpark framework. The application runs on macOS and Windows operating sy
- [Snowpark Migration Accelerator: Downloading and Getting Access | Snowflake Documentation](en/migrations/sma-docs/general/getting-started/download-and-access.md) - The Snowpark Migration Accelerator (SMA) is a desktop application that helps you to convert your existing code to Snowflake’s Snowpark framework. The application runs on macOS and Windows operating sy
- [Snowpark Migration Accelerator:  Installation | Snowflake Documentation](en/migrations/sma-docs/general/getting-started/installation/README.md) - When you download the Snowpark Migration Accelerator (SMA), you’ll receive an installer package. The installation process varies depending on your operating system, as SMA runs locally on your machine
- [Snowpark Migration Accelerator:  Linux Installation | Snowflake Documentation](en/migrations/sma-docs/general/getting-started/installation/linux-installation.md) - The Snowpark Migration Accelerator (SMA) offers two installation options:
- [Snowpark Migration Accelerator:  MacOS Installation | Snowflake Documentation](en/migrations/sma-docs/general/getting-started/installation/macos-installation.md) - You can install the Snowpark Migration Accelerator (SMA) on macOS in two ways:
- [Snowpark Migration Accelerator: Windows Installation | Snowflake Documentation](en/migrations/sma-docs/general/getting-started/installation/windows-installation.md) - You can install the Snowpark Migration Accelerator (SMA) on Windows in two ways:
- [Snowpark Migration Accelerator: Introduction | Snowflake Documentation](en/migrations/sma-docs/general/introduction.md) - The Snowpark Migration Accelerator (SMA), formerly SnowConvert for Spark, helps developers convert code from various platforms to Snowflake. It uses a proven migration framework with 30 years of devel
- [Snowpark Migration Accelerator: Release Notes | Snowflake Documentation](en/migrations/sma-docs/general/release-notes/README.md) - Note that the release notes below are organized by release date. Version numbers for both the application and the conversion core will appear below.
- [Snowpark Migration Accelerator: Old Version Release Notes | Snowflake Documentation](en/migrations/sma-docs/general/release-notes/old-version-release-notes/README.md) - The Snowpark Migration Accelerator (SMA) has published release notes, but before the SMA existed, SnowConvert for Spark existed. You can find release notes and version information for old versions of 
- [Snowpark Migration Accelerator:  SC Spark Python Release Notes | Snowflake Documentation](en/migrations/sma-docs/general/release-notes/old-version-release-notes/sc-spark-python-release-notes/README.md) - 2023-10-24 Added Add condensed ID for filenames and use it in the log.
- [Snowpark Migration Accelerator:  Known Issues | Snowflake Documentation](en/migrations/sma-docs/general/release-notes/old-version-release-notes/sc-spark-python-release-notes/known-issues.md) - No known issues
- [Snowpark Migration Accelerator:  SC Spark Scala Release Notes | Snowflake Documentation](en/migrations/sma-docs/general/release-notes/old-version-release-notes/sc-spark-scala-release-notes/README.md) - 2023-10-24 Added Add condensed ID for filenames and use it in the log.
- [Snowpark Migration Accelerator:  Known Issues | Snowflake Documentation](en/migrations/sma-docs/general/release-notes/old-version-release-notes/sc-spark-scala-release-notes/known-issues.md) - There are some scenarios that are not properly supported in order to resolve symbols for assessment reports and mappings.
- [Snowpark Migration Accelerator: Roadmap | Snowflake Documentation](en/migrations/sma-docs/general/roadmap.md) - The SMA team continuously enhances and updates the tool. You can track these improvements in the Release Notes.
- [Snowpark Migration Accelerator: Interactive Assessment Application Installation Guide | Snowflake Documentation](en/migrations/sma-docs/interactive-assessment-application/installation-guide.md) - This section guides you through deploying the Interactive Assessment Application (IAA) in your Snowflake account. The IAA is a Streamlit app that leverages the power of Snowflake within Snowflake to a
- [Snowpark Migration Accelerator: Interactive Assessment Application Overview | Snowflake Documentation](en/migrations/sma-docs/interactive-assessment-application/overview.md) - The Interactive Assessment Application (IAA) is a Streamlit in Snowflake (SiS) app designed to provide users with insights into the SMA output. These insights guide initial migration steps, highlighti
- [Snowpark Migration Accelerator:  Approach | Snowflake Documentation](en/migrations/sma-docs/issue-analysis/approach.md) - The Snowpark Migration Accelerator (SMA) helps you migrate code by identifying and reporting potential issues during the conversion process. It serves two main purposes: accelerating code migration an
- [Snowpark Migration Accelerator:  Deploying the Output Code | Snowflake Documentation](en/migrations/sma-docs/issue-analysis/deploying-the-output-code.md) - To run the output code generated by the Snowpark Migration Accelerator (SMA), follow these environment-specific recommendations based on your source platform.
- [Snowpark Migration Accelerator: Issue Code Categorization | Snowflake Documentation](en/migrations/sma-docs/issue-analysis/issue-code-categorization.html.md) - The Snowpark Migration Accelerator (SMA) analyzes your codebase and generates issue codes. While these codes provide detailed information, they fall into three main categories.
- [Snowpark Migration Accelerator: Issue Code Categorization | Snowflake Documentation](en/migrations/sma-docs/issue-analysis/issue-code-categorization.md) - The Snowpark Migration Accelerator (SMA) analyzes your codebase and generates issue codes. While these codes provide detailed information, they fall into three main categories.
- [Snowpark Migration Accelerator:  Issue Codes by Source | Snowflake Documentation](en/migrations/sma-docs/issue-analysis/issue-codes-by-source/README.md) - During your work with the Snowpark Migration Accelerator (SMA), you’ll frequently encounter the term “issue.” Issues are diagnostic codes that appear in both reports and converted code. These codes se
- [Snowpark Migration Accelerator:  General | Snowflake Documentation](en/migrations/sma-docs/issue-analysis/issue-codes-by-source/general.md) - Issue codes can be either platform-specific or generic. Generic issue codes, which apply to multiple source platforms, are listed below.
- [Snowpark Migration Accelerator:  Pandas | Snowflake Documentation](en/migrations/sma-docs/issue-analysis/issue-codes-by-source/pandas/README.md) - All the warnings, parsing errors and conversion errors generated by the SMA when processing Pandas elements will appear below. If you have any concerns or see something that’s not right, please reach 
- [Snowpark Migration Accelerator: Issue Codes for Python | Snowflake Documentation](en/migrations/sma-docs/issue-analysis/issue-codes-by-source/python/README.md) - Message: Source project spark-core version is xx.xx:xx.x.x, the spark-core version supported by snowpark is 2.12:3.1.2 so there may be functional differences between the existing mappings.
- [Snowpark Migration Accelerator: Snowpark Connect Issue Codes for Python | Snowflake Documentation](en/migrations/sma-docs/issue-analysis/issue-codes-by-source/python/snowpark-connect-codes-python.md) - Message The element < element > is not supported for Snowpark Connect
- [Snowpark Migration Accelerator: Issue Codes for Spark - Scala | Snowflake Documentation](en/migrations/sma-docs/issue-analysis/issue-codes-by-source/spark-scala/README.md) - Message: org.apache.spark.sql.functions.covar_pop has a workaround, see documentation for more info
- [Snowpark Migration Accelerator: Snowpark Connect Issue Codes for Scala | Snowflake Documentation](en/migrations/sma-docs/issue-analysis/issue-codes-by-source/spark-scala/snowpark-connect-codes-scala.md) - Message The element < element > is not supported for Snowpark Connect.
- [Snowpark Migration Accelerator:  SQL | Snowflake Documentation](en/migrations/sma-docs/issue-analysis/issue-codes-by-source/sql/README.md) - The Snowpark Migration Accelerator (SMA) is primarily designed to analyze and convert code in scripts and notebooks. That can be from a variety of scripting languages, but also includes SQL. As the SM
- [Snowpark Migration Accelerator:  Hive | Snowflake Documentation](en/migrations/sma-docs/issue-analysis/issue-codes-by-source/sql/hive/README.md) - All of the warnings, parsing errors, and conversion exceptions generated by the SMA when Hive is selected as the Database language to migrate SQL statements will appear below. If you have any concerns
- [Snowpark Migration Accelerator:  SparkSQL | Snowflake Documentation](en/migrations/sma-docs/issue-analysis/issue-codes-by-source/sql/sparksql/README.md) - All of the warnings, parsing errors, and conversion exceptions generated by the SMA when SparkSQL is selected as the Database language to migrate SQL statements will appear below. If you have any conc
- [Snowpark Migration Accelerator: Troubleshooting the Output Code | Snowflake Documentation](en/migrations/sma-docs/issue-analysis/troubleshooting-the-output-code/README.md) - Resolving Common Issues with Code Generated by the Snowpark Migration Accelerator (SMA)
- [Snowpark Migration Accelerator:  Locating Issues | Snowflake Documentation](en/migrations/sma-docs/issue-analysis/troubleshooting-the-output-code/locating-issues.md) - The Snowpark Migration Accelerator (SMA) converts code where possible and identifies sections it cannot convert. When SMA encounters code it cannot convert, it generates an issue with a specific issue
- [Snowpark Migration Accelerator:  Workarounds | Snowflake Documentation](en/migrations/sma-docs/issue-analysis/workarounds.md) - Some code elements and functions cannot be automatically converted at this time. We call these “Workarounds.” While we provide suggested solutions for each workaround, they will require either manual 
- [Snowpark Migration Accelerator:  Contact Us | Snowflake Documentation](en/migrations/sma-docs/support/contact-us.md) - The Snowpark Migration Accelerator (previously known as SnowConvert for Spark) is now integrated into Snowflake’s product suite.
- [Snowpark Migration Accelerator:  Frequently Asked Questions (FAQ) | Snowflake Documentation](en/migrations/sma-docs/support/frequently-asked-questions-faq/README.md) - Looking for help with Snowpark Migration Accelerator for Python? Here are the most common questions and answers about SMA for PySpark to help you get started.
- [Snowpark Migration Accelerator:  DBC files explode | Snowflake Documentation](en/migrations/sma-docs/support/frequently-asked-questions-faq/dbc-files-explode.md) - Before migrating Databricks workloads, you need to complete two steps:
- [Snowpark Migration Accelerator: How to request an access code | Snowflake Documentation](en/migrations/sma-docs/support/frequently-asked-questions-faq/how-to-request-an-access-code.md) - The Snowpark Migration Accelerator (SMA) is a specialized tool created and maintained by Snowflake. While it is not included in the standard Snowflake Service, users can access the assessment feature 
- [Snowpark Migration Accelerator: Sharing the Output with Snowflake | Snowflake Documentation](en/migrations/sma-docs/support/frequently-asked-questions-faq/sharing-the-output-with-snowflake.md) - The Snowpark Migration Accelerator (SMA) is a standalone tool created by Snowflake. While it operates independently from the main Snowflake Service, it gathers basic usage statistics about how the too
- [Snowpark Migration Accelerator:  Using SMA with Jupyter Notebooks | Snowflake Documentation](en/migrations/sma-docs/support/frequently-asked-questions-faq/using-sma-with-jupyter-notebooks.md) - Yes! Place your notebook files (.ipynb) in the source directory you select as input for the tool. The notebooks can be located in any subfolder within that directory. You can include both Python files
- [Snowpark Migration Accelerator:  General Troubleshooting | Snowflake Documentation](en/migrations/sma-docs/support/general-troubleshooting/README.md) - Having trouble with SMA? This section will help you troubleshoot common issues and find solutions.
- [Snowpark Migration Accelerator: How do I make sure that .config is a folder instead of a file? | Snowflake Documentation](en/migrations/sma-docs/support/general-troubleshooting/how-do-I-make-sure-that-config-is-folder.md) - This problem only affects macOS systems.
- [Snowpark Migration Accelerator:  How do I give SMA permission to Documents, Desktop, and Downloads folders? | Snowflake Documentation](en/migrations/sma-docs/support/general-troubleshooting/how-do-i-give-sma-permission-to-documents-desktop-and-downloads-folders.md) - A known issue exists on macOS where SMA crashes if the project directory lacks proper read and write permissions.
- [Snowpark Migration Accelerator: How do I give SMA permission to the config folder? | Snowflake Documentation](en/migrations/sma-docs/support/general-troubleshooting/how-do-i-give-sma-permission-to-the-config-folder.md) - SMA requires specific folder permissions to function correctly. It needs read, write, and execute access to:
- [Snowpark Migration Accelerator:  Invalid Access Code error on VDI | Snowflake Documentation](en/migrations/sma-docs/support/general-troubleshooting/invalid-access-code-error-on-vdi.md) - If you receive an “invalid access code” error when trying to use SMA after restarting your Virtual Desktop Infrastructure (VDI) or reconnecting to it, even though you previously activated an access co
- [Snowpark Migration Accelerator:  Glossary | Snowflake Documentation](en/migrations/sma-docs/support/glossary.html.md) - The Snowpark Migration Accelerator (SMA) uses some technical terms that might be unfamiliar. Please refer to our glossary page to learn more about these terms.
- [Snowpark Migration Accelerator:  Glossary | Snowflake Documentation](en/migrations/sma-docs/support/glossary.md) - The Snowpark Migration Accelerator (SMA) uses some technical terms that might be unfamiliar. Please refer to our glossary page to learn more about these terms.
- [Snowpark Migration Accelerator:  HiveSQL | Snowflake Documentation](en/migrations/sma-docs/translation-reference/hivesql/README.md) - Function
- [Snowpark Migration Accelerator:  SIT Tagging | Snowflake Documentation](en/migrations/sma-docs/translation-reference/sit-tagging/README.md) - During Internal Consumption Tracking, SMA adds JSON-formatted comments to identify each processed element. These comments contain tracking information.
- [Snowpark Migration Accelerator:  SQL statements | Snowflake Documentation](en/migrations/sma-docs/translation-reference/sit-tagging/sql-statements.md) - SQL statements are tagged to monitor usage and consumption.
- [Snowpark Migration Accelerator:  Spark SQL | Snowflake Documentation](en/migrations/sma-docs/translation-reference/spark-sql/README.md) - While Snowflake SQL and Spark SQL share many similarities, they have distinct differences that require careful translation. When migrating between these platforms, certain SQL statements and functions
- [Snowpark Migration Accelerator:  Spark SQL Data Types | Snowflake Documentation](en/migrations/sma-docs/translation-reference/spark-sql/spark-sql-data-types.md) - Spark SQL
- [Snowpark Migration Accelerator: Spark SQL DDL | Snowflake Documentation](en/migrations/sma-docs/translation-reference/spark-sql/spark-sql-ddl/README.md) - While DDL (Data Definition Language) may seem straightforward at first glance, each database platform has its own specific parameters and syntax. These platform-specific differences can create signifi
- [Snowpark Migration Accelerator:  Create Table | Snowflake Documentation](en/migrations/sma-docs/translation-reference/spark-sql/spark-sql-ddl/create-table/README.md) - Let’s examine how to create a table. The CREATE TABLE syntax in Spark closely resembles the syntax used in Snowflake.
- [Snowpark Migration Accelerator:  Using | Snowflake Documentation](en/migrations/sma-docs/translation-reference/spark-sql/spark-sql-ddl/create-table/using.md) - The USING command in Spark specifies which file format should be used when creating a table. Common formats include CSV, JSON, and AVRO. For more detailed information about the Create Table USING comm
- [Snowpark Migration Accelerator:  Spark SQL DML | Snowflake Documentation](en/migrations/sma-docs/translation-reference/spark-sql/spark-sql-dml/README.md) - While SELECT statements are common across different SQL databases, the way data manipulation (DML) works can vary significantly between database systems. Each database has its own unique features and 
- [Snowpark Migration Accelerator:  Merge | Snowflake Documentation](en/migrations/sma-docs/translation-reference/spark-sql/spark-sql-dml/merge.md) - The MERGE statement combines data from one or more source tables with a target table, allowing you to perform updates and inserts in a single operation. Based on conditions you define, it determines w
- [Snowpark Migration Accelerator: SELECT | Snowflake Documentation](en/migrations/sma-docs/translation-reference/spark-sql/spark-sql-dml/select/README.md) - A SELECT statement offers multiple options to enhance your query results. While some of these options are directly compatible with Snowflake, others may require conversion or modification to work prop
- [Snowpark Migration Accelerator:  Distinct | Snowflake Documentation](en/migrations/sma-docs/translation-reference/spark-sql/spark-sql-dml/select/distinct.md) - Select all unique rows from the referenced tables. (Databricks SQL Language Reference SELECT)
- [Snowpark Migration Accelerator:  Group By | Snowflake Documentation](en/migrations/sma-docs/translation-reference/spark-sql/spark-sql-dml/select/group-by.md) - The GROUP BY clause groups rows based on specified expressions and calculates aggregate functions for each group. Databricks SQL provides advanced grouping options through GROUPING SETS, CUBE, and ROL
- [Snowpark Migration Accelerator:  Join | Snowflake Documentation](en/migrations/sma-docs/translation-reference/spark-sql/spark-sql-dml/select/join.md) - Merges rows from two table references using specified join conditions. For more details, see the Databricks SQL Language Reference JOIN.
- [Snowpark Migration Accelerator:  Union | Snowflake Documentation](en/migrations/sma-docs/translation-reference/spark-sql/spark-sql-dml/select/union.md) - Merges two subqueries into a single query. Databricks SQL provides three set operators that allow you to combine queries:
- [Snowpark Migration Accelerator:  Values | Snowflake Documentation](en/migrations/sma-docs/translation-reference/spark-sql/spark-sql-dml/select/values.md) - Creates a temporary table within the query that can be used immediately. For more information, see Databricks SQL Language Reference VALUES.
- [Snowpark Migration Accelerator:  Where | Snowflake Documentation](en/migrations/sma-docs/translation-reference/spark-sql/spark-sql-dml/select/where.md) - Filters the data returned by a query or subquery based on specified conditions. (Databricks SQL Language Reference WHERE)
- [Snowpark Migration Accelerator:  Supported functions | Snowflake Documentation](en/migrations/sma-docs/translation-reference/spark-sql/supported-functions.md) - Function
- [Snowpark Migration Accelerator:  SQL Embedded code | Snowflake Documentation](en/migrations/sma-docs/translation-reference/sql-embedded-code.md) - Note
- [Snowpark Migration Accelerator:  Translation Reference Overview | Snowflake Documentation](en/migrations/sma-docs/translation-reference/translation-reference-overview.md) - The Snowpark Migration Accelerator (SMA) converts source code into Snowflake-compatible formats. This section explains which elements and formats are compatible with Snowflake, helping you understand 
- [Snowpark Migration Accelerator: Assessment Walkthrough | Snowflake Documentation](en/migrations/sma-docs/use-cases/assessment-walkthrough/README.md) - The Snowpark Migration Accelerator (SMA) analyzes Python, Scala, and SQL code in your project to identify what can be converted from Spark API to Snowpark API. This analysis provides detailed insights
- [Snowpark Migration Accelerator:  Interpreting the Assessment Output | Snowflake Documentation](en/migrations/sma-docs/use-cases/assessment-walkthrough/interpreting-the-assessment-output/README.md) - After the tool completes its analysis, you can review the output to make informed decisions. Let’s examine the results to understand how to interpret the data and determine its value for your project.
- [Snowpark Migration Accelerator:  Assessment Output - In Application | Snowflake Documentation](en/migrations/sma-docs/use-cases/assessment-walkthrough/interpreting-the-assessment-output/assessment-output-in-application.md) - When the Snowpark Migration Accelerator (SMA) finishes analyzing your code, it generates assessment artifacts and displays “Analysis completed!” at the top of the page. Click “VIEW RESULTS” to access 
- [Snowpark Migration Accelerator: Assessment Output - Reports Folder | Snowflake Documentation](en/migrations/sma-docs/use-cases/assessment-walkthrough/interpreting-the-assessment-output/assessment-output-reports-folder.md) - A complete set of output files and reports will be generated when you use the Snowpark Migration Accelerator (SMA). To see the full list of generated files and reports, please refer to the Output Repo
- [Snowpark Migration Accelerator:  Running the SMA Again | Snowflake Documentation](en/migrations/sma-docs/use-cases/assessment-walkthrough/running-the-sma-again.md) - To demonstrate the limitations of the tool, let’s analyze a less suitable workload. We’ll run the tool on a codebase that may not be an ideal candidate for migration.
- [Snowpark Migration Accelerator: Running the Tool | Snowflake Documentation](en/migrations/sma-docs/use-cases/assessment-walkthrough/running-the-tool.md) - Now that you have installed the Snowpark Migration Accelerator (SMA) and prepared your codebase, you can begin the execution process. Return to the SMA application if it’s still open, or launch it if 
- [Snowpark Migration Accelerator: Walkthrough Setup | Snowflake Documentation](en/migrations/sma-docs/use-cases/assessment-walkthrough/walkthrough-setup/README.html.md) - This guide offers practical experience with the Snowpark Migration Accelerator (SMA). Through real-world examples, you will learn how to evaluate code and interpret assessment results, giving you a cl
- [Snowpark Migration Accelerator: Walkthrough Setup | Snowflake Documentation](en/migrations/sma-docs/use-cases/assessment-walkthrough/walkthrough-setup/README.md) - This guide offers practical experience with the Snowpark Migration Accelerator (SMA). Through real-world examples, you will learn how to evaluate code and interpret assessment results, giving you a cl
- [Snowpark Migration Accelerator: Notes on Code Preparation | Snowflake Documentation](en/migrations/sma-docs/use-cases/assessment-walkthrough/walkthrough-setup/notes-on-code-preparation.md) - Before running Snowpark Migration Accelerator (SMA), make sure all your source code files are located on the computer where you installed SMA. You don’t need to connect to any source database or Spark
- [Snowpark Migration Accelerator:  Conversion Walkthrough | Snowflake Documentation](en/migrations/sma-docs/use-cases/conversion-walkthrough.md) - The Snowpark Migration Accelerator (SMA) can be run in conversion mode to generate output code that is compatible with Snowflake. This lab will walk you through executing a conversion and help you bet
- [Snowpark Migration Accelerator: Migration Lab | Snowflake Documentation](en/migrations/sma-docs/use-cases/migration-lab/README.md) - [Note that this is also part of the Snowflake End-to-End Migration Quickstart available in the Snowflake quickstarts.]
- [Snowpark Migration Accelerator: Pipeline Lab - Assessment | Snowflake Documentation](en/migrations/sma-docs/use-cases/migration-lab/compatibility-and-assessment.md) - As with SnowConvert, we will run code through the SMA, evaluate the result, resolve any issues, and run it on the new platform. However, unlike SnowConvert, the SMA does NOT connect to any source plat
- [Snowpark Migration Accelerator: Conclusions | Snowflake Documentation](en/migrations/sma-docs/use-cases/migration-lab/conclusions.md) - By utilizing the SMA, we were able to accelerate the migration of both a data pipeline and a reporting notebook. The more of each that you have, the more value a tool like the SMA can provide.
- [Snowpark Migration Accelerator: Notebook Conversion | Snowflake Documentation](en/migrations/sma-docs/use-cases/migration-lab/notebook-conversion.md) - Let’s step over to the Reporting Notebook in our codebase: Basic Reporting Notebook - SqlServer Spark.ipynb. We’re going to walk through a similar set of steps as we did with the pipeline script.
- [Snowpark Migration Accelerator: Pipeline Conversion | Snowflake Documentation](en/migrations/sma-docs/use-cases/migration-lab/pipeline-conversion.html.md) - The SMA has “converted” our scripts, but has it really? What it has actually done is converted all references from the Spark API to the Snowpark API, but what it has not done is to replace the connect
- [Snowpark Migration Accelerator: Pipeline Conversion | Snowflake Documentation](en/migrations/sma-docs/use-cases/migration-lab/pipeline-conversion.md) - The SMA has “converted” our scripts, but has it really? What it has actually done is converted all references from the Spark API to the Snowpark API, but what it has not done is to replace the connect
- [Snowpark Migration Accelerator:  Sample Project | Snowflake Documentation](en/migrations/sma-docs/use-cases/sample-project.md) - A sample project is now available in the Snowpark Migration Accelerator (SMA). You can use this project to learn about SMA’s assessment and conversion features without needing your own code.
- [Snowpark Migration Accelerator: SMA Checkpoints walkthrough | Snowflake Documentation](en/migrations/sma-docs/use-cases/sma-checkpoints-walkthrough/README.md) - The Snowpark Migration Accelerator provides the SMA-Checkpoints feature, this feature goal is to be used within the checkpoints feature of the Snowflake Extension. SMA Checkpoints can be either enable
- [Snowpark Migration Accelerator: Prerequisites | Snowflake Documentation](en/migrations/sma-docs/use-cases/sma-checkpoints-walkthrough/prerequisites.md) - Minimum requirements:
- [Snowpark Migration Accelerator: SMA Execution Guide | Snowflake Documentation](en/migrations/sma-docs/use-cases/sma-checkpoints-walkthrough/sma-execution-guide/README.md) - The SMA-Checkpoints feature requires a PySpark workload as its entry point, since it depends on detecting the use of PySpark DataFrames. This walkthrough will guide you through the feature using a sin
- [Snowpark Migration Accelerator: Feature Settings | Snowflake Documentation](en/migrations/sma-docs/use-cases/sma-checkpoints-walkthrough/sma-execution-guide/feature-settings/README.md) - A new command has been added to the SMA CLI to disable the SMA-Checkpoints feature. Users can do this by using either of the following flags: -d or --disableCheckpoints.
- [Snowpark Migration Accelerator: Default Settings | Snowflake Documentation](en/migrations/sma-docs/use-cases/sma-checkpoints-walkthrough/sma-execution-guide/feature-settings/default-settings.md) - On/Off the whole feature: Enabled.
- [Snowpark Migration Accelerator: SMA-Checkpoints inventories | Snowflake Documentation](en/migrations/sma-docs/use-cases/sma-checkpoints-walkthrough/sma-execution-guide/sma-checkpoints-inventories.md) - The SMA-Checkpoints feature introduces two new inventory files: CheckpointsInventory.csv and DataFramesInventory.csv. These files are generated regardless of whether the feature is enabled.
- [Snowpark Migration Accelerator: Snowpark-Checkpoints Execution Guide | Snowflake Documentation](en/migrations/sma-docs/use-cases/sma-checkpoints-walkthrough/snowpark-checkpoints-execution-guide/README.md) - The SMA generates a file named checkpoints.json, which is placed in both the input and output folders. The file in the input folder is used for data collection, while the one in the output folder is e
- [Snowpark Migration Accelerator: Collection | Snowflake Documentation](en/migrations/sma-docs/use-cases/sma-checkpoints-walkthrough/snowpark-checkpoints-execution-guide/collection.md) - To follow the collection process, please proceed with the steps outlined below:
- [Snowpark Migration Accelerator: Validation | Snowflake Documentation](en/migrations/sma-docs/use-cases/sma-checkpoints-walkthrough/snowpark-checkpoints-execution-guide/validation.md) - To proceed with the validation process, follow the steps outlined below:
- [Snowpark Migration Accelerator: SMA CLI Walkthrough | Snowflake Documentation](en/migrations/sma-docs/use-cases/sma-cli-walkthrough.md) - The Snowpark Migration Accelerator (SMA) helps developers migrate their Python or Scala Spark code to Snowpark. It analyzes your code and:
- [SMA EWI Assistant walkthrough | Snowflake Documentation](en/migrations/sma-docs/use-cases/sma-ewi-assistant-walkthrough/README.md) - To make migrating to Snowpark faster, you can use a custom AI Assistant to resolve errors, warnings, and issues (EWIs). Integrated with the Snowflake VS Code extension, you can use this tool after run
- [Prerequisites | Snowflake Documentation](en/migrations/sma-docs/use-cases/sma-ewi-assistant-walkthrough/prerequisites.md) - To use the SMA AI Assistant, you must first complete the following prerequisites.
- [SMA AI Assistant Usage | Snowflake Documentation](en/migrations/sma-docs/use-cases/sma-ewi-assistant-walkthrough/sma-ai-assistant-usage/README.md) - To ensure correct usage of the SMA AI Assistant, please follow these steps:
- [AI Assistant setup | Snowflake Documentation](en/migrations/sma-docs/use-cases/sma-ewi-assistant-walkthrough/sma-ai-assistant-usage/ai-assistant-setup.md) - Install the Snowflake VS Code extension.
- [Snowpark Migration Accelerator: Snowpark Connect | Snowflake Documentation](en/migrations/sma-docs/use-cases/snowpark-connect/README.md) - Snowpark Connect for Spark allows you to run some Spark workflows in Snowflake with minimal changes.
- [Snowpark Migration Accelerator: Determining Compatibility with Snowpark Connect | Snowflake Documentation](en/migrations/sma-docs/use-cases/snowpark-connect/identifying-fully-compatible-files.md) - With Snowpark Connect for Spark, you can run your Spark code with Snowflake.
- [Snowpark Migration Accelerator:  Using SMA with Docker | Snowflake Documentation](en/migrations/sma-docs/use-cases/using-snowconvert-in-a-ubuntu-docker-image.md) - Using the Linux Command Line Interface (CLI) for Snowpark Migration Accelerator with Docker: A Step-by-Step Guide
- [Snowpark Migration Accelerator: Assessment | Snowflake Documentation](en/migrations/sma-docs/user-guide/assessment/README.md) - The Snowpark Migration Accelerator (SMA) begins with a comprehensive assessment of your environment. Understanding the assessment process is essential to maximize its benefits and ensure successful mi
- [Snowpark Migration Accelerator: Assessment Quick Start | Snowflake Documentation](en/migrations/sma-docs/user-guide/assessment/assessment-quick-start.md) - The Snowpark Migration Accelerator (SMA) helps you analyze your source code by generating detailed reports and inventories. This guide will show you how to begin the assessment process.
- [Snowpark Migration Accelerator: How the Assessment Works | Snowflake Documentation](en/migrations/sma-docs/user-guide/assessment/how-the-assessment-works.md) - The Snowpark Migration Accelerator (SMA) analyzes your source code and creates a detailed inventory of all its components and dependencies.
- [Snowpark Migration Accelerator: Output Logs | Snowflake Documentation](en/migrations/sma-docs/user-guide/assessment/output-logs.md) - The Snowpark Migration Accelerator (SMA) creates detailed log files during its execution. These logs track the tool’s operations and are valuable resources for troubleshooting when issues occur.
- [Snowpark Migration Accelerator:  Output Reports | Snowflake Documentation](en/migrations/sma-docs/user-guide/assessment/output-reports/README.md) - The assessment phase of this accelerator generates multiple detailed reports, including:
- [Snowpark Migration Accelerator:  Assessment zip file | Snowflake Documentation](en/migrations/sma-docs/user-guide/assessment/output-reports/assessment-zip-file.md) - The assessment results are stored in a zip file named “AssessmentFiles.zip” located in the output directory.
- [Snowpark Migration Accelerator: Curated Reports | Snowflake Documentation](en/migrations/sma-docs/user-guide/assessment/output-reports/curated-reports.html.md) - The Snowpark Migration Accelerator (SMA) generates comprehensive assessment reports by analyzing detailed data. The following section lists these available reports.
- [Snowpark Migration Accelerator: Curated Reports | Snowflake Documentation](en/migrations/sma-docs/user-guide/assessment/output-reports/curated-reports.md) - The Snowpark Migration Accelerator (SMA) generates comprehensive assessment reports by analyzing detailed data. The following section lists these available reports.
- [Snowpark Migration Accelerator:  Generic Inventories | Snowflake Documentation](en/migrations/sma-docs/user-guide/assessment/output-reports/generic-inventories.md) - When the Snowpark Migration Accelerator (SMA) analyzes your code, it performs two types of scans:
- [Snowpark Migration Accelerator:  SMA Inventories | Snowflake Documentation](en/migrations/sma-docs/user-guide/assessment/output-reports/sma-inventories.html.md) - The Snowpark Migration Accelerator (SMA) analyzes your codebase and produces detailed data, which is stored in the Reports folder as spreadsheets (inventories). This data is used to create two types o
- [Snowpark Migration Accelerator:  SMA Inventories | Snowflake Documentation](en/migrations/sma-docs/user-guide/assessment/output-reports/sma-inventories.md) - The Snowpark Migration Accelerator (SMA) analyzes your codebase and produces detailed data, which is stored in the Reports folder as spreadsheets (inventories). This data is used to create two types o
- [Snowpark Migration Accelerator: Readiness Scores | Snowflake Documentation](en/migrations/sma-docs/user-guide/assessment/readiness-scores.html.md) - The Snowpark Migration Accelerator (SMA) evaluates your code and produces detailed assessment data. To make this information more accessible, SMA calculates Readiness Scores that measure how easily yo
- [Snowpark Migration Accelerator: Readiness Scores | Snowflake Documentation](en/migrations/sma-docs/user-guide/assessment/readiness-scores.md) - The Snowpark Migration Accelerator (SMA) evaluates your code and produces detailed assessment data. To make this information more accessible, SMA calculates Readiness Scores that measure how easily yo
- [Snowpark Migration Accelerator:  Spark Reference Categories | Snowflake Documentation](en/migrations/sma-docs/user-guide/assessment/spark-reference-categories.md) - SnowConvert for Spark categorizes Spark elements based on how they can be mapped to Snowpark. The following categories describe how each Spark reference is translated, including:
- [Snowpark Migration Accelerator: Understanding the Assessment Summary | Snowflake Documentation](en/migrations/sma-docs/user-guide/assessment/understanding-the-assessment-summary.html.md) - After running an assessment, you can view the initial results and summary in the Assessment Summary Report. To access this report, click the View Results button.
- [Snowpark Migration Accelerator: Understanding the Assessment Summary | Snowflake Documentation](en/migrations/sma-docs/user-guide/assessment/understanding-the-assessment-summary.md) - After running an assessment, you can view the initial results and summary in the Assessment Summary Report. To access this report, click the View Results button.
- [Snowpark Migration Accelerator: Before Using the SMA | Snowflake Documentation](en/migrations/sma-docs/user-guide/before-using-the-sma/README.md) - The Snowpark Migration Accelerator (SMA) helps developers analyze and convert code by providing automated tools and features.
- [Snowpark Migration Accelerator:  Code Extraction | Snowflake Documentation](en/migrations/sma-docs/user-guide/before-using-the-sma/code-extraction.md) - The Snowpark Migration Accelerator (SMA) processes all files within a specified directory. While it creates an inventory of every file, it specifically analyzes files with certain extensions to identi
- [Snowpark Migration Accelerator:  Pre-Processing Considerations | Snowflake Documentation](en/migrations/sma-docs/user-guide/before-using-the-sma/pre-processing-considerations.md) - When preparing source code for analysis with the Snowpark Migration Accelerator (SMA), please note that the tool can only process code located in the input directory. Before running SMA, ensure all re
- [Snowpark Migration Accelerator:  Supported Filetypes | Snowflake Documentation](en/migrations/sma-docs/user-guide/before-using-the-sma/supported-filetypes.md) - The Snowpark Migration Accelerator (SMA) scans files in your selected source directory during project creation. While some files are excluded based on their type, SMA generates a summary report showin
- [Snowpark Migration Accelerator:  Supported Platforms | Snowflake Documentation](en/migrations/sma-docs/user-guide/before-using-the-sma/supported-platforms.md) - The Snowpark Migration Accelerator (SMA) currently supports the following programming languages as source code:
- [Using the SMA AI assistant | Snowflake Documentation](en/migrations/sma-docs/user-guide/chatbot.md) - You can use the SMA AI assistant to analyze and answer questions based exclusively on assessment data and documentation produced during the SMA migration assessment process.
- [Snowpark Migration Accelerator: Conversion | Snowflake Documentation](en/migrations/sma-docs/user-guide/conversion/README.md) - The Snowpark Migration Accelerator (SMA) begins by evaluating your Spark workload through an assessment process. Beyond assessment, SMA can also transform specific components of your Spark application
- [Snowpark Migration Accelerator: Conversion Quick Start | Snowflake Documentation](en/migrations/sma-docs/user-guide/conversion/conversion-quick-start.md) - You can convert your code using one of these two methods:
- [Snowpark Migration Accelerator:  Conversion Setup | Snowflake Documentation](en/migrations/sma-docs/user-guide/conversion/conversion-setup.html.md) - When you first launch the Snowpark Migration Accelerator (SMA), you need to either create a new project or open an existing one. Each project can store multiple SMA executions for both Assessment and 
- [Snowpark Migration Accelerator:  Conversion Setup | Snowflake Documentation](en/migrations/sma-docs/user-guide/conversion/conversion-setup.md) - When you first launch the Snowpark Migration Accelerator (SMA), you need to either create a new project or open an existing one. Each project can store multiple SMA executions for both Assessment and 
- [Snowpark Migration Accelerator:  How the Conversion Works | Snowflake Documentation](en/migrations/sma-docs/user-guide/conversion/how-the-conversion-works.html.md) - The Snowpark Migration Accelerator (SMA) not only generates a comprehensive assessment of your code but can also convert specific elements from your source code into compatible formats for your target
- [Snowpark Migration Accelerator:  How the Conversion Works | Snowflake Documentation](en/migrations/sma-docs/user-guide/conversion/how-the-conversion-works.md) - The Snowpark Migration Accelerator (SMA) not only generates a comprehensive assessment of your code but can also convert specific elements from your source code into compatible formats for your target
- [Snowpark Migration Accelerator:  Output Code | Snowflake Documentation](en/migrations/sma-docs/user-guide/conversion/output-code.md) - The SMA conversion process generates an Output folder containing the converted code. This folder becomes available immediately after the conversion is complete.
- [Snowpark Migration Accelerator: Understanding the Conversion Assessment and Reporting | Snowflake Documentation](en/migrations/sma-docs/user-guide/conversion/understanding-the-conversion-assessment-and-reporting.md) - When you run a conversion using the Snowpark Migration Accelerator (SMA), it generates detailed information similar to what you get in assessment mode. The process is identical in both cases (as expla
- [Snowpark Migration Accelerator: Overview | Snowflake Documentation](en/migrations/sma-docs/user-guide/overview.md) - If you have already downloaded and installed the Snowpark Migration Accelerator (SMA), this section will show you how to use it effectively.
- [Snowpark Migration Accelerator:  Project Overview | Snowflake Documentation](en/migrations/sma-docs/user-guide/project-overview/README.md) - The Snowpark Migration Accelerator (SMA) helps developers analyze and convert existing Spark code to Snowpark code. This tool simplifies the process of understanding your codebase and automatically tr
- [Snowpark Migration Accelerator: Configuration and Settings | Snowflake Documentation](en/migrations/sma-docs/user-guide/project-overview/configuration-and-settings.html.md) - Setting up a new project with the Snowpark Migration Accelerator (SMA) is a simple process. This page explains all available settings, updates, and customization options within the application.
- [Snowpark Migration Accelerator: Configuration and Settings | Snowflake Documentation](en/migrations/sma-docs/user-guide/project-overview/configuration-and-settings.md) - Setting up a new project with the Snowpark Migration Accelerator (SMA) is a simple process. This page explains all available settings, updates, and customization options within the application.
- [Snowpark Migration Accelerator: Optional Technical Discovery | Snowflake Documentation](en/migrations/sma-docs/user-guide/project-overview/optional-technical-discovery.md) - Technical discovery is an optional questionnaire within the Snowpark Migration Accelerator (SMA). With it, you can gather high-level information about your workload, which is a type of information tha
- [Snowpark Migration Accelerator:  Project Setup | Snowflake Documentation](en/migrations/sma-docs/user-guide/project-overview/project-setup.html.md) - When you first open the Snowpark Migration Accelerator (SMA), you will see two options:
- [Snowpark Migration Accelerator:  Project Setup | Snowflake Documentation](en/migrations/sma-docs/user-guide/project-overview/project-setup.md) - When you first open the Snowpark Migration Accelerator (SMA), you will see two options:
- [Snowpark Migration Accelerator:  Tool Execution | Snowflake Documentation](en/migrations/sma-docs/user-guide/project-overview/tool-execution.md) - After setting up your project, you can run the Snowpark Migration Accelerator (SMA). This is the most straightforward step in the process.
- [Snowpark Migration Accelerator:  Using the SMA CLI | Snowflake Documentation](en/migrations/sma-docs/user-guide/using-the-sma-cli/README.md) - The Snowpark Migration Accelerator (SMA) provides a Command Line Interface (CLI) that allows you to perform various operations. Using this CLI, you can execute the code processor, manage access codes 
- [Snowpark Migration Accelerator:  Additional Parameters | Snowflake Documentation](en/migrations/sma-docs/user-guide/using-the-sma-cli/additional-parameters.md) - The Snowpark Migration Accelerator (SMA) provides optional parameters that help you customize how your source code is assessed or converted. Here’s a detailed explanation of all additional parameters 
- [Snowpark Migration Accelerator:  Getting Started with the Workspace Estimator | Snowflake Documentation](en/migrations/sma-docs/workspace-estimator/getting-started.md) - This page is currently being developed. For more information about the Workspace Estimator, please contact sma-support@snowflake.com.
- [Snowpark Migration Accelerator: Overview of the Workspace Estimator | Snowflake Documentation](en/migrations/sma-docs/workspace-estimator/overview.md) - The Workspace Estimator (WE) is a tool that helps users understand how they are using their cloud workspace. This information can then be shared with Snowflake to compare current usage patterns with p
- [AI Verification with Source-System Verification | Snowflake Documentation](en/migrations/snowconvert-docs/ai-verification/snowconvert-ai-twosided-verification.md) - AI verification with source-system verification improves the accuracy of the conversion process. It runs the generated test case against both the converted code in Snowflake and the original source co
- [Snowflake Data Validation CLI - Quick Reference | Snowflake Documentation](en/migrations/snowconvert-docs/data-validation-cli/CLI_QUICK_REFERENCE.html.md) - This quick reference guide provides a condensed overview of commands, configuration options, and common usage patterns for the Snowflake Data Validation CLI tool, designed for easy lookup during valid
- [Snowflake Data Validation CLI - Quick Reference | Snowflake Documentation](en/migrations/snowconvert-docs/data-validation-cli/CLI_QUICK_REFERENCE.md) - This quick reference guide provides a condensed overview of commands, configuration options, and common usage patterns for the Snowflake Data Validation CLI tool, designed for easy lookup during valid
- [Snowflake Data Validation CLI - Complete Usage Guide | Snowflake Documentation](en/migrations/snowconvert-docs/data-validation-cli/CLI_USAGE_GUIDE.html.md) - The Snowflake Data Validation CLI (snowflake-data-validation or sdv) is a comprehensive command-line tool for validating data migrations between source databases (SQL Server, Teradata, Amazon Redshift
- [Snowflake Data Validation CLI - Complete Usage Guide | Snowflake Documentation](en/migrations/snowconvert-docs/data-validation-cli/CLI_USAGE_GUIDE.md) - The Snowflake Data Validation CLI (snowflake-data-validation or sdv) is a comprehensive command-line tool for validating data migrations between source databases (SQL Server, Teradata, Amazon Redshift
- [Configuration File Examples | Snowflake Documentation](en/migrations/snowconvert-docs/data-validation-cli/CONFIGURATION_EXAMPLES.html.md) - This document provides ready-to-use configuration examples for various validation scenarios. Copy and adapt these examples for your specific use case.
- [Configuration File Examples | Snowflake Documentation](en/migrations/snowconvert-docs/data-validation-cli/CONFIGURATION_EXAMPLES.md) - This document provides ready-to-use configuration examples for various validation scenarios. Copy and adapt these examples for your specific use case.
- [Snowflake Data Validation - Documentation Index | Snowflake Documentation](en/migrations/snowconvert-docs/data-validation-cli/index.md) - Welcome to the Snowflake Data Validation CLI documentation. The Snowflake Data Validation CLI (snowflake-data-validation or sdv) is a comprehensive command-line tool for validating data migrations bet
- [Amazon Redshift Commands Reference | Snowflake Documentation](en/migrations/snowconvert-docs/data-validation-cli/redshift_commands.html.md) - This page provides comprehensive reference documentation for Amazon Redshift-specific commands in the Snowflake Data Validation CLI. For SQL Server commands, see SQL Server Commands Reference. For Ter
- [Amazon Redshift Commands Reference | Snowflake Documentation](en/migrations/snowconvert-docs/data-validation-cli/redshift_commands.md) - This page provides comprehensive reference documentation for Amazon Redshift-specific commands in the Snowflake Data Validation CLI. For SQL Server commands, see SQL Server Commands Reference. For Ter
- [Release Notes - Snowflake Data Validation CLI | Snowflake Documentation](en/migrations/snowconvert-docs/data-validation-cli/release_notes.md) - New Command: column-partitioning-helper - Interactive helper to partition wide tables by columns for more efficient validation of tables with many columns
- [SQL Server Commands Reference | Snowflake Documentation](en/migrations/snowconvert-docs/data-validation-cli/sqlserver_commands.html.md) - This page provides comprehensive reference documentation for SQL Server-specific commands in the Snowflake Data Validation CLI. For Teradata commands, see Teradata Commands Reference. For Amazon Redsh
- [SQL Server Commands Reference | Snowflake Documentation](en/migrations/snowconvert-docs/data-validation-cli/sqlserver_commands.md) - This page provides comprehensive reference documentation for SQL Server-specific commands in the Snowflake Data Validation CLI. For Teradata commands, see Teradata Commands Reference. For Amazon Redsh
- [Teradata Commands Reference | Snowflake Documentation](en/migrations/snowconvert-docs/data-validation-cli/teradata_commands.html.md) - This page provides comprehensive reference documentation for Teradata-specific commands in the Snowflake Data Validation CLI. For SQL Server commands, see SQL Server Commands Reference. For Amazon Red
- [Teradata Commands Reference | Snowflake Documentation](en/migrations/snowconvert-docs/data-validation-cli/teradata_commands.md) - This page provides comprehensive reference documentation for Teradata-specific commands in the Snowflake Data Validation CLI. For SQL Server commands, see SQL Server Commands Reference. For Amazon Red
- [SnowConvert AI - About | Snowflake Documentation](en/migrations/snowconvert-docs/general/about.md) - SnowConvert AI is a specialized tool that accurately converts source code from various platforms to Snowflake exclusively.
- [SnowConvert AI - Contact Us | Snowflake Documentation](en/migrations/snowconvert-docs/general/contact-us.md) - SnowConvert AI is now a part of Snowflake.
- [SnowConvert AI - Frequently Asked Questions (FAQ) | Snowflake Documentation](en/migrations/snowconvert-docs/general/frequently-asked-questions-faq.md) - SnowConvert AI can translate SQL code from Teradata, Oracle, SQL Server, Amazon Redshift, Sybase IQ, Google BigQuery, Azure Synapse, Greenplum, PostgresSQL, Vertica, Hive, Spark, Databricks, Netezza a
- [SnowConvert AI - Getting Started | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/README.md) - Everything you need to get started with SnowConvert.
- [SnowConvert AI - Best practices | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/best-practices.md) - We highly recommend you use our scripts to extract your workload:
- [SnowConvert AI - Code Extraction | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/code-extraction/README.md) - Was this page helpful?
- [SnowConvert AI - Oracle | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/code-extraction/oracle.md) - The first step for migration is getting the code that you need to migrate. There are many ways to extract the code from your database. However, we recommend using the extraction scripts provided by Sn
- [SnowConvert AI - Redshift | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/code-extraction/redshift.md) - The first step in migration is getting the code you need to migrate. There are many ways to extract the code from your database, but we recommend using the extraction scripts provided by Snowflake.
- [SnowConvert AI - SQL Server | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/code-extraction/sql-server.md) - The first step for migration is getting the code that you need to migrate. There are many ways to extract the code from your database. However, we highly recommend using SQL Server Management Studio (
- [SnowConvert AI - Sybase IQ | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/code-extraction/sybase-iq.md) - The first step for migration is getting the code that you need to migrate. There are many ways to extract the code from your database. However, we recommend using the extraction scripts provided by Sn
- [SnowConvert AI - Teradata | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/code-extraction/teradata.md) - The first step for migration is getting the code that you need to migrate. There are many ways to extract the code from your database. However, we recommend using the extraction scripts provided by Sn
- [SnowConvert AI - Download and Access | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/download-and-access.md) - Getting up and running with Snowflake SnowConvert AI is quick and easy.
- [SnowConvert AI - Running SnowConvert AI | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/README.md) - Was this page helpful?
- [SnowConvert AI - Conversion | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/conversion/README.md) - To execute a conversion you need a valid access code, you can request one for free from the app by clicking over the link ‘Get an Access Code’:
- [SnowConvert AI - Converting subfolders | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/conversion/converting-subfolders.md) - SnowConvert AI allows you to run a conversion over a specific portion of your code, ignoring the parts that do not need to be converted.
- [SnowConvert AI - General Conversion Settings | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/conversion/general-conversion-settings.html.md) - This setting in SnowConvert AI determines how the tool reads and interprets the text within your source files. Choosing the correct encoding is important to ensure that all characters, especially acce
- [SnowConvert AI - General Conversion Settings | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/conversion/general-conversion-settings.md) - This setting in SnowConvert AI determines how the tool reads and interprets the text within your source files. Choosing the correct encoding is important to ensure that all characters, especially acce
- [SnowConvert AI -  Oracle Conversion Settings | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/conversion/oracle-conversion-settings.html.md)
- [SnowConvert AI -  Oracle Conversion Settings | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/conversion/oracle-conversion-settings.md)
- [SnowConvert AI - Preview Features Settings | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/conversion/preview-conversion-settings.md) - The Preview Features Settings in SnowConvert AI allow you to enable conversions that utilize Snowflake Public Preview features. By entering any of the available flags in the textbox, SnowConvert AI ca
- [SnowConvert AI - SQL Server Conversion Settings | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/conversion/sql-server-conversion-settings.md) - This topic applies to the following sources:
- [SnowConvert AI - Teradata Conversion Settings | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/conversion/teradata-conversion-settings.html.md)
- [SnowConvert AI - Teradata Conversion Settings | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/conversion/teradata-conversion-settings.md)
- [SnowConvert AI - Review Results | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/README.md) - The output from SnowConvert AI includes both Snowflake-Ready code and reports designed to give you more information about the conversion that just took place. You’ll also be given more information abo
- [SnowConvert AI - Output Code | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/output-code.md) - Suppose this is the input source code you’ve migrated:
- [SnowConvert AI - Reports | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/README.md) - In this section, we try to explain concepts used in multiple report documents generated by SnowConvert.
- [SnowConvert AI - Assessment Report | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/assessment-report/README.html.md) - The purpose of this document is to provide guidance for users to understand the summary results from the SnowConvert AI conversion tools. It will guide through the different metrics returned and how t
- [SnowConvert AI - Assessment Report | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/assessment-report/README.md) - The purpose of this document is to provide guidance for users to understand the summary results from the SnowConvert AI conversion tools. It will guide through the different metrics returned and how t
- [SnowConvert AI - Code Completeness Score | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/assessment-report/code-completeness-score.md)
- [SnowConvert AI - Databases & Schemas | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/assessment-report/databases-and-schemas.md) - Note
- [SnowConvert AI - File and Object Level Breakdown - SQL Files | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/assessment-report/file-and-object-level-breakdown-sql-files.md)
- [SnowConvert AI - File and Object Level Breakdown - SQL Identified Objects | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/assessment-report/file-and-object-level-breakdown-sql-identified-objects.md)
- [SnowConvert AI - Object Conversion Summary | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/assessment-report/object-conversion-summary.md)
- [SnowConvert AI - Overall Conversion Summary | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/assessment-report/overall-conversion-summary.md)
- [SnowConvert AI - Schemas | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/assessment-report/schemas.md) - Note
- [SnowConvert AI - Scripts - Files | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/assessment-report/scripts-files.md) - Note
- [SnowConvert AI - Scripts - Identified Objects | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/assessment-report/scripts-identified-objects.md) - Note
- [SnowConvert AI - Scripts Line Conversion Summary | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/assessment-report/scripts-line-conversion-summary.md) - Note
- [SnowConvert AI - SQL Conversion Summary | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/assessment-report/sql-conversion-summary.html.md) - Note
- [SnowConvert AI - SQL Conversion Summary | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/assessment-report/sql-conversion-summary.md) - Note
- [SnowConvert AI - Elements Report | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/elements-report.md) - The term “element” is used in this context to address a grammar element; that is, an element from a grammar that has a name, a syntax and a purpose within a specific language.
- [SnowConvert AI - Embedded Code Units Report | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/embedded-code-units-report.html.md) - A Code Unit, as the name suggests, is the most atomic, standalone executable element. In most cases, these are statements, but they also include script files as well because those are executed as a si
- [SnowConvert AI - Embedded Code Units Report | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/embedded-code-units-report.md) - A Code Unit, as the name suggests, is the most atomic, standalone executable element. In most cases, these are statements, but they also include script files as well because those are executed as a si
- [SnowConvert AI - ETL Replatform Issues Report | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/etl-replatform-issues-report.md) - Preview Feature — Open
- [SnowConvert AI - ETL Replatform Component Summary Report | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/etl-replatform-report.md) - Preview Feature — Open
- [SnowConvert AI - Functions Usage Report | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/functions-usage-report.md) - The term “usage” is used in this context to indicate that a specific function was invoked in the code. This function could be a built-in or user-defined function in a source language.
- [SnowConvert AI - Issues Report | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/issues-report.md) - An issue is a message that provides relevant information about the transformations done by SnowConvert AI.
- [SnowConvert AI - Missing Objects Report | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/missing-objects-report.md) - Missing object is the term used to refer to missing DDL definitions inside the source code that are being referenced by code units. The table below shows which elements could be missing objects in eac
- [SnowConvert AI - Object References Report | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/object-references-report.md) - Note
- [SnowConvert AI -  Renaming Report | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/renaming-reports.md) - It is an object that underwent a name change during the migration, following the changes configured in Redshift Studio.
- [SnowConvert AI - Top-Level Code Units Report | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/top-level-code-units-report.html.md) - A Code Unit, as the name suggests, is the most atomic, standalone executable element. In most cases, these are statements, but they also include script files as well because those are executed as a si
- [SnowConvert AI - Top-Level Code Units Report | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/top-level-code-units-report.md) - A Code Unit, as the name suggests, is the most atomic, standalone executable element. In most cases, these are statements, but they also include script files as well because those are executed as a si
- [SnowConvert AI - TypeMappings Report | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/reports/type-mappings-report.md) - The TypeMappings report shows the data type transformations that were applied based on your Data Type Customization file. This report only includes transformations specified in the customization file.
- [SnowConvert AI - SnowConvert AI Scopes | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/snowconvert-scopes.html.md) - Every single file in the input path is considered the Submitted Scope. However, there can be files with unrecognized extensions or unsupported encodings that will not be processed by SnowConvert AI. E
- [SnowConvert AI - SnowConvert AI Scopes | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/review-results/snowconvert-scopes.md) - Every single file in the input path is considered the Submitted Scope. However, there can be files with unrecognized extensions or unsupported encodings that will not be processed by SnowConvert AI. E
- [SnowConvert AI - Supported Languages | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/supported-languages/README.md) - Teradata
- [SnowConvert AI - Azure Synapse | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/supported-languages/azure-synapse.md) - SnowConvert AI is a software that understands Azure Synapse scripts and converts this source code into functionally equivalent Snowflake code.
- [SnowConvert AI - Google BigQuery | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/supported-languages/google-bigquery.md) - SnowConvert AI is a software that understands SQL Google BigQuery scripts and converts this source code into functionally equivalent Snowflake code.
- [SnowConvert AI - Hive-Spark-Databricks SQL | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/supported-languages/hive-spark-databricks-sql.md) - SnowConvert AI is a software that understands SQL scripts and converts this source code into functionally equivalent Snowflake code.
- [SnowConvert AI - IBM DB2 | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/supported-languages/ibm-db2.md) - SnowConvert AI is a software that understands SQL IBM DB2 scripts and converts this source code into functionally equivalent Snowflake code.
- [SnowConvert AI - Oracle | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/supported-languages/oracle.md) - SnowConvert AI is a software that understands Oracle SQL and PL/SQL, and performs the following conversions:
- [SnowConvert AI - PostgreSQL-Greenplum-Netezza | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/supported-languages/postgresql-and-based-languages.md) - SnowConvert AI is a software that understands PostgreSQL, Greenplum or Netezza scripts and converts the source code into functionally equivalent Snowflake code.
- [SnowConvert AI - Redshift | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/supported-languages/redshift.md) - SnowConvert AI is a software that understands SQL Redshift scripts and converts this source code into functionally equivalent Snowflake code.
- [SnowConvert AI - SQL Server | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/supported-languages/sql-server.md) - SnowConvert AI is a software that understands SQL Server scripts and converts this source code into functionally equivalent Snowflake code.
- [SnowConvert AI - Sybase IQ | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/supported-languages/sybase-iq.md) - SnowConvert AI is a software that understands Sybase IQ scripts and converts this source code into functionally equivalent Snowflake code.
- [SnowConvert AI - Teradata | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/supported-languages/teradata.md) - SnowConvert AI is a software that understands Teradata SQL, BTEQ, and other Teradata-specific scripts (such as Fastload, Multiload, TPump, and TPT files) and converts this source code into functionall
- [SnowConvert AI - Vertica | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/supported-languages/vertica.md) - SnowConvert AI is a software that understands SQL Vertica scripts and converts this source code into functionally equivalent Snowflake code.
- [SnowConvert AI - Validation | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/validation/README.md) - The Scope Validator step checks if the entry code meets the basic requirements to execute a successful conversion. These requirements are:
- [SnowConvert AI - Ambiguous Comments Validation | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/validation/ambiguous-comments-validations.md) - This validation step verifies if the entry code has a sequence of characters that may create ambiguous comments (/*/)
- [SnowConvert AI - Extraction Validation | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/validation/extraction-validation.md) - This validation step verifies if the entry code was extracted, which means the Extraction Script tool was used.
- [SnowConvert AI - File Encoding Validation | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/validation/file-encoding-validation.md) - This validation step tries to recognize the file’s encoding; if not, it is marked as invalid. If it is recognized as different from the encoding selected in the Assessment or Conversion configuration 
- [SnowConvert AI - File Extension Validation | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/validation/file-extension-validation.md) - This validation step verifies the file extensions. These are the valid file extensions:
- [SnowConvert AI - File Format Validation | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/validation/file-format-validation.md) - This validation step verifies the file’s structure and indentation. If the average of characters per line of all the entry code is greater than the maximum allowed, a window with a warning is displaye
- [SnowConvert AI - System Object Naming Validation | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/running-snowconvert/validation/system-object-naming-validation.md) - This validation step verifies the files and folder names containing reserved words. These files and folders are marked as invalid or out of scope because they can potentially be built-in systems defin
- [SnowConvert AI - System Requirements | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/system-requirements.md) - Before you start, make sure that your system meets the minimum requirements list given here:
- [SnowConvert AI - Training and Support | Snowflake Documentation](en/migrations/snowconvert-docs/general/getting-started/training-and-support.md) - We highly recommend that you go through the SnowConvert AI training in order to get the most out of SnowConvert AI. This training provides participants with the core knowledge to recognize how SnowCon
- [SnowConvert AI - How to Use SnowConvert AI with Docker | Snowflake Documentation](en/migrations/snowconvert-docs/general/others/using-snowconvert-in-a-ubuntu-docker-image.md) - The following dependencies must be installed on the machine:
- [SnowConvert AI - Recent Release Notes | Snowflake Documentation](en/migrations/snowconvert-docs/general/release-notes/release-notes/README.md) - SQL Server extraction process now adds ‘GO’ statements after USE database commands in object definition files to allow files to be executable.
- [SnowConvert AI - Technical Documentation | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/README.md) - Was this page helpful?
- [SnowConvert AI - Considerations | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/considerations/README.md) - Was this page helpful?
- [SnowConvert AI - Teradata | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/considerations/teradata.md) - Teradata and Snowflake handle calculations differently:
- [SnowConvert AI - Function References for Oracle | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/function-references/oracle/README.md) - This user-defined function (UDF) is used to subtract a number (which is a number of days) from a timestamp.
- [SnowConvert AI - Function References - Shared | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/function-references/shared/README.md) - This user-defined function (UDF) is used to multiply an interval of time with a value of ‘N’ times.
- [SnowConvert AI - SnowConvert AI UDFs | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/function-references/snowconvert-udfs.md) - SnowConvert AI includes several User-Defined Functions (UDFs) that help replicate behaviors from source languages which Snowflake doesn’t natively support. Here’s what these functions do:
- [SnowConvert AI - Function References for SQL-Server | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/function-references/sql-server/README.html.md) - This user-defined function (UDF) determines whether an expression is a valid numeric type.
- [SnowConvert AI - Function References for SQL-Server | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/function-references/sql-server/README.md) - This user-defined function (UDF) determines whether an expression is a valid numeric type.
- [SnowConvert AI - Function References for Teradata | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/function-references/teradata/README.md) - UDF (User-Defined Function) that calculates the quarter number of a given date according to the ISO calendar year, similar to Teradata’s QUARTERNUMBER_OF_YEAR_UDF(date, ‘ISO’) function.
- [SnowConvert AI - Understanding Converted Code | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/README.md) - SnowConvert AI produces messages in the converted code that highlight areas requiring additional work to ensure the code functions correctly in Snowflake.
- [SnowConvert AI - Conversion Issues (EWIs) | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/conversion-issues/README.md) - When SnowConvert AI cannot completely convert a piece of code, it generates an Error, Warning, and Issue (EWI). Each EWI negatively affects the conversion rate of a code unit. SnowConvert AI may encou
- [SnowConvert AI - BigQuery Issues | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/conversion-issues/bigqueryEWI.html.md) - Note
- [SnowConvert AI - BigQuery Issues | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/conversion-issues/bigqueryEWI.md) - Note
- [SnowConvert AI - IBM DB2 Issues | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/conversion-issues/db2EWI.html.md) - WITH ROW ACCESS POLICY CLAUSE DOES NOT SUPPORT MULTIPLE DECLARATION
- [SnowConvert AI - IBM DB2 Issues | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/conversion-issues/db2EWI.md) - WITH ROW ACCESS POLICY CLAUSE DOES NOT SUPPORT MULTIPLE DECLARATION
- [SnowConvert AI - General Issues | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/conversion-issues/generalEWI.md) - Unrecognized token on the line of the source code.
- [SnowConvert AI - Hive Issues | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/conversion-issues/hiveEWI.md) - Note
- [SnowConvert AI - Oracle Issues | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/conversion-issues/oracleEWI.html.md) - Sequence start value with ‘LIMIT VALUE’ is not supported by Snowflake.
- [SnowConvert AI - Oracle Issues | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/conversion-issues/oracleEWI.md) - Sequence start value with ‘LIMIT VALUE’ is not supported by Snowflake.
- [SnowConvert AI - PostgreSQL Issues | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/conversion-issues/postgresqlEWI.html.md) - Note
- [SnowConvert AI - PostgreSQL Issues | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/conversion-issues/postgresqlEWI.md) - Note
- [SnowConvert AI - Redshift Issues | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/conversion-issues/redshiftEWI.html.md) - Set “configuration parameter” is not supported in Snowflake.
- [SnowConvert AI - Redshift Issues | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/conversion-issues/redshiftEWI.md) - Set “configuration parameter” is not supported in Snowflake.
- [SnowConvert AI - Spark Issues | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/conversion-issues/sparkEWI.md) - Note
- [SnowConvert AI - SQL Server-Azure Synapse Issues | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/conversion-issues/sqlServerEWI.html.md) - SQL Server
- [SnowConvert AI - SQL Server-Azure Synapse Issues | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/conversion-issues/sqlServerEWI.md) - SQL Server
- [SnowConvert AI - SSIS Conversion Issues | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/conversion-issues/ssisEWI.html.md) - Preview Feature — Open
- [SnowConvert AI - SSIS Conversion Issues | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/conversion-issues/ssisEWI.md) - Preview Feature — Open
- [SnowConvert AI - Sybase IQ Issues | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/conversion-issues/sybaseEWI.html.md) - Note
- [SnowConvert AI - Sybase IQ Issues | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/conversion-issues/sybaseEWI.md) - Note
- [SnowConvert AI - Teradata Issues | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/conversion-issues/teradataEWI.html.md) - Recursive forward alias error.
- [SnowConvert AI - Teradata Issues | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/conversion-issues/teradataEWI.md) - Recursive forward alias error.
- [SnowConvert AI - Vertica Issues | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/conversion-issues/verticaEWI.html.md) - Inherited privileges clause is not supported in Snowflake.
- [SnowConvert AI - Vertica Issues | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/conversion-issues/verticaEWI.md) - Inherited privileges clause is not supported in Snowflake.
- [SnowConvert AI - Functional Difference Messages | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/functional-difference/README.md) - An FDM is generated when SnowConvert AI is able to output syntactically correct code but that code may not provide exact functional equivalence to the original legacy code. Reasons for functional in-e
- [SnowConvert AI - BigQuery Functional Differences | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/functional-difference/bigqueryFDM.html.md) - Note
- [SnowConvert AI - BigQuery Functional Differences | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/functional-difference/bigqueryFDM.md) - Note
- [SnowConvert AI - IBM DB2 Functional Differences | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/functional-difference/db2FDM.html.md) - FUNCTIONALITY MIGHT BE DIFFERENT DEPENDING ON THE DB2 DATABASE.
- [SnowConvert AI - IBM DB2 Functional Differences | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/functional-difference/db2FDM.md) - FUNCTIONALITY MIGHT BE DIFFERENT DEPENDING ON THE DB2 DATABASE.
- [SnowConvert AI - General Functional Differences | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/functional-difference/generalFDM.md) - Views selecting all columns from a single table are not required in Snowflake
- [SnowConvert AI - Greenplum Functional Differences | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/functional-difference/greenplumFDM.html.md) - Note
- [SnowConvert AI - Greenplum Functional Differences | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/functional-difference/greenplumFDM.md) - Note
- [SnowConvert AI - Hive Functional Differences | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/functional-difference/hiveFDM.html.md) - Inserting values into an external table is not supported in Snowflake
- [SnowConvert AI - Hive Functional Differences | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/functional-difference/hiveFDM.md) - Inserting values into an external table is not supported in Snowflake
- [SnowConvert AI - Oracle Functional Differences | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/functional-difference/oracleFDM.html.md) - Note
- [SnowConvert AI - Oracle Functional Differences | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/functional-difference/oracleFDM.md) - Note
- [SnowConvert AI - PostgreSQL Functional Differences | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/functional-difference/postgresqlFDM.html.md) - Note
- [SnowConvert AI - PostgreSQL Functional Differences | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/functional-difference/postgresqlFDM.md) - Note
- [SnowConvert AI - Redshift Functional Differences | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/functional-difference/redshiftFDM.html.md) - Option not supported. Data storage is automatically handled by Snowflake.
- [SnowConvert AI - Redshift Functional Differences | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/functional-difference/redshiftFDM.md) - Option not supported. Data storage is automatically handled by Snowflake.
- [SnowConvert AI - SQL Server-Azure Synapse Functional Differences | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/functional-difference/sqlServerFDM.html.md) - SQL Server
- [SnowConvert AI - SQL Server-Azure Synapse Functional Differences | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/functional-difference/sqlServerFDM.md) - SQL Server
- [SnowConvert AI - SSIS Functional Differences | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/functional-difference/ssisFDM.html.md) - Preview Feature — Open
- [SnowConvert AI - SSIS Functional Differences | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/functional-difference/ssisFDM.md) - Preview Feature — Open
- [SnowConvert AI - Sybase IQ Functional Differences | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/functional-difference/sybaseFDM.html.md) - Note
- [SnowConvert AI - Sybase IQ Functional Differences | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/functional-difference/sybaseFDM.md) - Note
- [SnowConvert AI - Teradata Functional Differences | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/functional-difference/teradataFDM.html.md) - Column converted from Blob data type.
- [SnowConvert AI - Teradata Functional Differences | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/functional-difference/teradataFDM.md) - Column converted from Blob data type.
- [SnowConvert AI - Vertica Functional Differences | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/functional-difference/verticaFDM.html.md) - Note
- [SnowConvert AI - Vertica Functional Differences | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/functional-difference/verticaFDM.md) - Note
- [SnowConvert AI - Out-of-Scope | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/out-of-scope/README.md) - Examples of Out-of-scope code units if multiple SQL Languages
- [SnowConvert AI - Out of Scope | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/out-of-scope/generalOOS.html.md) - The file has an unexpected encoding and was not translated
- [SnowConvert AI - Out of Scope | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/out-of-scope/generalOOS.md) - The file has an unexpected encoding and was not translated
- [SnowConvert AI - Performance Review Messages | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/performance-review/README.md) - A Performance Review (PRF) issue indicates that while SnowConvert AI successfully translated the source code to valid Snowflake syntax, the resulting code may not perform optimally in Snowflake. When 
- [SnowConvert AI - General Performance Review Messages | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/performance-review/generalPRF.html.md) - This statement has usages of cursor fetch bulk operations
- [SnowConvert AI - General Performance Review Messages | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/performance-review/generalPRF.md) - This statement has usages of cursor fetch bulk operations
- [SnowConvert AI - SQL Server-Azure Synapse Performance Review Messages | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/performance-review/sqlServerPRF.html.md) - SQL Server
- [SnowConvert AI - SQL Server-Azure Synapse Performance Review Messages | Snowflake Documentation](en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/performance-review/sqlServerPRF.md) - SQL Server
- [SnowConvert AI - Conversion Software Terms of Use | Snowflake Documentation](en/migrations/snowconvert-docs/general/terms-and-conditions/README.md) - For the most current and authoritative version of the Conversion Software Terms of Use, please visit the official Snowflake legal site:
- [SnowConvert AI - Open Source Libraries | Snowflake Documentation](en/migrations/snowconvert-docs/general/terms-and-conditions/open-source-libraries.md) - name
- [SnowConvert AI: Data migration | Snowflake Documentation](en/migrations/snowconvert-docs/general/user-guide/data-migration.md) - SnowConvert AI, as part of the end-to-end migration experience, provides the capability to migrate your actual data from source tables to Snowflake after the database structure is deployed. This data 
- [SnowConvert AI: Data validation | Snowflake Documentation](en/migrations/snowconvert-docs/general/user-guide/data-validation.md) - SnowConvert AI, as part of the end-to-end migration experience, provides the capability to validate your migrated data to ensure that both the structure of the data and the data itself match the origi
- [SnowConvert AI: Deployment | Snowflake Documentation](en/migrations/snowconvert-docs/general/user-guide/deployment.md) - SnowConvert AI, as part of the end-to-end migration experience, offers the option to deploy converted database objects directly to your Snowflake environment. With this deployment feature, you can rev
- [SnowConvert AI - ETL Migration | Snowflake Documentation](en/migrations/snowconvert-docs/general/user-guide/etl-migration-replatform.md) - Preview Feature — Open
- [SnowConvert AI: Extraction | Snowflake Documentation](en/migrations/snowconvert-docs/general/user-guide/extraction.md) - SnowConvert AI provides the following options for extracting database objects:
- [SnowConvert AI: Power BI Repointing | Snowflake Documentation](en/migrations/snowconvert-docs/general/user-guide/power-bi-repointing-general.md) - This guide provides comprehensive instructions on utilizing Snowconvert AI for Power BI repointing to Snowflake. It details the process of migrating your existing Power BI reports and dashboards to le
- [SnowConvert AI: Project Creation | Snowflake Documentation](en/migrations/snowconvert-docs/general/user-guide/project-creation.md) - SnowConvert AI manages migrations by using SnowConvert AI projects. A SnowConvert AI project contains metadata about migrating a data set into Snowflake, such as the source database platform, input fi
- [Using SnowConvert AI | Snowflake Documentation](en/migrations/snowconvert-docs/general/user-guide/snowconvert/README.md) - Use this guide to learn how SnowConvert AI can accelerate your migration to Snowflake:
- [SnowConvert AI - Command Line Interface | Snowflake Documentation](en/migrations/snowconvert-docs/general/user-guide/snowconvert/command-line-interface/README.md) - To execute a conversion with the SnowConvert AI CLI you have to have an active access code. Currently, the access codes for the CLI are different than the UI, but if you already have an access code fo
- [SnowConvert AI - Oracle | Snowflake Documentation](en/migrations/snowconvert-docs/general/user-guide/snowconvert/command-line-interface/oracle.html.md) - Flag to indicate whether SnowConvert AI should migrate the procedures to Javascript and Python. By default, it is set to false.
- [SnowConvert AI - Oracle | Snowflake Documentation](en/migrations/snowconvert-docs/general/user-guide/snowconvert/command-line-interface/oracle.md) - Flag to indicate whether SnowConvert AI should migrate the procedures to Javascript and Python. By default, it is set to false.
- [SnowConvert AI - Redshift | Snowflake Documentation](en/migrations/snowconvert-docs/general/user-guide/snowconvert/command-line-interface/redshift.md) - The following CLI arguments are specific for executing migrations with SnowConvert AI for Redshift
- [SnowConvert AI - Renaming feature | Snowflake Documentation](en/migrations/snowconvert-docs/general/user-guide/snowconvert/command-line-interface/renaming-feature.md) - Renaming objects during a database migration process is something that a lot of users need to do. For this reason, SnowConvert AI enables the Renaming feature to allow defining new names for the follo
- [SnowConvert AI - Sql Server | Snowflake Documentation](en/migrations/snowconvert-docs/general/user-guide/snowconvert/command-line-interface/sql-server.md) - Flag to indicate whether or not the Transact SQL USE statement should be translated.
- [SnowConvert AI - Teradata | Snowflake Documentation](en/migrations/snowconvert-docs/general/user-guide/snowconvert/command-line-interface/teradata.md) - The following CLI arguments are specific for executing migrations with SnowConvert AI for Teradata
- [SnowConvert AI - How to install the tool | Snowflake Documentation](en/migrations/snowconvert-docs/general/user-guide/snowconvert/how-to-install-the-tool/README.md) - Now that you’ve downloaded the tool, you can run the installer. Follow the steps below to get started using SnowConvert.
- [SnowConvert AI - Linux | Snowflake Documentation](en/migrations/snowconvert-docs/general/user-guide/snowconvert/how-to-install-the-tool/linux.md) - The Graphical User Interface is not available for Linux, but the Command Line Interface is. You can download the snow-convert.tar and then run the following commands in a terminal (in the directory wh
- [SnowConvert AI - MacOS | Snowflake Documentation](en/migrations/snowconvert-docs/general/user-guide/snowconvert/how-to-install-the-tool/macos.md) - Click on the downloaded .dmg file.
- [SnowConvert AI - Windows | Snowflake Documentation](en/migrations/snowconvert-docs/general/user-guide/snowconvert/how-to-install-the-tool/windows.md) - Click on the downloaded .exe file.
- [SnowConvert AI - How to get an access code | Snowflake Documentation](en/migrations/snowconvert-docs/general/user-guide/snowconvert/how-to-request-an-access-code/README.md) - An access code is required to use the application and is valid for 3 months. You can request an access code directly from the app, and it will only be issued to users with a company domain email addre
- [SnowConvert AI - How to Retrieve Your UUID for Offline Activation in Linux | Snowflake Documentation](en/migrations/snowconvert-docs/general/user-guide/snowconvert/how-to-request-an-access-code/how-to-retrieve-your-uuid-for-offline-activation-in-linux.md) - SnowConvert AI requires a UUID to validate the license for offline activation in Linux. Follow these steps to find and provide the UUID:
- [SnowConvert AI - How to update the tool | Snowflake Documentation](en/migrations/snowconvert-docs/general/user-guide/snowconvert/how-to-update-the-tool.md) - SnowConvert AI checks for updates automatically when you launch the application. But you can check any time if there is a new version available to be downloaded.
- [SnowConvert AI - How to use the SnowConvert AI CLI | Snowflake Documentation](en/migrations/snowconvert-docs/general/user-guide/snowconvert/how-to-use-the-snowconvert-cli.md) - Depending on your Operating System, you can review the corresponding installation guide:
- [SnowConvert AI - What is a Project? | Snowflake Documentation](en/migrations/snowconvert-docs/general/user-guide/snowconvert/what-is-a-snowconvert-project.md) - This concept introduces the ability to execute the tool and persist the status of a project and all its configurations like Source Platform, Conversion Settings, Status of the latest successfully exec
- [SnowConvert AI - Migration Assistant | Snowflake Documentation](en/migrations/snowconvert-docs/migration-assistant/README.md) - Visual Studio Code Extension
- [SnowConvert AI - Migration Assistant - Billing | Snowflake Documentation](en/migrations/snowconvert-docs/migration-assistant/billing.md) - The SnowConvert AI Migration Assistant uses the Snowflake Cortex REST API, which incurs compute costs based on the number of tokens processed. You can view current rates in the Snowflake Service Consu
- [SnowConvert AI - Migration Assistant - Getting Started | Snowflake Documentation](en/migrations/snowconvert-docs/migration-assistant/getting-started.md) - This guide will walk you through the SnowConvert AI Migration Assistant’s basic steps to resolve post-conversion issues in your SQL code.
- [SnowConvert AI - Migration Assistant - Legal Notices | Snowflake Documentation](en/migrations/snowconvert-docs/migration-assistant/legal-notices.md) - This feature relies on the Snowflake Cortex REST API to generate explanations of migration issues and suggest fixes. When the user interacts with the assistant, Usage Data may be collected through the
- [SnowConvert AI - Migration Assistant - Model Preference | Snowflake Documentation](en/migrations/snowconvert-docs/migration-assistant/model-preference.html.md) - The SnowConvert AI Migration Assistant supports configurable AI model preferences with automatic fallback functionality. This feature allows you to customize which AI models are used for generating fi
- [SnowConvert AI - Migration Assistant - Model Preference | Snowflake Documentation](en/migrations/snowconvert-docs/migration-assistant/model-preference.md) - The SnowConvert AI Migration Assistant supports configurable AI model preferences with automatic fallback functionality. This feature allows you to customize which AI models are used for generating fi
- [SnowConvert AI - Migration Assistant - Troubleshooting | Snowflake Documentation](en/migrations/snowconvert-docs/migration-assistant/troubleshooting.md) - Guidance on resolving issues you may encounter when using the SnowConvert AI Migration Assistant.
- [Snowflake SnowConvert AI Documentation | Snowflake Documentation](en/migrations/snowconvert-docs/overview.md)
- [SnowConvert AI Verification | Snowflake Documentation](en/migrations/snowconvert-docs/snowconvert-ai-verification.md) - AI verification strengthens SnowConvert AI by automating functional validation of converted database code. AI verification uses synthetic data generation, AI-driven unit testing, and AI-driven resolut
- [SnowConvert AI - BigQuery | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/bigquery/README.md) - Conversion Scope
- [SnowConvert AI - BigQuery - CREATE TABLE | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/bigquery/bigquery-create-table.md) - 1. Unsupported table options
- [SnowConvert AI - BigQuery - CREATE VIEW | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/bigquery/bigquery-create-view.md) - Creates a new view. (BigQuery SQL Language Reference Create view statement)
- [SnowConvert AI - BigQuery - Data types | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/bigquery/bigquery-data-types.md) - Snowflake provides support for the majority of fundamental SQL data types, with specific restrictions, across various SQL constructs including columns, local variables, expressions, and parameters.
- [SnowConvert AI - BigQuery - Built-in functions | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/bigquery/bigquery-functions.md) - Translation reference for all the supported built-in functions by SnowConvert AI for BigQuery.
- [SnowConvert AI - BigQuery - Identifier differences between BigQuery and Snowflake | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/bigquery/bigquery-identifiers.md) - BigQuery quoted identifiers are enclosed by backticks (`) while Snowflake encloses them in double quotes (“).
- [SnowConvert AI - BigQuery - Operators | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/bigquery/bigquery-operators.md) - IS operators return TRUE or FALSE for the condition they are testing. They never return NULL, even for NULL inputs. (BigQuery SQL Language Reference IS operators)
- [SnowConvert AI - DB2 | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/db2/README.md) - This page provides a comprehensive reference for how SnowConvert AI translates IBM DB2 grammar elements to Snowflake equivalents. In this translation reference, you will find code examples, functional
- [SnowConvert AI - IBM DB2 - CONTINUE HANDLER | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/db2/db2-continue-handler.html.md) - A CONTINUE handler allows the execution to continue after a condition is encountered. When a condition occurs and a continue handler is invoked, control is passed to the handler. When the handler comp
- [SnowConvert AI - IBM DB2 - CONTINUE HANDLER | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/db2/db2-continue-handler.md) - A CONTINUE handler allows the execution to continue after a condition is encountered. When a condition occurs and a continue handler is invoked, control is passed to the handler. When the handler comp
- [SnowConvert AI - IBM DB2 - CREATE FUNCTION | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/db2/db2-create-function.md) - Creates a new user defined function or replaces an existing function for the current database. (IBM DB2 SQL Language Reference Create Function).
- [SnowConvert AI - IBM DB2 - CREATE PROCEDURE | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/db2/db2-create-procedure.md) - Creates a new stored procedure or replaces an existing procedure for the current database. (IBM DB2 SQL Language Reference Create Procedure).
- [SnowConvert AI - IBM DB2 - CREATE TABLE | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/db2/db2-create-table.md) - The complete CREATE TABLE syntax for IBM DB2 is big enough that it does not fit on one page. However, the following image shows an overview of the syntax with some logical grouping that is later refer
- [SnowConvert AI - IBM DB2 - CREATE VIEW | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/db2/db2-create-view.md) - The CREATE VIEW statement defines a view on one or more tables, views or nicknames.
- [SnowConvert AI - IBM DB2 - Data Types | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/db2/db2-data-types.html.md) - Specifies the data type of the column
- [SnowConvert AI - IBM DB2 - Data Types | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/db2/db2-data-types.md) - Specifies the data type of the column
- [SnowConvert AI - IBM DB2 - EXIT HANDLER | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/db2/db2-exit-handler.html.md) - An EXIT handler terminates the current compound statement when the specified condition occurs. When a condition occurs and an exit handler is invoked, control is passed to the handler. When the handle
- [SnowConvert AI - IBM DB2 - EXIT HANDLER | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/db2/db2-exit-handler.md) - An EXIT handler terminates the current compound statement when the specified condition occurs. When a condition occurs and an exit handler is invoked, control is passed to the handler. When the handle
- [SnowConvert AI - IBM DB2 - From Clause | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/db2/db2-from-clause.md) - The FROM clause specifies an intermediate result table
- [SnowConvert AI - IBM DB2 - SELECT STATEMENT | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/db2/db2-select-statement.md) - A subdivision of the SELECT statement done in IBM DB2.
- [SnowConvert AI - General Translation Specification | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/general/README.md) - Translation references are essential for understanding how SnowConvert AI translates SQL statements from Oracle, Teradata, SQL Server, and all other available SQL languages to Snowflake.
- [SnowConvert AI - ANSI SQL - Built-in functions | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/general/built-in-functions.md) - This article provides an alphabetical list of built-in functions shared by the different dialects.
- [SnowConvert AI - ANSI SQL - Subqueries | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/general/subqueries.md) - A subquery is a query within another query. Subqueries in a FROM or WHERE clause are used to provide data that will be used to limit or compare/evaluate the data returned by the containing query. (Sno
- [SnowConvert AI - Hive-Spark-Databricks SQL | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/hive/README.md) - Conversion Scope
- [SnowConvert AI - Hive - Built-in functions | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/hive/built-in-functions.md) - Hive SQL
- [SnowConvert AI - Hive - Data Types | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/hive/data-types.md) - Snowflake supports most basic SQL data types (with some restrictions) for columns, local variables, expressions, parameters, and other appropriate/suitable locations.
- [SQL Statements | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/hive/ddls/README.md) - Translation reference for all the supported statements by SnowConvert AI for Hive, Spark and Databricks SQL.
- [SnowConvert AI - Hive - CREATE EXTERNAL TABLE | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/hive/ddls/create-external-table.md) - Hive SQL
- [SnowConvert AI - Hive - CREATE VIEW | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/hive/ddls/create-view.md) - Hive SQL
- [SnowConvert AI - Hive - SELECT | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/hive/ddls/select.md) - Hive SQL
- [SnowConvert AI - Hive - CREATE TABLE | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/hive/ddls/tables.md) - Hive SQL
- [SnowConvert AI - Oracle | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/README.md) - Translation specification for Oracle grammar syntax
- [SnowConvert AI - Oracle - Data Types | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/basic-elements-of-oracle-sql/data-types/README.html.md) - This section shows equivalents between data types in Oracle and Snowflake, as well as some notes on arithmetic differences.
- [SnowConvert AI - Oracle - Data Types | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/basic-elements-of-oracle-sql/data-types/README.md) - This section shows equivalents between data types in Oracle and Snowflake, as well as some notes on arithmetic differences.
- [SnowConvert AI - Oracle - Any Types | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/basic-elements-of-oracle-sql/data-types/any-types.html.md) - The Any types provide highly flexible modeling of procedure parameters and table columns where the actual type is not known. These data types let you dynamically encapsulate and access type descriptio
- [SnowConvert AI - Oracle - Any Types | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/basic-elements-of-oracle-sql/data-types/any-types.md) - The Any types provide highly flexible modeling of procedure parameters and table columns where the actual type is not known. These data types let you dynamically encapsulate and access type descriptio
- [SnowConvert AI - Oracle - Oracle Built-in Data Types | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/basic-elements-of-oracle-sql/data-types/oracle-built-in-data-types.html.md) - Beginning with Oracle Database 12_c_, you can specify a maximum size of 32767 bytes for the VARCHAR2, NVARCHAR2, and RAW data types. You can control whether your database supports this new maximum siz
- [SnowConvert AI - Oracle - Oracle Built-in Data Types | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/basic-elements-of-oracle-sql/data-types/oracle-built-in-data-types.md) - Beginning with Oracle Database 12_c_, you can specify a maximum size of 32767 bytes for the VARCHAR2, NVARCHAR2, and RAW data types. You can control whether your database supports this new maximum siz
- [SnowConvert AI - Oracle - Rowid Data Type | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/basic-elements-of-oracle-sql/data-types/rowid-types.html.md) - Each row in the database has an address. (Oracle SQL Language Reference Rowid Data Types)
- [SnowConvert AI - Oracle - Rowid Data Type | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/basic-elements-of-oracle-sql/data-types/rowid-types.md) - Each row in the database has an address. (Oracle SQL Language Reference Rowid Data Types)
- [SnowConvert AI - Oracle - Spatial Types | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/basic-elements-of-oracle-sql/data-types/spatial-types.html.md) - Oracle Spatial and Graph is designed to make spatial data management easier and more natural to users of location-enabled applications, geographic information system (GIS) applications, and geoimaging
- [SnowConvert AI - Oracle - Spatial Types | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/basic-elements-of-oracle-sql/data-types/spatial-types.md) - Oracle Spatial and Graph is designed to make spatial data management easier and more natural to users of location-enabled applications, geographic information system (GIS) applications, and geoimaging
- [SnowConvert AI - Oracle - User-Defined Types | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/basic-elements-of-oracle-sql/data-types/user-defined-types.md) - User-defined data types use Oracle built-in data types and other user-defined data types as the building blocks of object types that model the structure and behavior of data in applications. The secti
- [SnowConvert AI - Oracle - XML Types | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/basic-elements-of-oracle-sql/data-types/xml-types.html.md) - Extensible Markup Language (XML) is a standard format developed by the World Wide Web Consortium (W3C) for representing structured and unstructured data on the World Wide Web. Universal resource ident
- [SnowConvert AI - Oracle - XML Types | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/basic-elements-of-oracle-sql/data-types/xml-types.md) - Extensible Markup Language (XML) is a standard format developed by the World Wide Web Consortium (W3C) for representing structured and unstructured data on the World Wide Web. Universal resource ident
- [SnowConvert AI - Oracle - Literals | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/basic-elements-of-oracle-sql/literals.md) - The terms literal and constant value are synonymous and refer to a fixed data value. (Oracle SQL Language Reference Literals)
- [SnowConvert AI - Oracle - Built-In packages | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/built-in-packages.html.md) - Translation reference for Built-in packages.
- [SnowConvert AI - Oracle - Built-In packages | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/built-in-packages.md) - Translation reference for Built-in packages.
- [SnowConvert AI - Oracle - Power BI Repointing | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/etl-bi-repointing/power-bi-oracle-repointing.md) - The Power BI repointing is a feature that provides an easy way to redefine the connections from the M language in the Power Query Editor. This means that the connection parameters will be redefined to
- [SnowConvert AI - Oracle - Built-in functions | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/functions/README.md) - This section shows equivalents between functions in Oracle and in Snowflake.
- [SnowConvert AI - Oracle - SnowConvert AI Custom UDFs | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/functions/custom_udfs.html.md) - Some Oracle built-in functions and functionalities may not be available or may behave differently in Snowflake. To minimize these differences, some functions are replaced with SnowConvert AI Custom UD
- [SnowConvert AI - Oracle - SnowConvert AI Custom UDFs | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/functions/custom_udfs.md) - Some Oracle built-in functions and functionalities may not be available or may behave differently in Snowflake. To minimize these differences, some functions are replaced with SnowConvert AI Custom UD
- [SnowConvert AI - Oracle - PL/SQL to Javascript | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/pl-sql-to-javascript/README.html.md) - This is a translation reference to convert PL/SQL statements to snowflake JavaScript
- [SnowConvert AI - Oracle - PL/SQL to Javascript | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/pl-sql-to-javascript/README.md) - This is a translation reference to convert PL/SQL statements to snowflake JavaScript
- [SnowConvert AI - Oracle - Javascript Helpers | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/pl-sql-to-javascript/helpers.html.md) - In this section you will find the helper functions used inside procedures that are used to achieve functional equivalence of some Oracle features that are not supported natively in Snowflake.
- [SnowConvert AI - Oracle - Javascript Helpers | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/pl-sql-to-javascript/helpers.md) - In this section you will find the helper functions used inside procedures that are used to achieve functional equivalence of some Oracle features that are not supported natively in Snowflake.
- [SnowConvert AI - Oracle - PL/SQL to Snowflake Scripting | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/pl-sql-to-snowflake-scripting/README.html.md) - The assignment statement sets the value of a data item to a valid value. (Oracle PL/SQL Language Reference ASSIGNMENT Statement)
- [SnowConvert AI - Oracle - PL/SQL to Snowflake Scripting | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/pl-sql-to-snowflake-scripting/README.md) - The assignment statement sets the value of a data item to a valid value. (Oracle PL/SQL Language Reference ASSIGNMENT Statement)
- [SnowConvert AI - Oracle - COLLECTIONS AND RECORDS | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/pl-sql-to-snowflake-scripting/collections-and-records.html.md) - Translation reference to convert Oracle COLLECTIONS and RECORDS to Snowflake Scripting
- [SnowConvert AI - Oracle - COLLECTIONS AND RECORDS | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/pl-sql-to-snowflake-scripting/collections-and-records.md) - Translation reference to convert Oracle COLLECTIONS and RECORDS to Snowflake Scripting
- [SnowConvert AI - Oracle - CREATE FUNCTION | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/pl-sql-to-snowflake-scripting/create-function.md) - Oracle Create Function to Snowflake Snow Scripting
- [SnowConvert AI - Oracle - CREATE PROCEDURE | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/pl-sql-to-snowflake-scripting/create-procedure.md) - Oracle Create Procedure to Snowflake Snow Scripting
- [SnowConvert AI - Oracle - CURSOR | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/pl-sql-to-snowflake-scripting/cursor.md) - Danger
- [SnowConvert AI - Oracle - DML STATEMENTS | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/pl-sql-to-snowflake-scripting/dml-statements.md) - DML statement extensions differ from normal DML statements because they can use PL/SQL elements like collections and records. So far some of these elements are not supported by snowflake scripting. If
- [SnowConvert AI - Oracle - HELPERS | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/pl-sql-to-snowflake-scripting/helpers.html.md) - In this section you will find helper functions or procedures that are used to achieve functional equivalence of some Oracle features that are not supported natively in Snowflake Scripting.
- [SnowConvert AI - Oracle - HELPERS | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/pl-sql-to-snowflake-scripting/helpers.md) - In this section you will find helper functions or procedures that are used to achieve functional equivalence of some Oracle features that are not supported natively in Snowflake Scripting.
- [SnowConvert AI - Oracle - PACKAGES | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/pl-sql-to-snowflake-scripting/packages.md) - Use the CREATE PACKAGE statement to create the specification for a stored package, which is an encapsulated collection of related procedures, functions, and other program objects stored together in th
- [SnowConvert AI - Oracle - Pseudocolumns | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/pseudocolumns.md) - Translation spec for ROWID pseudocolumn
- [SnowConvert AI - Oracle - Sample data | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/sample-data.md) - Sample data used in examples
- [SnowConvert AI - Oracle - SQL*Plus | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/sql-plus.md) - This is a translation reference to convert SQL Plus statements to SnowSQL (CLI Client)
- [SnowConvert AI - Oracle - Joins | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/sql-queries-and-subqueries/joins.md) - A join is a query that combines rows from two or more tables, views, or materialized views. Oracle Database performs a join whenever multiple tables appear in the FROM clause of the query. (Oracle SQL
- [SnowConvert AI - Oracle - Select | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/sql-queries-and-subqueries/selects.md) - In this section you could find information about the select query syntax and its convertions.
- [SnowConvert AI - Oracle - SQL Statements | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/sql-translation-reference/README.html.md) - This document details all the similarities, differences in SQL syntax and how SnowConvert AI would translate those SQL syntaxes into a functional Snowflake SQL Syntax.
- [SnowConvert AI - Oracle - SQL Statements | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/sql-translation-reference/README.md) - This document details all the similarities, differences in SQL syntax and how SnowConvert AI would translate those SQL syntaxes into a functional Snowflake SQL Syntax.
- [SnowConvert AI - Oracle - Create Materialized Views | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/sql-translation-reference/create-materialized-view.md) - Translation reference to convert Oracle Materialized View to Snowflake Dynamic Table
- [SnowConvert AI - Oracle - Create Table | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/sql-translation-reference/create-table.md) - In this section you could find information about TABLES, their syntax and current convertions.
- [SnowConvert AI - Oracle - Create View | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/sql-translation-reference/create-view.md) - In this section, you could find information about Oracle Views and their Snowflake equivalent. The syntax of subquery used to create the view can be found in the SELECT section
- [SnowConvert AI - Oracle - Create Type | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/sql-translation-reference/create_type.html.md) - This is a translation reference to convert Oracle Create Type Statements (UDT’s) to snowflake
- [SnowConvert AI - Oracle - Create Type | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/sql-translation-reference/create_type.md) - This is a translation reference to convert Oracle Create Type Statements (UDT’s) to snowflake
- [SnowConvert AI - Oracle - Wrapped objects | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/oracle/wrapped-objects.md) - Input code can contain wrapped objects depending of the extraction tool used to produce it. Encrypted code will be exported as a “nonsense” group of characters which are preceded with the “wrapped” wo
- [SnowConvert AI - PostgreSQL-Greenplum-Netezza | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/postgres/README.md) - This documentation serves as a comprehensive resource, providing detailed information on both PostgreSQL and the SQL languages derived from it, specifically:
- [SnowConvert AI - Netezza - Data types | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/postgres/data-types/netezza-data-types.md) - Current Data types conversion for Netezza to Snowflake.
- [SnowConvert AI - PostgreSQL - Data types | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/postgres/data-types/postgresql-data-types.md) - Current Data types conversion for PostgreSQL to Snowflake.
- [SnowConvert AI - Greenplum - CREATE MATERIALIZED VIEW | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/postgres/ddls/create-materialized-view/greenplum-create-materialized-view.md) - Translation from Greenplum to Snowflake
- [SnowConvert AI - PostgreSQL - CREATE MATERIALIZED VIEW | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/postgres/ddls/create-materialized-view/postgresql-create-materialized-view.md) - Translation reference to convert PostgreSQL Materialized View to Snowflake Dynamic Table
- [SnowConvert AI - Greenplum - CREATE TABLE | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/postgres/ddls/create-table/greenplum-create-table.md) - Translation from Greenplum to Snowflake
- [SnowConvert AI - Netezza - CREATE TABLE | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/postgres/ddls/create-table/netezza-create-table.md) - Translation from Netezza to Snowflake
- [SnowConvert AI - PostgreSQL - CREATE TABLE | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/postgres/ddls/create-table/postgresql-create-table.md) - Translation from PostgreSql to Snowflake
- [SnowConvert AI - PostgreSQL - CREATE VIEW | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/postgres/ddls/postgresql-create-view.md) - Translation from PostgreSQL to Snowflake
- [SnowConvert AI - PostgreSQL - Power BI Repointing | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/postgres/etl-bi-repointing/power-bi-postgres-repointing.md) - The Power BI repointing is a feature that provides an easy way to redefine the connections from the M language in the Power Query Editor. This means that the connection parameters will be redefined to
- [SnowConvert AI - PostgreSQL - Built-in functions | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/postgres/postgresql-built-in-functions.md) - PostgreSQL
- [SnowConvert AI - PostgreSQL - Expressions | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/postgres/postgresql-expressions.md) - <> ALL & = ANY array expressions
- [SnowConvert AI - PostgreSQL - PostgreSQL interactive terminal | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/postgres/postgresql-interactive-terminal.md) - PSQL commands
- [SnowConvert AI - PostgreSQL - String Comparison | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/postgres/postgresql-string-comparison.md) - In PostgreSQL and PostgreSQL-based languages (Greenplum, RedShift, Netezza), when comparing fixed-length data types (CHAR, CHARACTER, etc) or comparing fixed-length data types against varchar data typ
- [SnowConvert AI - Redshift | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/redshift/README.md) - Translation specification for Redshift grammar syntax
- [SnowConvert AI - Redshift - Power BI Repointing | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/redshift/etl-bi-repointing/power-bi-redshift-repointing.md) - The Power BI repointing is a feature that provides an easy way to redefine the connections from the M language in the Power Query Editor. This means that the connection parameters will be redefined to
- [SnowConvert AI - Redshift - Literals | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/redshift/redshift-basic-elements-literals.md) - A literal or constant is a fixed data value, composed of a sequence of characters or a numeric constant. (Redshift SQL Language reference Literals).
- [SnowConvert AI - Redshift - Basic elements | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/redshift/redshift-basic-elements.html.md) - Names and identifiers translation for Redshift
- [SnowConvert AI - Redshift - Basic elements | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/redshift/redshift-basic-elements.md) - Names and identifiers translation for Redshift
- [SnowConvert AI - Redshift - Conditions | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/redshift/redshift-conditions.md) - A BETWEEN condition tests expressions for inclusion in a range of values, using the keywords BETWEEN and AND. (Redshift SQL Language Reference BETWEEN condition)
- [SnowConvert AI - Redshift - CONTINUE HANDLER | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/redshift/redshift-continue-handler.md) - Amazon Redshift, which uses PL/pgSQL for procedural logic, does not have a native DECLARE CONTINUE HANDLER statement in the same way as systems like DB2 or Teradata. In Redshift, exception handling is
- [SnowConvert AI - Redshift - Data types | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/redshift/redshift-data-types.md) - Current Data types conversion for Redshift in SnowConvert AI.
- [SnowConvert AI - Redshift - EXIT HANDLER | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/redshift/redshift-exit-handler.md) - Amazon Redshift, which uses PL/pgSQL for procedural logic, supports EXIT handlers in stored procedures through EXCEPTION blocks. An EXIT handler terminates the current block when a specific condition 
- [SnowConvert AI - Redshift - Expressions | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/redshift/redshift-expressions.md) - An expression list is a combination of expressions, and can appear in membership and comparison conditions (WHERE clauses) and in GROUP BY clauses. (Redshift SQL Language Reference Expression lists).
- [SnowConvert AI - Redshift - Built-in functions | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/redshift/redshift-functions.html.md) - Note
- [SnowConvert AI - Redshift - Built-in functions | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/redshift/redshift-functions.md) - Note
- [SnowConvert AI - Redshift - CREATE TABLE AS | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/redshift/redshift-sql-statements-create-table-as.md) - Create Table As Syntax Grammar.
- [SnowConvert AI - Redshift - CREATE TABLE | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/redshift/redshift-sql-statements-create-table.html.md) - Create Table Syntax Grammar.
- [SnowConvert AI - Redshift - CREATE TABLE | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/redshift/redshift-sql-statements-create-table.md) - Create Table Syntax Grammar.
- [SnowConvert AI - Redshift - SQL Statements | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/redshift/redshift-sql-statements.md) - Translation reference for all the supported statements by SnowConvert AI for Redshift.
- [SnowConvert AI - Redshift - System catalog tables | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/redshift/redshift-system-catalog.md) - Note
- [SnowConvert AI - Redshift - CREATE PROCEDURE | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/redshift/rs-sql-statements-create-procedure.html.md) - Creates a new stored procedure or replaces an existing procedure for the current database. (Redshift SQL Language Reference Create Procedure).
- [SnowConvert AI - Redshift - CREATE PROCEDURE | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/redshift/rs-sql-statements-create-procedure.md) - Creates a new stored procedure or replaces an existing procedure for the current database. (Redshift SQL Language Reference Create Procedure).
- [SnowConvert AI - Redshift - SELECT INTO | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/redshift/rs-sql-statements-select-into.md) - Returns rows from tables, views, and user-defined functions and inserts them into a new table. (Redshift SQL Language Reference SELECT statement)
- [SnowConvert AI - Redshift - SELECT | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/redshift/rs-sql-statements-select.html.md) - Returns rows from tables, views, and user-defined functions. (Redshift SQL Language Reference SELECT statement)
- [SnowConvert AI - Redshift - SELECT | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/redshift/rs-sql-statements-select.md) - Returns rows from tables, views, and user-defined functions. (Redshift SQL Language Reference SELECT statement)
- [SnowConvert AI - SSIS | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/ssis/README.md) - Preview Feature — Open
- [SnowConvert AI - Sybase IQ | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/sybase/README.md) - Translation specification for Sybase IQ grammar syntax
- [SnowConvert AI - Sybase IQ - Built-in functions | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/sybase/sybase-built-in-functions.md) - Note
- [SnowConvert AI - Sybase IQ - CREATE TABLE | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/sybase/sybase-create-table.md) - Creates a new table in the current database. You define a list of columns, which each hold data of a distinct type. The owner of the table is the issuer of the CREATE TABLE command.
- [SnowConvert AI - Sybase IQ - CREATE VIEW | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/sybase/sybase-create-view.md) - Creates a new view in the current database. You define a list of columns, which each hold data of a distinct type. The owner of the view is the issuer of the CREATE VIEW command.
- [SnowConvert AI - Sybase IQ - Data Types | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/sybase/sybase-data-types.md) - Snowflake supports most basic SQL data types (with some restrictions) for columns, local variables, expressions, parameters, and other appropriate/suitable locations.
- [SnowConvert AI - Sybase IQ - SELECT | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/sybase/sybase-select-statement.md) - Retrieves information from the database. (Sybase SQL Language Reference)
- [SnowConvert AI - Teradata | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/teradata/README.md) - Translation specification for Teradata grammar syntax
- [SnowConvert AI - Teradata - Data Migration Considerations | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/teradata/data-migration-considerations.md) - This section describe important consideration when migration data from Teradata to Snowflake.
- [SnowConvert AI - Teradata - Power BI Repointing | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/teradata/etl-bi-repointing/power-bi-teradata-repointing.md) - The Power BI repointing is a feature that provides an easy way to redefine the connections from the M language in the Power Query Editor. This means that the connection parameters will be redefined to
- [SnowConvert AI - Teradata - SnowConvert AI Procedures Helpers | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/teradata/helpers-for-procedures.html.md) - In this section you will find the helper functions used inside procedures that are used to achieve functional equivalence of some Teradata features that are not supported natively in Snowflake.
- [SnowConvert AI - Teradata - SnowConvert AI Procedures Helpers | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/teradata/helpers-for-procedures.md) - In this section you will find the helper functions used inside procedures that are used to achieve functional equivalence of some Teradata features that are not supported natively in Snowflake.
- [SnowConvert AI - Teradata - Scripts To Python Translation Reference | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/teradata/scripts-to-python/README.md) - This section details how Snow Convert translates the Teradata Scripts (BTEQ, FastLoad, MultiLoad, TPUMP, etc.) into a scripting language compatible with Snowflake.
- [SnowConvert AI - Teradata - BTEQ | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/teradata/scripts-to-python/bteq-translation.md) - Translation references to convert Teradata BTEQ files to Python
- [SnowConvert AI - Teradata - FLOAD | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/teradata/scripts-to-python/fastload-translation.md) - Translation references to convert Teradata FLOAD files to Python
- [SnowConvert AI - Teradata - MLOAD | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/teradata/scripts-to-python/multiload-translation.md) - Translation references to convert Teradata MLOAD files to Python
- [SnowConvert AI - Teradata - SnowConvert AI Scripts Helpers | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/teradata/scripts-to-python/snowconvert-script-helpers.md) - SnowConvert AI Helpers is a set of classes with functions designed to facilitate the conversion of Teradata script files to Python files that Snowflake can interpret.
- [SnowConvert AI - Teradata - TPT | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/teradata/scripts-to-python/tpt-translation.md) - This section illustrates TPT translation from Teradata to Snowflake.
- [SnowConvert AI - Teradata - Scripts to Snowflake SQL Translation Reference | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/teradata/scripts-to-snowflake-sql-translation-reference/README.md) - Translation reference to convert Teradata scripts files to Snowflake SQL
- [SnowConvert AI - Teradata - BTEQ | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/teradata/scripts-to-snowflake-sql-translation-reference/bteq.md) - Translation references to convert Teradata BTEQ files to Snowflake SQL
- [SnowConvert AI - Teradata - COMMON STATEMENTS | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/teradata/scripts-to-snowflake-sql-translation-reference/common-statements.md) - Translation references to convert Teradata script statements that are in common among all scripts syntaxes to Snowflake SQL
- [SnowConvert AI - Teradata - MLOAD | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/teradata/scripts-to-snowflake-sql-translation-reference/mload.md) - Translation references to convert Teradata MLOAD files to Snowflake SQL
- [SnowConvert AI - Teradata - Session Modes in Teradata | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/teradata/session-modes.md) - The Teradata database has different modes for running queries: ANSI Mode (rules based on the ANSI SQL: 2011 specifications) and TERA mode (rules defined by Teradata). Please review the following Terad
- [SnowConvert AI - Teradata - Iceberg Tables Transformations | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/teradata/sql-translation-reference/Iceberg-tables-transformations.md) - This section covers the transformation of tables into Snowflake-managed Iceberg tables, performed by SnowConvert AI when the conversion setting Table Translation is used.
- [SnowConvert AI - Teradata - SQL Translation Reference | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/teradata/sql-translation-reference/README.md) - This section provides information about the translation that SnowConvert AI performs, over Teradata SQL Syntax to Snowflake.
- [ANALYTIC | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/teradata/sql-translation-reference/analytic.md) - In this section, you will find the documentation for the translation reference of Analytic Language Elements.
- [SnowConvert AI - Teradata - Data Types | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/teradata/sql-translation-reference/data-types.md) - This section shows equivalents between data types in Teradata and in Snowflake.
- [SnowConvert AI - Teradata - Database DBC | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/teradata/sql-translation-reference/database-dbc.md) - Equivalents for DBC objects and columns
- [SnowConvert AI - Teradata - DDL | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/teradata/sql-translation-reference/ddl-teradata.md) - In this section, you will find the documentation for the translation reference of Data Definition Language Elements.
- [SnowConvert AI - Teradata - DML | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/teradata/sql-translation-reference/dml-teradata.md) - In this section, you will find the documentation for the translation reference of Data Manipulation Language Elements.
- [SnowConvert AI - Teradata - Built-in Functions | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/teradata/sql-translation-reference/teradata-built-in-functions.md) - This page provides a description of the translation for the built-in functions in Teradata to Snowflake
- [SnowConvert AI - Teradata - SQL to JavaScript (Procedures) | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/teradata/teradata-to-javascript-translation-reference.md) - Translation reference to convert Teradata GET DIAGNOSTICS EXCEPTION statement to Snowflake Scripting
- [SnowConvert AI - Teradata - SQL to Snowflake Scripting (Procedures) | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/teradata/teradata-to-snowflake-scripting-translation-reference.html.md) - Translation reference to convert Teradata ABORT and ROLLBACK statements to Snowflake Scripting
- [SnowConvert AI - Teradata - SQL to Snowflake Scripting (Procedures) | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/teradata/teradata-to-snowflake-scripting-translation-reference.md) - Translation reference to convert Teradata ABORT and ROLLBACK statements to Snowflake Scripting
- [SnowConvert AI - SQL Server-Azure Synapse | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/transact/README.md) - This page provides a comprehensive reference for how SnowConvert AI translates Transact grammar elements to Snowflake equivalents. In this translation reference, you will find code examples, functiona
- [SnowConvert AI - Transact - Power BI Repointing | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/transact/etl-bi-repointing/power-bi-transact-repointing.md) - SQL Server
- [SnowConvert AI - SQL Server-Azure Synapse - ALTER | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/transact/transact-alter-statement.md) - Translation reference for all the DDL statements that are preceded by the ALTER keyword.
- [SnowConvert AI - SQL Server-Azure Synapse - ANSI_NULLS | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/transact/transact-ansi-nulls.md) - SQL Server
- [SnowConvert AI - SQL Server-Azure Synapse - Built-in functions | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/transact/transact-built-in-functions.md) - SQL Server
- [SnowConvert AI - SQL Server-Azure Synapse - Built-in procedures | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/transact/transact-built-in-procedures.md) - SQL Server
- [SnowConvert AI - SQL Server-Azure Synapse - CONTINUE HANDLER | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/transact/transact-continue-handler.md) - In SQL Server and Azure Synapse Analytics, exception handling is primarily managed through TRY...CATCH blocks. Unlike some other database systems (such as Teradata or DB2), SQL Server does not have a 
- [SnowConvert AI - SQL Server - CREATE FUNCTION | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/transact/transact-create-function.md) - Translation reference for the Transact-SQL User Defined Functions
- [SnowConvert AI - SQL Server-Azure Synapse - CREATE INDEX | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/transact/transact-create-index.md) - Translation reference to convert CREATE INDEX statement to Snowflake
- [SnowConvert AI - SQL Server-Azure Synapse - Materialized View | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/transact/transact-create-materialized-view.md) - Translation reference to convert Materialized View to Snowflake Dynamic Table
- [SnowConvert AI - SQL Server-Azure Synapse - CREATE PROCEDURE (Snowflake Scripting) | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/transact/transact-create-procedure-snow-script.html.md) - Translation reference to convert Transact-SQL BEGIN and COMMIT transaction to Snowflake SQL
- [SnowConvert AI - SQL Server-Azure Synapse - CREATE PROCEDURE (Snowflake Scripting) | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/transact/transact-create-procedure-snow-script.md) - Translation reference to convert Transact-SQL BEGIN and COMMIT transaction to Snowflake SQL
- [SnowConvert AI - SQL Server-Azure Synapse - Procedures | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/transact/transact-create-procedure.html.md) - This section documents the transformation of the syntax and the procedure’s TSQL statements to snowflake javascript
- [SnowConvert AI - SQL Server-Azure Synapse - Procedures | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/transact/transact-create-procedure.md) - This section documents the transformation of the syntax and the procedure’s TSQL statements to snowflake javascript
- [SnowConvert AI - SQL Server-Azure Synapse - CREATE TABLE | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/transact/transact-create-table.md) - SQL Server
- [SnowConvert AI - SQL Server-Azure Synapse - Views | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/transact/transact-create-view.md) - SQL Server
- [SnowConvert AI - SQL Server-Azure Synapse - Data Types | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/transact/transact-data-types.md) - Snowflake supports most basic SQL data types (with some restrictions) for use in columns, local variables, expressions, parameters, and any other appropriate/suitable locations.
- [SnowConvert AI - SQL Server-Azure Synapse - DMLs | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/transact/transact-dmls.html.md) - Returns TRUE when the input expression (numeric or string) is within the specified lower and upper boundary.
- [SnowConvert AI - SQL Server-Azure Synapse - DMLs | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/transact/transact-dmls.md) - Returns TRUE when the input expression (numeric or string) is within the specified lower and upper boundary.
- [SnowConvert AI - SQL Server-Azure Synapse - EXIT HANDLER | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/transact/transact-exit-handler.md) - In SQL Server and Azure Synapse Analytics, exception handling is primarily managed through TRY...CATCH blocks. Unlike some other database systems (such as Teradata or DB2), SQL Server does not have a 
- [SnowConvert AI - SQL Server-Azure Synapse - General Language Elements | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/transact/transact-general-statements.html.md) - In this section you could find information about general statements of Transact-SQL.
- [SnowConvert AI - SQL Server-Azure Synapse - General Language Elements | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/transact/transact-general-statements.md) - In this section you could find information about general statements of Transact-SQL.
- [SnowConvert AI - SQL Server-Azure Synapse - QUOTED_IDENTIFIER | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/transact/transact-quoted-identifier.md) - SQL Server
- [SnowConvert AI - SQL Server-Azure Synapse - SELECT | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/transact/transact-select.md) - Translation reference for SELECT statement inside procedures in Transact-SQL.
- [SnowConvert AI - SQL Server-Azure Synapse - System Tables | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/transact/transact-system-tables.md) - Translation spec for Transact-SQL System Tables
- [SnowConvert AI - Vertica | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/vertica/README.md) - Conversion Scope
- [SnowConvert AI - Vertica - Built-in functions | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/vertica/vertica-built-in-functions.md) - Functions return information from the database. This section describes functions that Vertica supports. Except for meta-functions, you can use a function anywhere an expression is allowed. (Vertica SQ
- [SnowConvert AI - Vertica - CREATE TABLE | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/vertica/vertica-create-table.md) - Creates a table in the logical schema. (Vertica SQL Language Reference Create Table).
- [SnowConvert AI - Vertica - CREATE VIEW | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/vertica/vertica-create-view.md) - Creates a new view. (Vertica SQL Language Reference Create view statement)
- [SnowConvert AI - Vertica - Data types | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/vertica/vertica-data-types.md) - Snowflake supports most basic SQL data types (with some restrictions) for use in columns, local variables, expressions, parameters, and any other appropriate/suitable locations.
- [SnowConvert AI - Vertica - Identifier differences between Vertica and Snowflake | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/vertica/vertica-identifier-between-vertica-and-snowflake.md) - In Vertica, quoted identifiers sticks to the case sensitivity rules, which means that, for example, column names are still case insensitive even when quoted. Thus, identifiers "ABC", "ABc", and "aBc" 
- [SnowConvert AI - Vertica - Operators | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/vertica/vertica-operators.md) - Vertica Operators
- [SnowConvert AI - Vertica - Predicates | Snowflake Documentation](en/migrations/snowconvert-docs/translation-references/vertica/vertica-predicates.md) - An expression used to evaluate and compare each element of an array against a specified expression. (Vertica Language Reference ANY & ALL (array))
- [Reference | Snowflake Documentation](en/reference.md) - Reference information on various areas of Snowflake.
- [SQL command reference | Snowflake Documentation](en/sql-reference-commands.md) - These topics provide reference information for all the Snowflake SQL commands (DDL, DML, and query syntax).
- [CORTEX_FUNCTIONS_USAGE_HISTORY view | Snowflake Documentation](en/sql-reference/account-usage/cortex_functions_usage_history.md) - ACCOUNT_USAGE
- [Collation support | Snowflake Documentation](en/sql-reference/collation.md) - Collation allows you to specify alternative rules for comparing text strings, which can be used to compare and sort data according to a particular language or other user-specified rules.
- [Overview of Constraints | Snowflake Documentation](en/sql-reference/constraints-overview.md) - Snowflake provides the following constraint functionality:
- [Constraints | Snowflake Documentation](en/sql-reference/constraints.md) - Constraints define integrity and consistency rules for data stored in tables. Snowflake provides support for constraints as defined in the ANSI SQL standard, as well as some extensions for compatibili
- [AT | BEFORE | Snowflake Documentation](en/sql-reference/constructs/at-before.md) - Query syntax
- [CONNECT BY | Snowflake Documentation](en/sql-reference/constructs/connect-by.md) - Query syntax
- [GROUP BY CUBE | Snowflake Documentation](en/sql-reference/constructs/group-by-cube.md) - Query syntax
- [GROUP BY GROUPING SETS | Snowflake Documentation](en/sql-reference/constructs/group-by-grouping-sets.md) - Query syntax
- [GROUP BY ROLLUP | Snowflake Documentation](en/sql-reference/constructs/group-by-rollup.md) - Query syntax
- [GROUP BY | Snowflake Documentation](en/sql-reference/constructs/group-by.md) - Query syntax
- [HAVING | Snowflake Documentation](en/sql-reference/constructs/having.md) - Query syntax
- [INTO | Snowflake Documentation](en/sql-reference/constructs/into.md) - Query syntax
- [JOIN | Snowflake Documentation](en/sql-reference/constructs/join.html.md) - Query syntax
- [JOIN | Snowflake Documentation](en/sql-reference/constructs/join.md) - Query syntax
- [LIMIT / FETCH | Snowflake Documentation](en/sql-reference/constructs/limit.md) - Query syntax
- [ORDER BY | Snowflake Documentation](en/sql-reference/constructs/order-by.md) - Query syntax
- [QUALIFY | Snowflake Documentation](en/sql-reference/constructs/qualify.md) - Query syntax
- [SAMPLE / TABLESAMPLE | Snowflake Documentation](en/sql-reference/constructs/sample.md) - Query syntax
- [TOP <n> | Snowflake Documentation](en/sql-reference/constructs/top_n.md) - Query syntax
- [VALUES | Snowflake Documentation](en/sql-reference/constructs/values.md) - Query syntax
- [WHERE | Snowflake Documentation](en/sql-reference/constructs/where.html.md) - Query syntax
- [WITH | Snowflake Documentation](en/sql-reference/constructs/with.html.md) - Query syntax
- [WITH | Snowflake Documentation](en/sql-reference/constructs/with.md) - Query syntax
- [Date & time data types | Snowflake Documentation](en/sql-reference/data-types-datetime.html.md) - Snowflake supports data types for managing dates, times, and timestamps (combined date + time). Snowflake also supports formats for string constants used in manipulating dates, times, and timestamps.
- [Date & time data types | Snowflake Documentation](en/sql-reference/data-types-datetime.md) - Snowflake supports data types for managing dates, times, and timestamps (combined date + time). Snowflake also supports formats for string constants used in manipulating dates, times, and timestamps.
- [Geospatial data types | Snowflake Documentation](en/sql-reference/data-types-geospatial.html.md) - Snowflake offers native support for geospatial features such as points, lines, and polygons on the Earth’s surface.
- [Geospatial data types | Snowflake Documentation](en/sql-reference/data-types-geospatial.md) - Snowflake offers native support for geospatial features such as points, lines, and polygons on the Earth’s surface.
- [Logical data types | Snowflake Documentation](en/sql-reference/data-types-logical.md) - This topic describes the logical data types supported in Snowflake.
- [Numeric data types | Snowflake Documentation](en/sql-reference/data-types-numeric.html.md) - This topic describes the numeric data types supported in Snowflake, along with the supported formats for numeric constants and literals.
- [Numeric data types | Snowflake Documentation](en/sql-reference/data-types-numeric.md) - This topic describes the numeric data types supported in Snowflake, along with the supported formats for numeric constants and literals.
- [Semi-structured data types | Snowflake Documentation](en/sql-reference/data-types-semistructured.html.md) - The following Snowflake data types can contain other data types:
- [Semi-structured data types | Snowflake Documentation](en/sql-reference/data-types-semistructured.md) - The following Snowflake data types can contain other data types:
- [String & binary data types | Snowflake Documentation](en/sql-reference/data-types-text.html.md) - This topic describes the string/text data types, including binary strings, supported in Snowflake, along with the supported formats for string constants/literals.
- [String & binary data types | Snowflake Documentation](en/sql-reference/data-types-text.md) - This topic describes the string/text data types, including binary strings, supported in Snowflake, along with the supported formats for string constants/literals.
- [Unsupported data types | Snowflake Documentation](en/sql-reference/data-types-unsupported.html.md) - Snowflake doesn’t support the following data types:
- [SQL data types reference | Snowflake Documentation](en/sql-reference/data-types.html.md) - Snowflake supports most basic SQL data types (with some restrictions) for use in columns, local variables, expressions, parameters, and any other appropriate locations.
- [Date and time input and output formats | Snowflake Documentation](en/sql-reference/date-time-input-output.html.md) - Date and time formats provide a method for representing dates, times, and timestamps.
- [Date and time input and output formats | Snowflake Documentation](en/sql-reference/date-time-input-output.md) - Date and time formats provide a method for representing dates, times, and timestamps.
- [Window functions | Snowflake Documentation](en/sql-reference/functions-analytic.html.md) - Window functions are analytic functions that you can use for various calculations such as running totals, moving averages, and rankings.
- [Context functions | Snowflake Documentation](en/sql-reference/functions-context.html.md) - This family of functions allows for the gathering of information about the context in which the statement is executed. These functions are evaluated at most once per statement.
- [Context functions | Snowflake Documentation](en/sql-reference/functions-context.md) - This family of functions allows for the gathering of information about the context in which the statement is executed. These functions are evaluated at most once per statement.
- [Conversion functions | Snowflake Documentation](en/sql-reference/functions-conversion.md) - This family of functions can be used to convert an expression of any Snowflake data type to another data type.
- [Date & time functions | Snowflake Documentation](en/sql-reference/functions-date-time.md) - This family of functions can be used to construct, convert, extract, or modify date, time, and timestamp data.
- [File functions | Snowflake Documentation](en/sql-reference/functions-file.html.md) - File functions enable you to access files staged in cloud storage.
- [String functions (regular expressions) | Snowflake Documentation](en/sql-reference/functions-regexp.html.md) - These string functions perform operations that match a regular expression (often referred to as a “regex”).
- [String functions (regular expressions) | Snowflake Documentation](en/sql-reference/functions-regexp.md) - These string functions perform operations that match a regular expression (often referred to as a “regex”).
- [ABS | Snowflake Documentation](en/sql-reference/functions/abs.html.md) - Numeric functions (Rounding and Truncation)
- [ACOS | Snowflake Documentation](en/sql-reference/functions/acos.md) - Numeric functions (Trigonometric)
- [ACOSH | Snowflake Documentation](en/sql-reference/functions/acosh.md) - Numeric functions (Trigonometric)
- [ADD_MONTHS | Snowflake Documentation](en/sql-reference/functions/add_months.md) - Date & time functions
- [AI_TRANSLATE | Snowflake Documentation](en/sql-reference/functions/ai_translate.md) - String & binary functions (AI Functions)
- [APPROX_TOP_K_ESTIMATE | Snowflake Documentation](en/sql-reference/functions/approx_top_k_estimate.md) - Aggregate functions (Frequency Estimation) , Window function syntax and usage
- [ARRAY_AGG | Snowflake Documentation](en/sql-reference/functions/array_agg.md) - Aggregate functions (Semi-structured Data) , Window functions (General) , Semi-structured and structured data functions (Array/Object)
- [ARRAY_CAT | Snowflake Documentation](en/sql-reference/functions/array_cat.md) - Semi-structured and structured data functions (Array/Object)
- [ARRAY_COMPACT | Snowflake Documentation](en/sql-reference/functions/array_compact.html.md) - Semi-structured and structured data functions (Array/Object)
- [ARRAY_CONTAINS | Snowflake Documentation](en/sql-reference/functions/array_contains.html.md) - Semi-structured and structured data functions (Array/Object)
- [ARRAY_FLATTEN | Snowflake Documentation](en/sql-reference/functions/array_flatten.md) - Semi-structured and structured data functions (Array/Object)
- [ARRAY_SIZE | Snowflake Documentation](en/sql-reference/functions/array_size.html.md) - Semi-structured and structured data functions (Array/Object)
- [ARRAY_SIZE | Snowflake Documentation](en/sql-reference/functions/array_size.md) - Semi-structured and structured data functions (Array/Object)
- [ARRAY_SLICE | Snowflake Documentation](en/sql-reference/functions/array_slice.html.md) - Semi-structured and structured data functions (Array/Object)
- [ARRAY_SLICE | Snowflake Documentation](en/sql-reference/functions/array_slice.md) - Semi-structured and structured data functions (Array/Object)
- [ARRAY_TO_STRING | Snowflake Documentation](en/sql-reference/functions/array_to_string.md) - Semi-structured and structured data functions (Array/Object)
- [AS_TIMESTAMP_* | Snowflake Documentation](en/sql-reference/functions/as_timestamp.md) - Semi-structured and structured data functions (Cast)
- [ASIN | Snowflake Documentation](en/sql-reference/functions/asin.md) - Numeric functions (Trigonometric)
- [AVG | Snowflake Documentation](en/sql-reference/functions/avg.html.md) - Aggregate functions (General) , Window functions (General, Window Frame)
- [BASE64_ENCODE | Snowflake Documentation](en/sql-reference/functions/base64_encode.md) - String & binary functions (Encoding/Decoding)
- [BIT_LENGTH | Snowflake Documentation](en/sql-reference/functions/bit_length.md) - String & binary functions (General)
- [BITAND | Snowflake Documentation](en/sql-reference/functions/bitand.md) - Bitwise expression functions
- [BITNOT | Snowflake Documentation](en/sql-reference/functions/bitnot.md) - Bitwise expression functions
- [BITOR | Snowflake Documentation](en/sql-reference/functions/bitor.md) - Bitwise expression functions
- [BITSHIFTLEFT | Snowflake Documentation](en/sql-reference/functions/bitshiftleft.md) - Bitwise expression functions
- [BITSHIFTRIGHT | Snowflake Documentation](en/sql-reference/functions/bitshiftright.md) - Bitwise expression functions
- [BITXOR | Snowflake Documentation](en/sql-reference/functions/bitxor.md) - Bitwise expression functions
- [BOOLAND_AGG | Snowflake Documentation](en/sql-reference/functions/booland_agg.md) - Aggregate functions (Boolean) , Window functions , Conditional expression functions
- [BOOLOR_AGG | Snowflake Documentation](en/sql-reference/functions/boolor_agg.md) - Aggregate functions (Boolean) , Window functions , Conditional expression functions
- [BUILD_STAGE_FILE_URL | Snowflake Documentation](en/sql-reference/functions/build_stage_file_url.html.md) - File functions
- [CASE | Snowflake Documentation](en/sql-reference/functions/case.html.md) - Conditional expression functions
- [CASE | Snowflake Documentation](en/sql-reference/functions/case.md) - Conditional expression functions
- [CAST , :: | Snowflake Documentation](en/sql-reference/functions/cast.html.md) - Conversion functions
- [CAST , :: | Snowflake Documentation](en/sql-reference/functions/cast.md) - Conversion functions
- [CHARINDEX | Snowflake Documentation](en/sql-reference/functions/charindex.html.md) - String & binary functions (Matching/Comparison)
- [CHR , CHAR | Snowflake Documentation](en/sql-reference/functions/chr.html.md) - String & binary functions (General)
- [COALESCE | Snowflake Documentation](en/sql-reference/functions/coalesce.html.md) - Conditional expression functions
- [COALESCE | Snowflake Documentation](en/sql-reference/functions/coalesce.md) - Conditional expression functions
- [COLLATE | Snowflake Documentation](en/sql-reference/functions/collate.md) - String & binary functions
- [COMPLETE (SNOWFLAKE.CORTEX) | Snowflake Documentation](en/sql-reference/functions/complete-snowflake-cortex.md) - String & binary functions (AI Functions)
- [CONCAT , || | Snowflake Documentation](en/sql-reference/functions/concat.html.md) - String & binary functions (General)
- [CONDITIONAL_CHANGE_EVENT | Snowflake Documentation](en/sql-reference/functions/conditional_change_event.md) - Window functions (General)
- [CONDITIONAL_TRUE_EVENT | Snowflake Documentation](en/sql-reference/functions/conditional_true_event.md) - Window functions (General)
- [CONVERT_TIMEZONE | Snowflake Documentation](en/sql-reference/functions/convert_timezone.html.md) - Date & time functions
- [CONVERT_TIMEZONE | Snowflake Documentation](en/sql-reference/functions/convert_timezone.md) - Date & time functions
- [COS | Snowflake Documentation](en/sql-reference/functions/cos.md) - Numeric functions (Trigonometric)
- [COSH | Snowflake Documentation](en/sql-reference/functions/cosh.md) - Numeric functions (Trigonometric)
- [COUNT | Snowflake Documentation](en/sql-reference/functions/count.md) - Aggregate functions (General) , Window functions
- [COUNT_IF | Snowflake Documentation](en/sql-reference/functions/count_if.md) - Aggregate functions (General) , Window functions
- [COVAR_POP | Snowflake Documentation](en/sql-reference/functions/covar_pop.md) - Aggregate functions (General) , Window functions (General)
- [CURRENT_DATABASE | Snowflake Documentation](en/sql-reference/functions/current_database.html.md) - Context functions (Session Object)
- [CURRENT_DATABASE | Snowflake Documentation](en/sql-reference/functions/current_database.md) - Context functions (Session Object)
- [CURRENT_DATE | Snowflake Documentation](en/sql-reference/functions/current_date.md) - Context functions (General)
- [CURRENT_ORGANIZATION_USER | Snowflake Documentation](en/sql-reference/functions/current_organization_user.md) - Context functions (Session)
- [CURRENT_SECONDARY_ROLES | Snowflake Documentation](en/sql-reference/functions/current_secondary_roles.md) - Context functions (Session Object)
- [CURRENT_TIMESTAMP | Snowflake Documentation](en/sql-reference/functions/current_timestamp.html.md) - Context functions (General)
- [CURRENT_VERSION | Snowflake Documentation](en/sql-reference/functions/current_version.md) - Context functions (General)
- [DATASKETCHES_HLL_ACCUMULATE | Snowflake Documentation](en/sql-reference/functions/datasketches_hll_accumulate.md) - Aggregate functions (Cardinality Estimation) , Window function syntax and usage
- [DATE_FROM_PARTS | Snowflake Documentation](en/sql-reference/functions/date_from_parts.html.md) - Date & time functions
- [DATE_FROM_PARTS | Snowflake Documentation](en/sql-reference/functions/date_from_parts.md) - Date & time functions
- [DATE_PART | Snowflake Documentation](en/sql-reference/functions/date_part.html.md) - Date & time functions
- [DATE_PART | Snowflake Documentation](en/sql-reference/functions/date_part.md) - Date & time functions
- [DATE_TRUNC | Snowflake Documentation](en/sql-reference/functions/date_trunc.md) - Date & time functions
- [DATEADD | Snowflake Documentation](en/sql-reference/functions/dateadd.html.md) - Date & time functions
- [DATEADD | Snowflake Documentation](en/sql-reference/functions/dateadd.md) - Date & time functions
- [DATEDIFF | Snowflake Documentation](en/sql-reference/functions/datediff.html.md) - Date & time functions
- [DATEDIFF | Snowflake Documentation](en/sql-reference/functions/datediff.md) - Date & time functions
- [DENSE_RANK | Snowflake Documentation](en/sql-reference/functions/dense_rank.html.md) - Window function syntax and usage (Ranking)
- [ENCRYPT | Snowflake Documentation](en/sql-reference/functions/encrypt.md) - Encryption functions
- [ENDSWITH | Snowflake Documentation](en/sql-reference/functions/endswith.md) - String & binary functions (Matching/Comparison)
- [EXTRACT | Snowflake Documentation](en/sql-reference/functions/extract.html.md) - Date & time functions
- [EXTRACT | Snowflake Documentation](en/sql-reference/functions/extract.md) - Date & time functions
- [FIRST_VALUE | Snowflake Documentation](en/sql-reference/functions/first_value.md) - Window function syntax and usage (Ranking)
- [FLATTEN | Snowflake Documentation](en/sql-reference/functions/flatten.html.md) - Table functions , Semi-structured and structured data functions (Extraction)
- [FLATTEN | Snowflake Documentation](en/sql-reference/functions/flatten.md) - Table functions , Semi-structured and structured data functions (Extraction)
- [FLOOR | Snowflake Documentation](en/sql-reference/functions/floor.html.md) - Numeric functions (Rounding and Truncation)
- [GETDATE | Snowflake Documentation](en/sql-reference/functions/getdate.md) - Context functions (General)
- [GREATEST_IGNORE_NULLS | Snowflake Documentation](en/sql-reference/functions/greatest_ignore_nulls.md) - Conditional expression functions
- [GROUPING | Snowflake Documentation](en/sql-reference/functions/grouping.md) - Aggregate functions (General)
- [GROUPING_ID | Snowflake Documentation](en/sql-reference/functions/grouping_id.md) - Aggregate functions (General)
- [HASH | Snowflake Documentation](en/sql-reference/functions/hash.md) - Hash functions
- [HASH_AGG | Snowflake Documentation](en/sql-reference/functions/hash_agg.md) - Aggregate functions , Window functions
- [HEX_ENCODE | Snowflake Documentation](en/sql-reference/functions/hex_encode.md) - String & binary functions (Encoding/Decoding)
- [HLL_COMBINE | Snowflake Documentation](en/sql-reference/functions/hll_combine.md) - Aggregate functions (Cardinality Estimation) , Window function syntax and usage
- [HOUR / MINUTE / SECOND | Snowflake Documentation](en/sql-reference/functions/hour-minute-second.md) - Date & time functions
- [IFF | Snowflake Documentation](en/sql-reference/functions/iff.html.md) - Conditional expression functions
- [IFNULL | Snowflake Documentation](en/sql-reference/functions/ifnull.md) - Conditional expression functions
- [[ NOT ] ILIKE | Snowflake Documentation](en/sql-reference/functions/ilike.md) - String & binary functions (Matching/Comparison)
- [[ NOT ] IN | Snowflake Documentation](en/sql-reference/functions/in.md) - Conditional expression functions
- [INFER_SCHEMA | Snowflake Documentation](en/sql-reference/functions/infer_schema.md) - Table functions
- [INITCAP | Snowflake Documentation](en/sql-reference/functions/initcap.md) - String & binary functions (Case Conversion)
- [INSERT | Snowflake Documentation](en/sql-reference/functions/insert.md) - String & binary functions (General)
- [INTERPOLATE_BFILL, INTERPOLATE_FFILL, INTERPOLATE_LINEAR | Snowflake Documentation](en/sql-reference/functions/interpolate_bfill.md) - Window functions (General)
- [IS_ARRAY | Snowflake Documentation](en/sql-reference/functions/is_array.md) - Semi-structured and structured data functions (Type Predicates)
- [IS_BOOLEAN | Snowflake Documentation](en/sql-reference/functions/is_boolean.md) - Semi-structured and structured data functions (Type Predicates)
- [IS_GRANTED_TO_INVOKER_ROLE | Snowflake Documentation](en/sql-reference/functions/is_granted_to_invoker_role.md) - Context functions (Session Object)
- [JSON_EXTRACT_PATH_TEXT | Snowflake Documentation](en/sql-reference/functions/json_extract_path_text.md) - Semi-structured and structured data functions (Extraction)
- [KURTOSIS | Snowflake Documentation](en/sql-reference/functions/kurtosis.md) - Aggregate functions (General) , Window function syntax and usage
- [LAG | Snowflake Documentation](en/sql-reference/functions/lag.md) - Window function syntax and usage (Ranking)
- [LAST_QUERY_ID | Snowflake Documentation](en/sql-reference/functions/last_query_id.md) - Context functions (Session)
- [LAST_VALUE | Snowflake Documentation](en/sql-reference/functions/last_value.md) - Window function syntax and usage (Ranking)
- [LEAST_IGNORE_NULLS | Snowflake Documentation](en/sql-reference/functions/least_ignore_nulls.md) - Conditional expression functions
- [LEFT | Snowflake Documentation](en/sql-reference/functions/left.html.md) - String & binary functions (Matching/Comparison)
- [LENGTH, LEN | Snowflake Documentation](en/sql-reference/functions/length.html.md) - String & binary functions (General)
- [LISTAGG | Snowflake Documentation](en/sql-reference/functions/listagg.md) - Aggregate functions (General) , Window function syntax and usage (General)
- [LOCALTIME | Snowflake Documentation](en/sql-reference/functions/localtime.html.md) - Context functions (General)
- [LOWER | Snowflake Documentation](en/sql-reference/functions/lower.html.md) - String & binary functions (Case Conversion)
- [LPAD | Snowflake Documentation](en/sql-reference/functions/lpad.md) - String & binary functions (General)
- [MAX_BY | Snowflake Documentation](en/sql-reference/functions/max_by.md) - Aggregate functions (General)
- [MIN_BY | Snowflake Documentation](en/sql-reference/functions/min_by.md) - Aggregate functions (General)
- [MONTHS_BETWEEN | Snowflake Documentation](en/sql-reference/functions/months_between.html.md) - Date & time functions
- [MONTHS_BETWEEN | Snowflake Documentation](en/sql-reference/functions/months_between.md) - Date & time functions
- [NEXT_DAY | Snowflake Documentation](en/sql-reference/functions/next_day.md) - Date & time functions
- [NTH_VALUE | Snowflake Documentation](en/sql-reference/functions/nth_value.md) - Window function syntax and usage (Ranking)
- [NULLIF | Snowflake Documentation](en/sql-reference/functions/nullif.html.md) - Conditional expression functions
- [NVL | Snowflake Documentation](en/sql-reference/functions/nvl.html.md) - Conditional expression functions
- [OBJECT_CONSTRUCT | Snowflake Documentation](en/sql-reference/functions/object_construct.md) - Semi-structured and structured data functions (Array/Object)
- [OCTET_LENGTH | Snowflake Documentation](en/sql-reference/functions/octet_length.html.md) - String & binary functions (General)
- [PARSE_JSON | Snowflake Documentation](en/sql-reference/functions/parse_json.html.md) - Semi-structured and structured data functions (Parsing)
- [PARSE_JSON | Snowflake Documentation](en/sql-reference/functions/parse_json.md) - Semi-structured and structured data functions (Parsing)
- [PI | Snowflake Documentation](en/sql-reference/functions/pi.md) - Numeric functions (Trigonometric)
- [POSITION | Snowflake Documentation](en/sql-reference/functions/position.md) - String & binary functions (Matching/Comparison)
- [PREVIOUS_DAY | Snowflake Documentation](en/sql-reference/functions/previous_day.md) - Date & time functions
- [RANK | Snowflake Documentation](en/sql-reference/functions/rank.html.md) - Window functions (Ranking)
- [RATIO_TO_REPORT | Snowflake Documentation](en/sql-reference/functions/ratio_to_report.md) - Window functions (General)
- [REGEXP_INSTR | Snowflake Documentation](en/sql-reference/functions/regexp_instr.md) - String functions (regular expressions)
- [REGEXP_REPLACE | Snowflake Documentation](en/sql-reference/functions/regexp_replace.md) - String functions (regular expressions)
- [REGEXP_SUBSTR | Snowflake Documentation](en/sql-reference/functions/regexp_substr.md) - String functions (regular expressions)
- [REGEXP_SUBSTR_ALL | Snowflake Documentation](en/sql-reference/functions/regexp_substr_all.md) - String functions (regular expressions)
- [REGR_AVGX | Snowflake Documentation](en/sql-reference/functions/regr_avgx.md) - Aggregate functions (Linear Regression) , Window functions
- [REGR_R2 | Snowflake Documentation](en/sql-reference/functions/regr_r2.md) - Aggregate functions (Linear Regression) , Window function syntax and usage
- [REGR_SXX | Snowflake Documentation](en/sql-reference/functions/regr_sxx.md) - Aggregate functions (Linear Regression) , Window function syntax and usage
- [REPEAT | Snowflake Documentation](en/sql-reference/functions/repeat.html.md) - String & binary functions (General)
- [REPLACE | Snowflake Documentation](en/sql-reference/functions/replace.html.md) - String & binary functions (Matching/Comparison)
- [REPLACE | Snowflake Documentation](en/sql-reference/functions/replace.md) - String & binary functions (Matching/Comparison)
- [REVERSE | Snowflake Documentation](en/sql-reference/functions/reverse.md) - String & binary functions (General)
- [RIGHT | Snowflake Documentation](en/sql-reference/functions/right.html.md) - String & binary functions (Matching/Comparison)
- [RIGHT | Snowflake Documentation](en/sql-reference/functions/right.md) - String & binary functions (Matching/Comparison)
- [[ NOT ] RLIKE | Snowflake Documentation](en/sql-reference/functions/rlike.md) - String functions (regular expressions)
- [ROUND | Snowflake Documentation](en/sql-reference/functions/round.html.md) - Numeric functions (Rounding and Truncation)
- [ROUND | Snowflake Documentation](en/sql-reference/functions/round.md) - Numeric functions (Rounding and Truncation)
- [ROW_NUMBER | Snowflake Documentation](en/sql-reference/functions/row_number.html.md) - Window function syntax and usage (Ranking)
- [RTRIM | Snowflake Documentation](en/sql-reference/functions/rtrim.html.md) - String & binary functions (General)
- [SCHEDULED_TIME | Snowflake Documentation](en/sql-reference/functions/scheduled_time.md) - Date & time functions (Alerts)
- [SEQ1 / SEQ2 / SEQ4 / SEQ8 | Snowflake Documentation](en/sql-reference/functions/seq1.html.md) - Data generation functions
- [SPACE | Snowflake Documentation](en/sql-reference/functions/space.html.md) - String & binary functions (General)
- [SPACE | Snowflake Documentation](en/sql-reference/functions/space.md) - String & binary functions (General)
- [SPLIT | Snowflake Documentation](en/sql-reference/functions/split.md) - String & binary functions (General)
- [SPLIT_TO_TABLE | Snowflake Documentation](en/sql-reference/functions/split_to_table.md) - String & binary functions (General) , Table functions
- [SQRT | Snowflake Documentation](en/sql-reference/functions/sqrt.html.md) - Numeric functions (Exponent and Root)
- [SQRT | Snowflake Documentation](en/sql-reference/functions/sqrt.md) - Numeric functions (Exponent and Root)
- [SQUARE | Snowflake Documentation](en/sql-reference/functions/square.html.md) - Numeric functions (Exponent and Root)
- [SQUARE | Snowflake Documentation](en/sql-reference/functions/square.md) - Numeric functions (Exponent and Root)
- [ST_ASWKT , ST_ASTEXT | Snowflake Documentation](en/sql-reference/functions/st_aswkt.md) - Geospatial functions
- [ST_GEOGRAPHYFROMWKT | Snowflake Documentation](en/sql-reference/functions/st_geographyfromwkt.md) - Geospatial functions, Conversion functions
- [ST_MAKEPOINT , ST_POINT | Snowflake Documentation](en/sql-reference/functions/st_makepoint.md) - Geospatial functions
- [STARTSWITH | Snowflake Documentation](en/sql-reference/functions/startswith.md) - String & binary functions (Matching/Comparison)
- [STDDEV, STDDEV_SAMP | Snowflake Documentation](en/sql-reference/functions/stddev.html.md) - Aggregate functions (General) , Window function syntax and usage (General)
- [STDDEV_POP | Snowflake Documentation](en/sql-reference/functions/stddev_pop.html.md) - Aggregate functions (General) , Window function syntax and usage (General)
- [SUBSTR , SUBSTRING | Snowflake Documentation](en/sql-reference/functions/substr.html.md) - String & binary functions (Matching/Comparison)
- [SUM | Snowflake Documentation](en/sql-reference/functions/sum.html.md) - Aggregate functions (General) , Window function syntax and usage (General)
- [SUMMARIZE (SNOWFLAKE.CORTEX) | Snowflake Documentation](en/sql-reference/functions/summarize-snowflake-cortex.md) - String & binary functions (AI Functions)
- [SYSDATE | Snowflake Documentation](en/sql-reference/functions/sysdate.md) - Context functions (General)
- [TIMEADD | Snowflake Documentation](en/sql-reference/functions/timeadd.md) - Date & time functions
- [TIMEDIFF | Snowflake Documentation](en/sql-reference/functions/timediff.md) - Date & time functions
- [TIMESTAMP_FROM_PARTS | Snowflake Documentation](en/sql-reference/functions/timestamp_from_parts.md) - Date & time functions
- [TIMESTAMPADD | Snowflake Documentation](en/sql-reference/functions/timestampadd.md) - Date & time functions
- [TO_BINARY | Snowflake Documentation](en/sql-reference/functions/to_binary.md) - Conversion functions
- [TO_CHAR , TO_VARCHAR | Snowflake Documentation](en/sql-reference/functions/to_char.md) - Conversion functions
- [TO_DECIMAL , TO_NUMBER , TO_NUMERIC | Snowflake Documentation](en/sql-reference/functions/to_decimal.md) - Conversion functions
- [TO_TIMESTAMP / TO_TIMESTAMP_* | Snowflake Documentation](en/sql-reference/functions/to_timestamp.md) - Conversion functions , Date & time functions
- [TO_XML | Snowflake Documentation](en/sql-reference/functions/to_xml.html.md) - Conversion functions , Semi-structured and structured data functions (Cast)
- [TRUNCATE , TRUNC | Snowflake Documentation](en/sql-reference/functions/trunc.html.md) - Numeric functions (Rounding and Truncation)
- [TRUNCATE , TRUNC | Snowflake Documentation](en/sql-reference/functions/trunc.md) - Numeric functions (Rounding and Truncation)
- [TRY_BASE64_DECODE_BINARY | Snowflake Documentation](en/sql-reference/functions/try_base64_decode_binary.md) - String & binary functions (Encoding/Decoding)
- [TRY_CAST | Snowflake Documentation](en/sql-reference/functions/try_cast.md) - Conversion functions
- [TRY_HEX_DECODE_BINARY | Snowflake Documentation](en/sql-reference/functions/try_hex_decode_binary.md) - String & binary functions (Encoding/Decoding)
- [TRY_TO_BINARY | Snowflake Documentation](en/sql-reference/functions/try_to_binary.md) - Conversion functions
- [UNICODE | Snowflake Documentation](en/sql-reference/functions/unicode.md) - String & binary functions (General)
- [UPPER | Snowflake Documentation](en/sql-reference/functions/upper.html.md) - String & binary functions (Case Conversion)
- [UUID_STRING | Snowflake Documentation](en/sql-reference/functions/uuid_string.md) - String & binary functions (General) , Data generation functions
- [VAR_SAMP | Snowflake Documentation](en/sql-reference/functions/var_samp.md) - Aggregate functions (General) , Window function syntax and usage (General)
- [YEAR* / DAY* / WEEK* / MONTH / QUARTER | Snowflake Documentation](en/sql-reference/functions/year.html.md) - Date & time functions
- [YEAR* / DAY* / WEEK* / MONTH / QUARTER | Snowflake Documentation](en/sql-reference/functions/year.md) - Date & time functions
- [ZEROIFNULL | Snowflake Documentation](en/sql-reference/functions/zeroifnull.md) - Conditional expression functions
- [Identifier requirements | Snowflake Documentation](en/sql-reference/identifiers-syntax.md) - Unquoted object identifiers:
- [Snowflake Information Schema | Snowflake Documentation](en/sql-reference/info-schema.html.md) - The Snowflake Information Schema (aka “Data Dictionary”) consists of a set of system-defined views and table functions that provide extensive metadata information about the objects created in your acc
- [APPLICABLE_ROLES view | Snowflake Documentation](en/sql-reference/info-schema/applicable_roles.html.md) - This Information Schema view displays one row for each role grant applied to the currently authenticated user.
- [Summary of data types | Snowflake Documentation](en/sql-reference/intro-summary-data-types.md) - Snowflake supports most SQL data types. The following table provides a summary of the supported data types:
- [Arithmetic operators | Snowflake Documentation](en/sql-reference/operators-arithmetic.md) - Arithmetic operators are used to generate numeric output from one or more input expressions.
- [Logical operators | Snowflake Documentation](en/sql-reference/operators-logical.md) - Logical operators return the result of a particular Boolean operation on one or two input expressions. Logical operators are also referred to as Boolean operators.
- [Set operators | Snowflake Documentation](en/sql-reference/operators-query.html.md) - Set operators combine the intermediate results of multiple query blocks into a single result set.
- [Set operators | Snowflake Documentation](en/sql-reference/operators-query.md) - Set operators combine the intermediate results of multiple query blocks into a single result set.
- [Parameters | Snowflake Documentation](en/sql-reference/parameters.html.md) - Snowflake provides parameters that let you control the behavior of your account, individual user sessions, and objects. All parameters have default values. You can set these parameters and override th
- [Parameters | Snowflake Documentation](en/sql-reference/parameters.md) - Snowflake provides parameters that let you control the behavior of your account, individual user sessions, and objects. All parameters have default values. You can set these parameters and override th
- [Reserved & limited keywords | Snowflake Documentation](en/sql-reference/reserved-keywords.md) - Snowflake SQL reserves all ANSI keywords (with the exception of type keywords such as CHAR, DATE, DECIMAL, etc.), as well as some additional keywords (ASC, DESC, MINUS, etc.) that are reserved by othe
- [SQL variables | Snowflake Documentation](en/sql-reference/session-variables.html.md) - You can define and use SQL variables in sessions in Snowflake.
- [SQL variables | Snowflake Documentation](en/sql-reference/session-variables.md) - You can define and use SQL variables in sessions in Snowflake.
- [BEGIN … END (Snowflake Scripting) | Snowflake Documentation](en/sql-reference/snowflake-scripting/begin.md) - BEGIN and END define a Snowflake Scripting block.
- [CASE (Snowflake Scripting) | Snowflake Documentation](en/sql-reference/snowflake-scripting/case.md) - A CASE statement provides a way to specify multiple conditions.
- [EXCEPTION (Snowflake Scripting) | Snowflake Documentation](en/sql-reference/snowflake-scripting/exception.md) - Specifies how to handle exceptions raised in the Snowflake Scripting block.
- [FETCH (Snowflake Scripting) | Snowflake Documentation](en/sql-reference/snowflake-scripting/fetch.md) - Uses the specified cursor to fetch one or more rows.
- [FOR (Snowflake Scripting) | Snowflake Documentation](en/sql-reference/snowflake-scripting/for.html.md) - A FOR loop repeats a sequence of steps a specific number of times. The number of times might be specified by the user, or might be specified by the number of rows in a cursor. The syntax of these two 
- [FOR (Snowflake Scripting) | Snowflake Documentation](en/sql-reference/snowflake-scripting/for.md) - A FOR loop repeats a sequence of steps a specific number of times. The number of times might be specified by the user, or might be specified by the number of rows in a cursor. The syntax of these two 
- [IF (Snowflake Scripting) | Snowflake Documentation](en/sql-reference/snowflake-scripting/if.md) - An IF statement provides a way to execute a set of statements if a condition is met.
- [LET (Snowflake Scripting) | Snowflake Documentation](en/sql-reference/snowflake-scripting/let.html.md) - Assigns an expression to a Snowflake Scripting variable, cursor, or RESULTSET.
- [LOOP (Snowflake Scripting) | Snowflake Documentation](en/sql-reference/snowflake-scripting/loop.md) - A LOOP loop does not specify a number of iterations or a terminating condition. The user must explicitly exit the loop by using BREAK or RETURN inside the loop.
- [SQL format models | Snowflake Documentation](en/sql-reference/sql-format-models.html.md) - In Snowflake, SQL format models (i.e. literals containing format strings) are used to specify how numeric values are converted to text strings and vice versa. As such, they can be specified as argumen
- [SQL format models | Snowflake Documentation](en/sql-reference/sql-format-models.md) - In Snowflake, SQL format models (i.e. literals containing format strings) are used to specify how numeric values are converted to text strings and vice versa. As such, they can be specified as argumen
- [ALTER SESSION | Snowflake Documentation](en/sql-reference/sql/alter-session.md) - Sets parameters that change the behavior for the current session.
- [ALTER TABLE | Snowflake Documentation](en/sql-reference/sql/alter-table.md) - Modifies the properties, columns, or constraints for an existing table.
- [COPY INTO <location> | Snowflake Documentation](en/sql-reference/sql/copy-into-location.html.md) - Unloads data from a table (or query) into one or more files in one of the following locations:
- [COPY INTO <location> | Snowflake Documentation](en/sql-reference/sql/copy-into-location.md) - Unloads data from a table (or query) into one or more files in one of the following locations:
- [COPY INTO <table> | Snowflake Documentation](en/sql-reference/sql/copy-into-table.html.md) - Loads data from files to an existing table. The files must already be in one of the following locations:
- [COPY INTO <table> | Snowflake Documentation](en/sql-reference/sql/copy-into-table.md) - Loads data from files to an existing table. The files must already be in one of the following locations:
- [CREATE DYNAMIC TABLE | Snowflake Documentation](en/sql-reference/sql/create-dynamic-table.md) - Creates a dynamic table, based on a specified query.
- [CREATE EXTERNAL TABLE | Snowflake Documentation](en/sql-reference/sql/create-external-table.md) - Creates a new external table in the current or specified schema or replaces an existing external table. When queried, an external table reads data from a set of one or more files in a specified extern
- [CREATE FILE FORMAT | Snowflake Documentation](en/sql-reference/sql/create-file-format.html.md) - Creates a named file format that describes a set of staged data to access or load into Snowflake tables.
- [CREATE FILE FORMAT | Snowflake Documentation](en/sql-reference/sql/create-file-format.md) - Creates a named file format that describes a set of staged data to access or load into Snowflake tables.
- [CREATE MASKING POLICY | Snowflake Documentation](en/sql-reference/sql/create-masking-policy.html.md) - Enterprise Edition Feature
- [CREATE NOTIFICATION INTEGRATION | Snowflake Documentation](en/sql-reference/sql/create-notification-integration.md) - Creates a new notification integration in the account or replaces an existing integration. A notification integration is a Snowflake object that provides an interface between Snowflake and third-party
- [CREATE PROCEDURE | Snowflake Documentation](en/sql-reference/sql/create-procedure.html.md) - Creates a new stored procedure.
- [CREATE PROCEDURE | Snowflake Documentation](en/sql-reference/sql/create-procedure.md) - Creates a new stored procedure.
- [CREATE STAGE | Snowflake Documentation](en/sql-reference/sql/create-stage.html.md) - Creates a new named internal or external stage to use for loading data from files into Snowflake tables and unloading data from tables into files:
- [CREATE STAGE | Snowflake Documentation](en/sql-reference/sql/create-stage.md) - Creates a new named internal or external stage to use for loading data from files into Snowflake tables and unloading data from tables into files:
- [CREATE STORAGE INTEGRATION | Snowflake Documentation](en/sql-reference/sql/create-storage-integration.md) - Creates a new storage integration in the account or replaces an existing integration.
- [CREATE | ALTER TABLE … CONSTRAINT | Snowflake Documentation](en/sql-reference/sql/create-table-constraint.html.md) - This topic describes how to create constraints by specifying a CONSTRAINT clause in a CREATE TABLE, CREATE HYBRID TABLE, or ALTER TABLE statement:
- [CREATE TABLE | Snowflake Documentation](en/sql-reference/sql/create-table.html.md) - Creates a new table in the current/specified schema, replaces an existing table, or alters an existing table. A table can have multiple columns, with each column definition consisting of a name, data 
- [CREATE TABLE | Snowflake Documentation](en/sql-reference/sql/create-table.md) - Creates a new table in the current/specified schema, replaces an existing table, or alters an existing table. A table can have multiple columns, with each column definition consisting of a name, data 
- [CREATE TASK | Snowflake Documentation](en/sql-reference/sql/create-task.md) - Creates a new task in the current/specified schema or replaces an existing task.
- [CREATE VIEW | Snowflake Documentation](en/sql-reference/sql/create-view.md) - Creates a new view in the current/specified schema, based on a query of one or more existing tables (or any other valid query expression).
- [DELETE | Snowflake Documentation](en/sql-reference/sql/delete.md) - Remove rows from a table. You can use a WHERE clause to specify which rows should be removed. If you need to use a subquery(s) or additional table(s) to identify the rows to be removed, specify the su
- [DROP TABLE | Snowflake Documentation](en/sql-reference/sql/drop-table.html.md) - Removes a table from the current or specified schema, but retains a version of the table so that it can be recovered by using UNDROP TABLE. For information, see Usage Notes.
- [EXECUTE DBT PROJECT | Snowflake Documentation](en/sql-reference/sql/execute-dbt-project.md) - Executes the specified dbt project object or the dbt project in a Snowflake workspace using the dbt command and command-line options specified.
- [GET | Snowflake Documentation](en/sql-reference/sql/get.html.md) - Downloads data files from one of the following internal stage types to a local directory or folder on a client machine:
- [GRANT OWNERSHIP | Snowflake Documentation](en/sql-reference/sql/grant-ownership.md) - Transfers ownership of an object or all objects of a specified type in a schema from one role to another role. Role refers to either a role or a database role.
- [INSERT | Snowflake Documentation](en/sql-reference/sql/insert.md) - Updates a table by inserting one or more rows into the table. The values inserted into each column in the table can be explicitly-specified or the results of a query.
- [MERGE | Snowflake Documentation](en/sql-reference/sql/merge.html.md) - Inserts, updates, and deletes values in a table that are based on values in a second table or a subquery. Merging can be useful if the second table is a change log that contains new rows (to be insert
- [MERGE | Snowflake Documentation](en/sql-reference/sql/merge.md) - Inserts, updates, and deletes values in a table that are based on values in a second table or a subquery. Merging can be useful if the second table is a change log that contains new rows (to be insert
- [PUT | Snowflake Documentation](en/sql-reference/sql/put.html.md) - Uploads one or more data files from a local file system onto an internal stage.
- [SELECT | Snowflake Documentation](en/sql-reference/sql/select.md) - SELECT can be used as either a statement or as a clause within other statements:
- [SHOW <objects> | Snowflake Documentation](en/sql-reference/sql/show.html.md) - Lists the existing objects for the specified object type. The output includes metadata for the objects, including:
- [UPDATE | Snowflake Documentation](en/sql-reference/sql/update.html.md) - Updates specified rows in the target table with new values.
- [UPDATE | Snowflake Documentation](en/sql-reference/sql/update.md) - Updates specified rows in the target table with new values.
- [USE DATABASE | Snowflake Documentation](en/sql-reference/sql/use-database.html.md) - Specifies the active/current database for the session:
- [USE SCHEMA | Snowflake Documentation](en/sql-reference/sql/use-schema.html.md) - Specifies the active/current schema for the session:
- [JavaScript stored procedures API | Snowflake Documentation](en/sql-reference/stored-procedures-api.html.md) - This topic covers the JavaScript API for Snowflake stored procedures. The API consists of JavaScript objects and the methods in those objects.
- [Writing stored procedures in JavaScript | Snowflake Documentation](en/sql-reference/stored-procedures-javascript.html.md) - This topic explains how to write the JavaScript code for a stored procedure.
- [Stored procedures overview | Snowflake Documentation](en/sql-reference/stored-procedures-overview.md) - You can write stored procedures to extend the system with procedural code. With a procedure, you can use branching, looping, and other programmatic constructs. You can reuse a procedure multiple times
- [Transactions | Snowflake Documentation](en/sql-reference/transactions.html.md) - A transaction is a sequence of SQL statements that are committed or rolled back as a unit.
- [Transactions | Snowflake Documentation](en/sql-reference/transactions.md) - A transaction is a sequence of SQL statements that are committed or rolled back as a unit.
- [User-defined functions overview | Snowflake Documentation](en/sql-reference/user-defined-functions.html.md) - You can write user-defined functions (UDFs) to extend the system to perform operations that are not available through the built-in system-defined functions provided by Snowflake. Once you create a UDF
- [Browse Tutorials](en/tutorials.md) - Choose Category
- [Replication considerations | Snowflake Documentation](en/user-guide/account-replication-considerations.md) - Standard & Business Critical Feature
- [Setting up alerts based on data in Snowflake | Snowflake Documentation](en/user-guide/alerts.md) - This topic explains how to set up an alert that periodically performs an action under specific conditions, based on data within Snowflake.
- [Binary input and output | Snowflake Documentation](en/user-guide/binary-input-output.md) - Snowflake supports three binary formats or encoding schemes: hex, base64, and UTF-8.
- [Contacting Snowflake Support | Snowflake Documentation](en/user-guide/contacting-support.md) - To submit a case to Snowflake Support, you can either:
- [CI/CD integrations on dbt Projects on Snowflake | Snowflake Documentation](en/user-guide/data-engineering/dbt-projects-on-snowflake-ci-cd.md) - dbt project objects support using Snowflake CLI commands to integrate deployment and execution into your CI/CD workflows.
- [Understand dependencies for dbt Projects on Snowflake | Snowflake Documentation](en/user-guide/data-engineering/dbt-projects-on-snowflake-dependencies.md) - In dbt Projects on Snowflake, dbt dependencies are the packages that you declare in your packages.yml file (for example, dbt-labs/dbt_utils from the Getting started tutorial). They get installed into 
- [Monitor dbt Projects on Snowflake | Snowflake Documentation](en/user-guide/data-engineering/dbt-projects-on-snowflake-monitoring-observability.md) - This topic explains the ways you can use monitoring features for dbt Projects on Snowflake to inspect dbt project executions—–manual or task-scheduled–—and how to view logs and artifacts.
- [dbt Projects on Snowflake | Snowflake Documentation](en/user-guide/data-engineering/dbt-projects-on-snowflake.md) - dbt Core is an open-source data transformation tool and framework that you can use to define, test, and deploy SQL transformations.
- [About Openflow | Snowflake Documentation](en/user-guide/data-integration/openflow/about.md) - Feature — Generally Available
- [About Openflow Connector for MySQL | Snowflake Documentation](en/user-guide/data-integration/openflow/connectors/mysql/about.md) - Feature — Generally Available
- [Set up the Openflow Connector for Snowflake to Kafka | Snowflake Documentation](en/user-guide/data-integration/openflow/connectors/snowflake-to-kafka/setup.md) - Preview Feature
- [Overview of the data lifecycle | Snowflake Documentation](en/user-guide/data-lifecycle.md) - Snowflake provides support for all standard SELECT, DDL, and DML operations across the lifecycle of data in the system, from organizing and storing data to querying and working with data, as well as r
- [Staging data files from a local file system | Snowflake Documentation](en/user-guide/data-load-local-file-system-stage.html.md) - Execute PUT using the Snowflake CLI client, the SnowSQL client, or Drivers to upload (stage) local data files into an internal stage.
- [Bulk loading from a local file system | Snowflake Documentation](en/user-guide/data-load-local-file-system.md) - This set of topics describes how to use the COPY command to bulk load data from a local file system into tables using an internal (i.e. Snowflake-managed) stage. For instructions on loading data from 
- [Automating Snowpipe for Amazon S3 | Snowflake Documentation](en/user-guide/data-load-snowpipe-auto-s3.md) - This topic provides instructions for triggering Snowpipe data loads from external stages on S3 automatically using Amazon SQS (Simple Queue Service) notifications for an S3 bucket.
- [Introduction to Streams and Tasks | Snowflake Documentation](en/user-guide/data-pipelines-intro.md) - Snowflake supports continuous data pipelines with Streams and Tasks:
- [Understanding & using Time Travel | Snowflake Documentation](en/user-guide/data-time-travel.html.md) - Snowflake Time Travel enables accessing historical data (that is, data that has been changed or deleted) at any point within a defined period.
- [Understanding & using Time Travel | Snowflake Documentation](en/user-guide/data-time-travel.md) - Snowflake Time Travel enables accessing historical data (that is, data that has been changed or deleted) at any point within a defined period.
- [Data unloading considerations | Snowflake Documentation](en/user-guide/data-unload-considerations.md) - This topic provides best practices, general guidelines, and important considerations for unloading data from a table. It is intended to help simplify exporting data from Snowflake tables into files in
- [Overview of data unloading | Snowflake Documentation](en/user-guide/data-unload-overview.md) - Similar to data loading, Snowflake supports bulk export (i.e. unload) of data from a database table into flat, delimited text files.
- [Preparing to unload data | Snowflake Documentation](en/user-guide/data-unload-prepare.md) - This topic provides an overview of supported data file formats for unloading data.
- [Unloading into Amazon S3 | Snowflake Documentation](en/user-guide/data-unload-s3.md) - If you already have a Amazon Web Services (AWS) account and use S3 buckets for storing and managing your data files, you can make use of your existing buckets and folder paths when unloading data from
- [Date and time input and output formats | Snowflake Documentation](en/user-guide/date-time-input-output.html.md) - Date and time formats provide a method for representing dates, times, and timestamps.
- [Dynamic tables | Snowflake Documentation](en/user-guide/dynamic-tables-about.md) - Dynamic tables are tables that automatically refresh based on a defined query and target freshness, simplifying data transformation and pipeline management without requiring manual updates or custom s
- [Snowflake Ecosystem | Snowflake Documentation](en/user-guide/ecosystem.md) - Snowflake works with a wide array of industry-leading tools and technologies, enabling you to access Snowflake through an extensive network of connectors, drivers, programming languages, and utilities
- [Getting started](en/user-guide/getting-started.md) - Begin your adventure: a comprehensive guide to getting started with Snowflake and making the most of its features and benefits.
- [Snowflake interactive tables and interactive warehouses | Snowflake Documentation](en/user-guide/interactive.md) - Feature — Generally Available
- [Snowflake key concepts and architecture | Snowflake Documentation](en/user-guide/intro-key-concepts.html.md) - Snowflake is powered by an advanced data platform that is provided to you as a self-managed service. Snowflake’s data platform brings together data storage, processing, and analytic solutions that are
- [Snowflake key concepts and architecture | Snowflake Documentation](en/user-guide/intro-key-concepts.md) - Snowflake is powered by an advanced data platform that is provided to you as a self-managed service. Snowflake’s data platform brings together data storage, processing, and analytic solutions that are
- [Key-pair authentication and key-pair rotation | Snowflake Documentation](en/user-guide/key-pair-auth.md) - This topic describes using key pair authentication and key pair rotation in Snowflake.
- [Notifications in Snowflake | Snowflake Documentation](en/user-guide/notifications/about-notifications.md) - You can configure Snowflake to send notifications to a queue provided by a Cloud service (Amazon SNS, Google Cloud PubSub, or Azure Event Grid), an email address, or a webhook. For details, see the fo
- [Snowflake Open Catalog overview | Snowflake Documentation](en/user-guide/opencatalog/overview.md) - Feature — Generally Available
- [Organization accounts | Snowflake Documentation](en/user-guide/organization-accounts.md) - Enterprise Edition Feature
- [Organization users | Snowflake Documentation](en/user-guide/organization-users.md) - Preview Feature — Open
- [Connecting to your accounts | Snowflake Documentation](en/user-guide/organizations-connect.md) - This topic provides the URL and account identifier formats that you use to connect to the Snowflake accounts in your organization.
- [Managing accounts in your organization | Snowflake Documentation](en/user-guide/organizations-manage-accounts.md) - An organization administrator manages the lifecycle of every account that belongs to the organization, from creating a new account to deleting it.
- [Using programmatic access tokens for authentication | Snowflake Documentation](en/user-guide/programmatic-access-tokens.md) - You can use a programmatic access token to authenticate to the following Snowflake endpoints:
- [Snowflake Connector for Python | Snowflake Documentation](en/user-guide/python-connector.html.md) - Note
- [Working with CTEs (Common Table Expressions) | Snowflake Documentation](en/user-guide/queries-cte.md) - CONNECT BY , WITH
- [Using the Query Acceleration Service (QAS) | Snowflake Documentation](en/user-guide/query-acceleration-service.md) - Enterprise Edition Feature
- [Estimating the Number of Distinct Values | Snowflake Documentation](en/user-guide/querying-approximate-cardinality.md) - Snowflake uses HyperLogLog to estimate the approximate number of distinct values in a data set. HyperLogLog is a state-of-the-art cardinality estimation algorithm, capable of estimating distinct cardi
- [Working with joins | Snowflake Documentation](en/user-guide/querying-joins.md) - Query syntax
- [Using Sequences | Snowflake Documentation](en/user-guide/querying-sequences.html.md) - Sequences are used to generate unique numbers across sessions and statements, including concurrent statements. They can be used to generate values for a primary key or any column that requires a uniqu
- [Working with Subqueries | Snowflake Documentation](en/user-guide/querying-subqueries.html.md) - A subquery is a query within another query. Subqueries in a FROM or WHERE clause are used to provide data that will be used to limit or compare/evaluate the data returned by the containing query.
- [Introduction to business continuity & disaster recovery | Snowflake Documentation](en/user-guide/replication-intro.md) - Standard & Business Critical Feature
- [Sample data: TPC-DS | Snowflake Documentation](en/user-guide/sample-data-tpcds.md) - TPC-DS is a benchmark that models a retail product supplier’s decision support system. It has customer, order, and product data. Snowflake provides 10TB and 100TB versions of TPC-DS data for you to ex
- [Sample data: TPC-H | Snowflake Documentation](en/user-guide/sample-data-tpch.md) - As described in the TPC Benchmark™ H (TPC-H) specification:
- [Tutorial: Loading JSON data into a relational table | Snowflake Documentation](en/user-guide/script-data-load-transform-json.md) - Was this page helpful?
- [Using Dynamic Data Masking | Snowflake Documentation](en/user-guide/security-column-ddm-use.md) - Enterprise Edition Feature
- [Downloading Snowflake Clients, Connectors, Drivers, and Libraries | Snowflake Documentation](en/user-guide/snowflake-client-repository.md) - To download the installation package for a Snowflake client, connector, driver, or library, use the download pages in the Snowflake Developer Center.
- [Snowflake Cortex AI Functions (including LLM functions) | Snowflake Documentation](en/user-guide/snowflake-cortex/aisql.md) - Regional Availability
- [Cortex REST API | Snowflake Documentation](en/user-guide/snowflake-cortex/cortex-rest-api.md) - You can use the Snowflake Cortex REST API to invoke inference with the LLM of your choice. You can make requests using any programming language that can make HTTP POST requests. This functionality all
- [Cross-region inference | Snowflake Documentation](en/user-guide/snowflake-cortex/cross-region-inference.md) - Inference is the process of using a machine learning model to get an output based on a user input. For example, when you call the SNOWFLAKE.CORTEX.COMPLETE function, you are requesting an inference fr
- [Snowflake Cortex AI Functions (including LLM functions) | Snowflake Documentation](en/user-guide/snowflake-cortex/llm-functions.md) - Regional Availability
- [Snowflake Horizon Catalog | Snowflake Documentation](en/user-guide/snowflake-horizon.md) - Horizon Catalog is the universal catalog for your entire data estate. It provides context and governance for AI, enables any architecture across clouds and regions, works with any engine and data form
- [Snowflake Postgres | Snowflake Documentation](en/user-guide/snowflake-postgres/about.md) - Preview Feature — Open
- [Snowflake Postgres Insights | Snowflake Documentation](en/user-guide/snowflake-postgres/insights.md) - Preview Feature — Open
- [Creating a Snowflake Postgres Instance | Snowflake Documentation](en/user-guide/snowflake-postgres/postgres-create-instance.md) - Preview Feature — Open
- [Snowflake Postgres Instance Sizes | Snowflake Documentation](en/user-guide/snowflake-postgres/postgres-instance-sizes.md) - Preview Feature — Open
- [Snowflake Postgres Tri-Secret Secure | Snowflake Documentation](en/user-guide/snowflake-postgres/postgres-tss.md) - Preview Feature — Open
- [Installing SnowSQL | Snowflake Documentation](en/user-guide/snowsql-install-config.html.md) - This topic describes how to download and install SnowSQL on all supported platforms.
- [Using SnowSQL | Snowflake Documentation](en/user-guide/snowsql-use.html.md) - This topic describes how to use SnowSQL, including starting/stopping the client, using commands and variables within the client, and other general usage information.
- [SnowSQL (CLI client) | Snowflake Documentation](en/user-guide/snowsql.html.md) - Note
- [SnowSQL (CLI client) | Snowflake Documentation](en/user-guide/snowsql.md) - Note
- [Snowflake Connector for Spark | Snowflake Documentation](en/user-guide/spark-connector.md) - The Snowflake Connector for Spark (“Spark connector”) brings Snowflake into the Apache Spark ecosystem, enabling Spark to read data from, and write data to, Snowflake. From Spark’s perspective, Snowfl
- [Storage lifecycle policies | Snowflake Documentation](en/user-guide/storage-management/storage-lifecycle-policies.md) - Note
- [Introduction to Streams | Snowflake Documentation](en/user-guide/streams.md) - A stream object records data manipulation language (DML) changes made to tables, including inserts (including COPY INTO), updates, and deletes, as well as metadata about each change, so that actions c
- [Clustering Keys & Clustered Tables | Snowflake Documentation](en/user-guide/tables-clustering-keys.html.md) - In general, Snowflake produces well-clustered data in tables; however, over time, particularly as DML occurs on very large tables (as defined by the amount of data in the table, not the number of rows
- [Clustering Keys & Clustered Tables | Snowflake Documentation](en/user-guide/tables-clustering-keys.md) - In general, Snowflake produces well-clustered data in tables; however, over time, particularly as DML occurs on very large tables (as defined by the amount of data in the table, not the number of rows
- [Micro-partitions & Data Clustering | Snowflake Documentation](en/user-guide/tables-clustering-micropartitions.html.md) - Traditional data warehouses rely on static partitioning of large tables to achieve acceptable performance and enable better scaling. In these systems, a partition is a unit of management that is manip
- [Micro-partitions & Data Clustering | Snowflake Documentation](en/user-guide/tables-clustering-micropartitions.md) - Traditional data warehouses rely on static partitioning of large tables to achieve acceptable performance and enable better scaling. In these systems, a partition is a unit of management that is manip
- [Refresh external tables automatically for Azure Blob Storage | Snowflake Documentation](en/user-guide/tables-external-azure.md) - You can create external tables and refresh the external table metadata automatically by using Microsoft Azure Event Grid notifications for an Azure container. This operation synchronizes the metadata 
- [Refresh external tables automatically for Google Cloud Storage | Snowflake Documentation](en/user-guide/tables-external-gcs.md) - You can trigger external table metadata refreshes by using Google Cloud Pub/Sub messages for Google Cloud Storage (GCS) events.
- [Refresh external tables automatically for Amazon S3 | Snowflake Documentation](en/user-guide/tables-external-s3.md) - You can create external tables and refresh the external table metadata automatically by using Amazon SQS (Simple Queue Service) notifications for an S3 bucket. This operation synchronizes the metadata
- [Introduction to external tables | Snowflake Documentation](en/user-guide/tables-external.html.md) - An external table is a Snowflake feature that you can use to query data stored in an external stage as if the data were inside a table in Snowflake. The external stage is not part of Snowflake, so Sno
- [Apache Iceberg™ tables | Snowflake Documentation](en/user-guide/tables-iceberg.md) - Apache Iceberg™ tables for Snowflake combine the performance and query semantics of typical Snowflake tables with external cloud storage that you manage. They are ideal for existing data lakes that yo
- [Data storage considerations | Snowflake Documentation](en/user-guide/tables-storage-considerations.html.md) - This topic provides guidelines and best practices for controlling data storage costs associated with Continuous Data Protection (CDP), particularly for tables.
- [Working with Temporary and Transient Tables | Snowflake Documentation](en/user-guide/tables-temp-transient.html.md) - In addition to permanent tables, which is the default table type when creating tables, Snowflake supports defining tables as either temporary or transient. These types of tables are especially useful 
- [Working with Temporary and Transient Tables | Snowflake Documentation](en/user-guide/tables-temp-transient.md) - In addition to permanent tables, which is the default table type when creating tables, Snowflake supports defining tables as either temporary or transient. These types of tables are especially useful 
- [Introduction to tasks | Snowflake Documentation](en/user-guide/tasks-intro.md) - Tasks are a powerful way to automate data processing and to optimize business procedures on your data pipeline.
- [Tutorial: Getting started with dbt Projects on Snowflake | Snowflake Documentation](en/user-guide/tutorials/dbt-projects-on-snowflake-getting-started-tutorial.md) - Was this page helpful?
- [Tutorial: Loading and unloading Parquet data | Snowflake Documentation](en/user-guide/tutorials/script-data-load-transform-parquet.md) - Was this page helpful?
- [Working with Materialized Views | Snowflake Documentation](en/user-guide/views-materialized.html.md) - Enterprise Edition Feature
- [Working with Materialized Views | Snowflake Documentation](en/user-guide/views-materialized.md) - Enterprise Edition Feature
- [Snowflake Extension for Visual Studio Code | Snowflake Documentation](en/user-guide/vscode-ext.md) - The Snowflake Visual Studio Code (VS Code) extension enables you to write and execute Snowflake SQL statements directly in VS Code. The extension also integrates with Snowpark Python to provide debugg
- [Warehouse considerations | Snowflake Documentation](en/user-guide/warehouses-considerations.md) - This topic provides general guidelines and best practices for using virtual warehouses in Snowflake to process queries. It does not provide specific or absolute numbers, values, or recommendations bec
- [Snowflake generation 2 standard warehouses | Snowflake Documentation](en/user-guide/warehouses-gen2.md) - Generation 2 Standard Warehouse (Gen2) is an updated version (the “next generation”) of the current standard virtual warehouse in Snowflake, focused on improving performance for analytics and data eng
- [Monitoring warehouse load | Snowflake Documentation](en/user-guide/warehouses-load-monitoring.md) - The web interface provides a query load chart that depicts concurrent queries processed by a warehouse over a two-week period. Warehouse query load measures the average number of queries that were run
- [Multi-cluster warehouses | Snowflake Documentation](en/user-guide/warehouses-multicluster.md) - Enterprise Edition Feature
- [Overview of warehouses | Snowflake Documentation](en/user-guide/warehouses-overview.md) - Warehouses are required for queries, as well as all DML operations, including loading data into tables. In addition to being defined by its type as either Standard or Snowpark-optimized, a warehouse i
- [Snowpark-optimized warehouses | Snowflake Documentation](en/user-guide/warehouses-snowpark-optimized.md) - Snowpark-optimized warehouses let you configure the available memory resources and CPU architecture on a single-node instance for your workloads.
- [Working with warehouses | Snowflake Documentation](en/user-guide/warehouses-tasks.md) - All warehouse tasks can be performed from the Snowflake web interface or using the DDL commands for warehouses.
- [Virtual warehouses | Snowflake Documentation](en/user-guide/warehouses.md) - A virtual warehouse, often referred to simply as a “warehouse”, is a cluster of compute resources in Snowflake. A virtual warehouse is available in two types:

## About This Documentation

All content is automatically scraped from [Snowflake's Official Documentation](https://docs.snowflake.com/).

- **Total Documents**: 1000
- **Last Updated**: 2026-01-14
- **Auto-generated**: Yes

---

*This skill provides quick access to Snowflake documentation for AI assistants.*
