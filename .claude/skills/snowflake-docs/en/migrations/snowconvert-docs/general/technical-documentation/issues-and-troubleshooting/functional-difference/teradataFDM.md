---
auto_generated: true
description: Column converted from Blob data type.
last_scraped: '2026-01-14T16:52:51.994221+00:00'
scraper_version: 1.1.0
source_url: https://docs.snowflake.com/en/migrations/snowconvert-docs/general/technical-documentation/issues-and-troubleshooting/functional-difference/teradataFDM
title: SnowConvert AI - Teradata Functional Differences | Snowflake Documentation
---

1. [Overview](../../../../../../guides/README.md)
2. [Snowflake Horizon Catalog](../../../../../../user-guide/snowflake-horizon.md)
4. [Applications and tools for connecting to Snowflake](../../../../../../guides/overview-connecting.md)
6. [Virtual warehouses](../../../../../../user-guide/warehouses.md)
7. [Databases, Tables, & Views](../../../../../../guides/overview-db.md)
8. [Data types](../../../../../../data-types.md)
10. Data Integration

    - [Snowflake Openflow](../../../../../../user-guide/data-integration/openflow/about.md)
    - Apache Iceberg™

      - [Apache Iceberg™ Tables](../../../../../../user-guide/tables-iceberg.md)
      - [Snowflake Open Catalog](../../../../../../user-guide/opencatalog/overview.md)
11. Data engineering

    - [Data loading](../../../../../../guides/overview-loading-data.md)
    - [Dynamic Tables](../../../../../../user-guide/dynamic-tables-about.md)
    - [Streams and Tasks](../../../../../../user-guide/data-pipelines-intro.md)
    - [dbt Projects on Snowflake](../../../../../../user-guide/data-engineering/dbt-projects-on-snowflake.md)
    - [Data Unloading](../../../../../../guides/overview-unloading-data.md)
12. [Storage Lifecycle Policies](../../../../../../user-guide/storage-management/storage-lifecycle-policies.md)
13. [Migrations](../../../../../README.md)

    * Tools

      * [SnowConvert AI](../../../../overview.md)

        + General

          + [About](../../../about.md)
          + [Getting Started](../../../getting-started/README.md)
          + [Terms And Conditions](../../../terms-and-conditions/README.md)
          + [Release Notes](../../../release-notes/release-notes/README.md)
          + User Guide

            + [SnowConvert AI](../../../user-guide/snowconvert/README.md)
            + [Project Creation](../../../user-guide/project-creation.md)
            + [Extraction](../../../user-guide/extraction.md)
            + [Deployment](../../../user-guide/deployment.md)
            + [Data Migration](../../../user-guide/data-migration.md)
            + [Data Validation](../../../user-guide/data-validation.md)
            + [Power BI Repointing](../../../user-guide/power-bi-repointing-general.md)
            + [ETL Migration](../../../user-guide/etl-migration-replatform.md)
          + [Technical Documentation](../../README.md)

            - [Considerations](../../considerations/README.md)
            - [Issues And Troubleshooting](../README.md)

              * [Conversion Issues](../conversion-issues/README.md)
              * [Functional Difference](README.md)

                + [General](generalFDM.md)
                + [BigQuery](bigqueryFDM.md)
                + [DB2](db2FDM.md)
                + [Greenplum](greenplumFDM.md)
                + [Hive](hiveFDM.md)
                + [Oracle](oracleFDM.md)
                + [PostgreSQL](postgresqlFDM.md)
                + [Redshift](redshiftFDM.md)
                + [SQL Server-Azure Synapse](sqlServerFDM.md)
                + [Sybase IQ](sybaseFDM.md)
                + [Teradata](teradataFDM.md)
                + [Vertica](verticaFDM.md)
                + [SSIS](ssisFDM.md)
              * [Out Of Scope](../out-of-scope/README.md)
              * [Performance Review](../performance-review/README.md)
            - Function References

              - [SnowConvert AI Udfs](../../function-references/snowconvert-udfs.md)
              - [Teradata](../../function-references/teradata/README.md)
              - [Oracle](../../function-references/oracle/README.md)
              - [Shared](../../function-references/shared/README.md)
              - [SQL Server](../../function-references/sql-server/README.md)
          + [Contact Us](../../../contact-us.md)
          + Others

            + [Using SnowConvert AI In A Ubuntu Docker Image](../../../others/using-snowconvert-in-a-ubuntu-docker-image.md)
          + [Frequently Asked Questions (FAQ)](../../../frequently-asked-questions-faq.md)")
        + Translation References

          + [General](../../../../translation-references/general/README.md)
          + [Teradata](../../../../translation-references/teradata/README.md)
          + [Oracle](../../../../translation-references/oracle/README.md)
          + [SQL Server-Azure Synapse](../../../../translation-references/transact/README.md)
          + [Sybase IQ](../../../../translation-references/sybase/README.md)
          + [Hive-Spark-Databricks SQL](../../../../translation-references/hive/README.md)
          + [Redshift](../../../../translation-references/redshift/README.md)
          + [PostgreSQL-Greenplum-Netezza](../../../../translation-references/postgres/README.md)
          + [BigQuery](../../../../translation-references/bigquery/README.md)
          + [Vertica](../../../../translation-references/vertica/README.md)
          + [IBM DB2](../../../../translation-references/db2/README.md)
          + [SSIS](../../../../translation-references/ssis/README.md)
        + [Migration Assistant](../../../../migration-assistant/README.md)
        + [Data Validation CLI](../../../../data-validation-cli/index.md)
        + [AI Verification](../../../../snowconvert-ai-verification.md)
      * [Snowpark Migration Accelerator](../../../../../sma-docs/README.md)
    * Guides

      * [Teradata](../../../../../guides/teradata.md)
      * [Databricks](../../../../../guides/databricks.md)
      * [SQL Server](../../../../../guides/sqlserver.md)
      * [Amazon Redshift](../../../../../guides/redshift.md)
      * [Oracle](../../../../../guides/oracle.md)
      * [Azure Synapse](../../../../../guides/azuresynapse.md)
15. [Queries](../../../../../../guides/overview-queries.md)
16. [Listings](../../../../../../collaboration/collaboration-listings-about.md)
17. [Collaboration](../../../../../../guides/overview-sharing.md)
19. [Snowflake AI & ML](../../../../../../guides/overview-ai-features.md)
21. [Snowflake Postgres](../../../../../../user-guide/snowflake-postgres/about.md)
23. [Alerts & Notifications](../../../../../../guides/overview-alerts.md)
25. [Security](../../../../../../guides/overview-secure.md)
26. [Data Governance](../../../../../../guides/overview-govern.md)
27. [Privacy](../../../../../../guides/overview-privacy.md)
29. [Organizations & Accounts](../../../../../../guides/overview-manage.md)
30. [Business continuity & data recovery](../../../../../../user-guide/replication-intro.md)
32. [Performance optimization](../../../../../../guides/overview-performance.md)
33. [Cost & Billing](../../../../../../guides/overview-cost.md)

[Guides](../../../../../../guides/README.md)[Migrations](../../../../../README.md)Tools[SnowConvert AI](../../../../overview.md)General[Technical Documentation](../../README.md)[Issues And Troubleshooting](../README.md)[Functional Difference](README.md)Teradata

# SnowConvert AI - Teradata Functional Differences[¶](#snowconvert-ai-teradata-functional-differences "Link to this heading")

## SSC-FDM-TD0001[¶](#ssc-fdm-td0001 "Link to this heading")

Column converted from Blob data type.

### Description[¶](#description "Link to this heading")

This message is shown when SnowConvert AI finds a data type BLOB. Since BLOB is not supported in Snowflake, the type is changed to Binary.

#### Code Example[¶](#code-example "Link to this heading")

##### Input Code:[¶](#input-code "Link to this heading")

```
 CREATE TABLE TableExample
(
ColumnExample BLOB
);
```

Copy

##### Generated Code:[¶](#generated-code "Link to this heading")

```
 CREATE OR REPLACE TABLE TableExample
(
ColumnExample BINARY /*** SSC-FDM-TD0001 - COLUMN CONVERTED FROM BLOB DATA TYPE ***/
)
COMMENT = '{"origin":"sf_sc","name":"snowconvert","version":{"major":1, "minor":0},{"attributes":{"component":"teradata"}}'
;
```

Copy

#### Best Practices[¶](#best-practices "Link to this heading")

* No additional user actions are required.
* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0002[¶](#ssc-fdm-td0002 "Link to this heading")

Column converted from Clob data type.

### Description[¶](#id1 "Link to this heading")

This message is shown when SnowConvert AI finds a data type CLOB. Since CLOB is not supported in SnowConvert AI, the type is changed to VARCHAR.

#### Code Example[¶](#id2 "Link to this heading")

##### Input Code:[¶](#id3 "Link to this heading")

```
 CREATE TABLE TableExample
(
ColumnExample CLOB
)
```

Copy

##### Generated Code:[¶](#id4 "Link to this heading")

```
 CREATE OR REPLACE TABLE TableExample
(
ColumnExample VARCHAR /*** SSC-FDM-TD0002 - COLUMN CONVERTED FROM CLOB DATA TYPE ***/
)
COMMENT = '{"origin":"sf_sc","name":"snowconvert","version":{"major":1, "minor":0},{"attributes":{"component":"teradata"}}'
;
```

Copy

#### Best Practices[¶](#id5 "Link to this heading")

* No additional user actions are required.
* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0003[¶](#ssc-fdm-td0003 "Link to this heading")

Bash variables found, using SnowSQL with variable substitution enabled is required to run this script

### Description[¶](#id6 "Link to this heading")

When the source code of a script file migrated to Snowflake Scripting contains Bash variables placeholders ($variable or ${variable}), SnowConvert AI transforms them into SnowSQL variables (&variable or &{variable}).

This warning is generated to point out that the execution of the migrated script now depends on SnowSQL to work, please consider the following when running the script in SnowSQL:

* Variable substitution [must be enabled](https://docs.snowflake.com/en/user-guide/snowsql-use.html#enabling-variable-substitution).
* All variables [must be defined](https://docs.snowflake.com/en/user-guide/snowsql-use.html#defining-variables).
* Run the file as a [batch script](https://docs.snowflake.com/en/user-guide/snowsql-use.html#running-batch-scripts).

#### Example Code[¶](#example-code "Link to this heading")

##### Input Code:[¶](#id7 "Link to this heading")

```
 .LOGON dbc, dbc;

select '$variable', '${variable}', '${variable}_concatenated';

select $colname from $tablename where info = $id;

select ${colname} from ${tablename} where info = ${id};

.LOGOFF;
```

Copy

##### Generated Code:[¶](#id8 "Link to this heading")

```
EXECUTE IMMEDIATE
$$
  --** SSC-FDM-TD0003 - BASH VARIABLES FOUND, USING SNOWSQL WITH VARIABLE SUBSTITUTION ENABLED IS REQUIRED TO RUN THIS SCRIPT **
  DECLARE
    STATUS_OBJECT OBJECT := OBJECT_CONSTRUCT('SQLCODE', 0);
  BEGIN
    --.LOGON dbc, dbc
    !!!RESOLVE EWI!!! /*** SSC-EWI-0073 - PENDING FUNCTIONAL EQUIVALENCE REVIEW FOR 'BTLogOn' NODE ***/!!!
    null;
    BEGIN
      SELECT
        '&#x26;variable',
        '&#x26;{variable}',
        '&#x26;{variable}_concatenated';
      STATUS_OBJECT := OBJECT_CONSTRUCT('SQLROWCOUNT', SQLROWCOUNT);
    EXCEPTION
      WHEN OTHER THEN
        STATUS_OBJECT := OBJECT_CONSTRUCT('SQLCODE', SQLCODE, 'SQLERRM', SQLERRM, 'SQLSTATE', SQLSTATE);
    END;
    BEGIN
      SELECT
        &#x26;colname
      from
        &#x26;tablename
      where
        info = &#x26;id;
      STATUS_OBJECT := OBJECT_CONSTRUCT('SQLROWCOUNT', SQLROWCOUNT);
    EXCEPTION
      WHEN OTHER THEN
        STATUS_OBJECT := OBJECT_CONSTRUCT('SQLCODE', SQLCODE, 'SQLERRM', SQLERRM, 'SQLSTATE', SQLSTATE);
    END;
    BEGIN
      SELECT
        &#x26;{colname}
      from
        &#x26;{tablename}
      where
        info = &#x26;{id};
      STATUS_OBJECT := OBJECT_CONSTRUCT('SQLROWCOUNT', SQLROWCOUNT);
    EXCEPTION
      WHEN OTHER THEN
        STATUS_OBJECT := OBJECT_CONSTRUCT('SQLCODE', SQLCODE, 'SQLERRM', SQLERRM, 'SQLSTATE', SQLSTATE);
    END;
    --.LOGOFF
    !!!RESOLVE EWI!!! /*** SSC-EWI-0073 - PENDING FUNCTIONAL EQUIVALENCE REVIEW FOR 'LogOff' NODE ***/!!!
    null;
  END
$$
```

Copy

#### Best Practices[¶](#id9 "Link to this heading")

* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0004[¶](#ssc-fdm-td0004 "Link to this heading")

Period types are handled as two data fields

### Description[¶](#id10 "Link to this heading")

Teradata has a period data type used to represent a time interval, with instances of this type having a beginning and ending bound of the same type (time, date or timestamp) along with a set of functions that allow to initialize and manipulate period data like PERIOD, BEGIN, END, OVERLAPS, etc.

Since the period type is not supported by Snowflake, SnowConvert AI transforms this type and its related functions using the following rules:

* Any period type declaration in column tables is migrated as a two column of the same type.
* The [period value constructor function](https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/SQL-Date-and-Time-Functions-and-Expressions/Period-Functions-and-Operators) is migrated into two different constructors of the period subtype one with the begin value and the other with the end value.
* Supported functions that expect period type parameters are migrated to UDFs as well, these UDFs expect almost two parameters for the begin value and the end value.

#### Example code[¶](#id11 "Link to this heading")

##### Input code:[¶](#id12 "Link to this heading")

```
 -- Additional Params: --SplitPeriodDatatype
CREATE TABLE DateTable
(
	COL1 PERIOD(DATE) DEFAULT PERIOD (DATE '2005-02-03', UNTIL_CHANGED)
);
```

Copy

##### Generated Code:[¶](#id13 "Link to this heading")

```
CREATE OR REPLACE TABLE DateTable
(
	COL1_begin DATE DEFAULT DATE '2005-02-03',
	COL1_end DATE DEFAULT DATE '9999-12-31' /*** SSC-FDM-TD0004 - PERIOD DATA TYPES ARE HANDLED AS TWO DATA FIELDS ***/
)
COMMENT = '{"origin":"sf_sc","name":"snowconvert","version":{"major":1, "minor":0},"attributes":{"component":"teradata"}}'
;
```

Copy

#### Best Practices[¶](#id14 "Link to this heading")

* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0005[¶](#ssc-fdm-td0005 "Link to this heading")

Non-standard time zone offsets are not supported in Snowflake, rounded to nearest valid time zone

### Description[¶](#id15 "Link to this heading")

While Teradata provides the flexibility to define any time zone offset between `-12:59` and `+14:00` using the `SET TIME ZONE` query, Snowflake exclusively supports time zones listed in the [IANA Time Zone Database](https://www.iana.org/time-zones).

If the specified offset in the SET TIME ZONE query does not align with an IANA standard time zone, Snowflake will automatically round it to the nearest standard time zone with the closest offset. In such a case, a warning message will be generated.

#### Example Code[¶](#id16 "Link to this heading")

##### Input Code:[¶](#id17 "Link to this heading")

```
-- Will be rounded to Asia/Colombo (+05:30)
SET TIME ZONE '05:26';
```

Copy

##### Generated Code:[¶](#id18 "Link to this heading")

```
 -- Will be rounded to Asia/Colombo (+05:30)
--** SSC-FDM-TD0005 - NON-STANDARD TIME ZONE OFFSETS NOT SUPPORTED IN SNOWFLAKE, ROUNDED TO NEAREST VALID TIME ZONE **
ALTER SESSION SET TIMEZONE = 'Asia/Colombo';
```

Copy

#### Best Practices[¶](#id19 "Link to this heading")

* No additional user actions are required.
* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0006[¶](#ssc-fdm-td0006 "Link to this heading")

View With Check Option Not Supported.

### Description[¶](#id20 "Link to this heading")

This message is shown when SnowConvert AI finds a view with the WITH CHECK OPTION clause. Which is not supported in Snowflake, so it is commented out from the code.

This clause works with updatable views that can be used to execute INSERT and UPDATE commands over the view and internally update the table associated with the view.

The clause is used to restrict the rows that will be affected by the command using the WHERE clause in the view.

For more details see the [documentation](https://docs.teradata.com/r/SQL-Data-Definition-Language-Syntax-and-Examples/July-2021/View-Statements/CREATE-VIEW-and-REPLACE-VIEW/CREATE-VIEW-and-REPLACE-VIEW-Syntax-Elements/WITH-CHECK-OPTION) about the clause functionality.

#### Example code[¶](#id21 "Link to this heading")

##### Input code:[¶](#id22 "Link to this heading")

```
REPLACE VIEW VIEWWITHOPTIONTEST AS
LOCKING ROW FOR ACCESS
SELECT 
    *        
FROM SOMETABLE
WHERE app_id = 'SUPPLIER'
WITH CHECK OPTION;
```

Copy

##### Generated Code:[¶](#id23 "Link to this heading")

```
 CREATE OR REPLACE VIEW VIEWWITHOPTIONTEST
COMMENT = '{ "origin": "sf_sc", "name": "snowconvert", "version": {  "major": 0,  "minor": 0,  "patch": "0" }, "attributes": {  "component": "teradata",  "convertedOn": "07/02/2025",  "domain": "no-domain-provided" }}'
AS
SELECT
    *
FROM
    SOMETABLE
WHERE
    UPPER(RTRIM( app_id)) = UPPER(RTRIM('SUPPLIER'))
--    --** SSC-FDM-TD0006 - VIEW WITH OPTION NOT SUPPORTED IN SNOWFLAKE **
--    WITH CHECK OPTION
                     ;
```

Copy

#### Best Practices[¶](#id24 "Link to this heading")

* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0007[¶](#ssc-fdm-td0007 "Link to this heading")

Variant column does not support collation.

### Description[¶](#id25 "Link to this heading")

This message is shown when SnowConvert AI a Variant data type in the transformation of a code has a COLLATE clause. Since COLLATE is not supported with the data type VARIANT, it will be removed and a message will be added.

#### Example code[¶](#id26 "Link to this heading")

##### Input code:[¶](#id27 "Link to this heading")

```
-- Additional Params: --useCollateForCaseSpecification
CREATE TABLE TableExample
(
ColumnExample JSON(2500) NOT CASESPECIFIC
)
```

Copy

##### Generated Code:[¶](#id28 "Link to this heading")

```
 CREATE OR REPLACE TABLE TableExample
(
ColumnExample VARIANT
--                      NOT CASESPECIFIC /*** SSC-FDM-TD0007 - VARIANT COLUMN DOES NOT SUPPORT COLLATION ***/
)
COMMENT = '{"origin":"sf_sc","name":"snowconvert","version":{"major":1, "minor":0},{"attributes":{"component":"teradata"}}'
;
```

Copy

The data type JSON is converted to VARIANT, while NOT CASESPECIFIC is converted to a COLLATE clause.

#### Best Practices[¶](#id29 "Link to this heading")

* No additional user actions are required.
* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0008[¶](#ssc-fdm-td0008 "Link to this heading")

When NVP\_UDF fourth parameter is non-literal and it contains a backslash, that backslash needs to be escaped.

### Description[¶](#id30 "Link to this heading")

Non-literal delimiters with spaces need their backslash escaped in snowflake.

#### Example code[¶](#id31 "Link to this heading")

##### Input code[¶](#id32 "Link to this heading")

```
SELECT NVP('store = whole foods&#x26;&#x26;store: ?Bristol farms','store', '&#x26;&#x26;', valueDelimiter, 2);
```

Copy

##### Generated Code[¶](#id33 "Link to this heading")

```
 SELECT
PUBLIC.NVP_UDF('store = whole foods&&store: ?Bristol farms', 'store', '&&', valueDelimiter, 2) /*** SSC-FDM-TD0008 - WHEN NVP_UDF FOURTH PARAMETER IS NON-LITERAL AND IT CONTAINS A BACKSLASH, THAT BACKSLASH NEEDS TO BE ESCAPED ***/;
```

Copy

#### Best Practices[¶](#id34 "Link to this heading")

* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0009[¶](#ssc-fdm-td0009 "Link to this heading")

Converted from integer to varchar for current session default.

### Description[¶](#id35 "Link to this heading")

This message is shown when SnowConvert AI finds a DEFAULT SESSION and the data type is NOT a VARCHAR. If that is the case, the data type is changed to VARCHAR and a message is added.

#### Code Example[¶](#id36 "Link to this heading")

##### Input Code:[¶](#id37 "Link to this heading")

```
 CREATE TABLE TableExample
(
ColumnExample INTEGER DEFAULT SESSION,
ColumnExample2 VARCHAR DEFAULT SESSION
)
```

Copy

##### Generated Code:[¶](#id38 "Link to this heading")

```
 CREATE OR REPLACE TABLE TableExample
(
ColumnExample VARCHAR DEFAULT CURRENT_SESSION() /*** SSC-FDM-TD0009 - CONVERTED FROM INTEGER TO VARCHAR FOR CURRENT_SESSION DEFAULT ***/,
ColumnExample2 VARCHAR DEFAULT CURRENT_SESSION()
)
COMMENT = '{"origin":"sf_sc","name":"snowconvert","version":{"major":1, "minor":0},{"attributes":{"component":"teradata"}}'
;
```

Copy

Let’s look at the example. Note that ColumnExample has a data type INTEGER with DEFAULT SESSION. Since the data type is not VARCHAR, in the output it is transformed to VARCHAR.

The data type of ColumnExample2 hasn’t changed since it is already VARCHAR.

#### Best Practices[¶](#id39 "Link to this heading")

* No additional user actions are required.
* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0010[¶](#ssc-fdm-td0010 "Link to this heading")

Table columns between tables (Teradata) DBC.COLUMNSV and INFORMATION\_SCHEMA.COLUMNS (SnowFlake). But some columns might not have an exact match in Snowflake.

### Description[¶](#id40 "Link to this heading")

Uses of the table `DBC.COLUMNSV` in Teradata are converted to `INFORMATION_SCHEMA.COLUMNS`, but some columns might not have an exact match in SnowFlake. That means there are some columns in Teradata for which there is **no** equivalent in SnowFlake, and there are others that do have a matching column but the content is not exactly the same.

![](../../../../../.gitbook/assets/TeradataTable (3).png)

An example of the contents of DBC.COLUMNSV table in Teradata

![](../../../../../.gitbook/assets/SnowConvertTable (5).png)

An example of the contents of INFORMATION\_SCHEMA.COLUMNS table in SnowFlake

Notice, for example, that there is no equivalent column for *“ColumnFormat*” in SnowFlake and notice also that *“DATA\_TYPE”* seems to be the match for the column *“ColumnType”* in Teradata, but their content greatly differ.

#### Code Example[¶](#id41 "Link to this heading")

##### Input Code:[¶](#id42 "Link to this heading")

```
 SELECT columnname FROM dbc.columnsV WHERE tablename = 'TableN';
```

Copy

##### Generated Code:[¶](#id43 "Link to this heading")

```
 SELECT
COLUMN_NAME AS COLUMNNAME
FROM
--** SSC-FDM-TD0010 - USES OF TABLE DBC.COLUMNSV ARE CONVERTED TO INFORMATION_SCHEMA.COLUMNS, BUT SOME COLUMNS MIGHT NOT HAVE AND EXACT MATCH IN SNOWFLAKE **
INFORMATION_SCHEMA.COLUMNS
WHERE
UPPER(RTRIM(TABLE_NAME)) = UPPER(RTRIM('TableN'));
```

Copy

#### Best Practices[¶](#id44 "Link to this heading")

* Review what columns were used in Teradata and check if the available content in SnowFlake matches your needs.
* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0011[¶](#ssc-fdm-td0011 "Link to this heading")

Unicode BMP escape is not supported.

### Description[¶](#id45 "Link to this heading")

Snowflake doesn’t support Unicode BMP, so this message is shown when SnowConvert AI transforms Teradata [Unicode Delimited Character Literal](https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/SQL-Data-Types-and-Literals/Data-Literals/Unicode-Delimited-Character-Literals) with Unicode BMP escape to snowflake.

#### Example code[¶](#id46 "Link to this heading")

##### Input Code:[¶](#id47 "Link to this heading")

```
 SELECT U&'hola #+005132 mundo' UESCAPE '#';
```

Copy

##### Generated Code:[¶](#id48 "Link to this heading")

```
 SELECT
--** SSC-FDM-TD0011 - UNICODE BMP IS NOT SUPPORTED IN SNOWFLAKE **
'hola \u+005132 mundo';
```

Copy

#### Best Practices[¶](#id49 "Link to this heading")

* Check if a Unicode equivalent exists.
* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0012[¶](#ssc-fdm-td0012 "Link to this heading")

Invalid default value.

Note

This FDM is deprecated, please refer to [SSC-EWI-TD0006](../conversion-issues/teradataEWI.html#ssc-ewi-td0006) documentation

### Description[¶](#id50 "Link to this heading")

The **DEFAULT TIME** / **DEFAULT DATE** / **DEFAULT CURREN\_DATE** */* **DEFAULT DEFAULT CURRENT\_TIME** */* **DEFAULT CURRENT\_TIMESTAMP** column specifications are not supported for the **FLOAT** data type.

#### Example Code[¶](#id51 "Link to this heading")

##### Teradata:[¶](#teradata "Link to this heading")

```
CREATE TABLE T_2004
(
    -- In the output code all of these columns will be FLOAT type
    -- and will include the SSC-FDM-TD0012 message.
    COL1 FLOAT DEFAULT TIME,
    COL2 FLOAT DEFAULT DATE,
    COL3 FLOAT DEFAULT CURRENT_DATE,
    COL4 FLOAT DEFAULT CURRENT_TIME,
    COL5 FLOAT DEFAULT CURRENT_TIMESTAMP
);
```

Copy

##### Snowflake Scripting:[¶](#snowflake-scripting "Link to this heading")

```
 CREATE TABLE T_2004
(
    -- In the output code all of these columns will be FLOAT type
    -- and will include the SSC-FDM-TD0012 message.
    COL1 FLOAT DEFAULT TIME /*** SSC-FDM-TD0012 - DEFAULT CURRENT_TIME NOT VALID FOR DATA TYPE ***/,
    COL2 FLOAT DEFAULT DATE /*** SSC-FDM-TD0012 - DEFAULT CURRENT_DATE NOT VALID FOR DATA TYPE ***/,
    COL3 FLOAT DEFAULT CURRENT_DATE /*** SSC-FDM-TD0012 - DEFAULT CURRENT_DATE NOT VALID FOR DATA TYPE ***/,
    COL4 FLOAT DEFAULT CURRENT_TIME /*** SSC-FDM-TD0012 - DEFAULT CURRENT_TIME NOT VALID FOR DATA TYPE ***/,
    COL5 FLOAT DEFAULT CURRENT_TIMESTAMP /*** SSC-FDM-TD0012 - DEFAULT CURRENT_TIMESTAMP NOT VALID FOR DATA TYPE ***/
)
COMMENT = '{"origin":"sf_sc","name":"snowconvert","version":{"major":1, "minor":0},{"attributes":{"component":"teradata"}}'
;
```

Copy

#### Best Practices[¶](#id52 "Link to this heading")

* No additional user actions are required.
* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0013[¶](#ssc-fdm-td0013 "Link to this heading")

The Snowflake error code mismatch the original Teradata error code

### Description[¶](#id53 "Link to this heading")

This message is shown because the error code saved in the BTEQ ERRORCODE build-in variable could not be the same in Snowflake Scripting.

#### Example code[¶](#id54 "Link to this heading")

##### Input code:[¶](#id55 "Link to this heading")

```
SELECT * FROM table1;
 
.IF ERRORCODE<>0 THEN .EXIT 1

.QUIT 0
```

Copy

##### Generated Code:[¶](#id56 "Link to this heading")

```
 -- Additional Params: -q snowscript

EXECUTE IMMEDIATE
$$
  DECLARE
    STATUS_OBJECT OBJECT := OBJECT_CONSTRUCT('SQLCODE', 0);
  BEGIN
    BEGIN
      SELECT
        *
      FROM
        table1;
      STATUS_OBJECT := OBJECT_CONSTRUCT('SQLROWCOUNT', SQLROWCOUNT);
    EXCEPTION
      WHEN OTHER THEN
        STATUS_OBJECT := OBJECT_CONSTRUCT('SQLCODE', SQLCODE, 'SQLERRM', SQLERRM, 'SQLSTATE', SQLSTATE);
    END;
    IF (STATUS_OBJECT['SQLCODE'] /*** SSC-FDM-TD0013 - THE SNOWFLAKE ERROR CODE MISMATCH THE ORIGINAL TERADATA ERROR CODE ***/ != 0) THEN
      RETURN 1;
    END IF;
    RETURN 0;
  END
$$
```

Copy

#### Best Practices[¶](#id57 "Link to this heading")

* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0014[¶](#ssc-fdm-td0014 "Link to this heading")

File execution inconsistency

### Description[¶](#id58 "Link to this heading")

This EWI appears when the migrated code is a BTEQ sentence executing an environment file with SQL statements E.g. $(<$INPUT\_SQL\_FILE). The difference between the BTEQ execution and the python generated code is that BTEQ continues with the other statements in the file when one of them fails but the python execution stops whenever an error occurs.

#### Example Code[¶](#id59 "Link to this heading")

##### Teradata BTEQ:[¶](#teradata-bteq "Link to this heading")

```
 .logmech LDAP;
.logon $LOGON_STR;
.SET DEFAULTS;


$(<$INPUT_SQL_FILE)

.export reset
.logoff
.quit
```

Copy

##### Python:[¶](#python "Link to this heading")

```
#*** Generated code is based on the SnowConvert AI Python Helpers version 2.0.6 ***

from snowconvert.helpers import exec_file
import os
import sys
import snowconvert.helpers
from snowconvert.helpers import Export
from snowconvert.helpers import exec
from snowconvert.helpers import BeginLoading
con = None
#** SSC-FDM-TD0022 - SHELL VARIABLES FOUND, RUNNING THIS CODE IN A SHELL SCRIPT IS REQUIRED **
def main():
  snowconvert.helpers.configure_log()
  con = snowconvert.helpers.log_on()
  #** SSC-FDM-0027 - REMOVED NEXT STATEMENT, NOT APPLICABLE IN SNOWFLAKE. LOGMECH **
  #.logmech LDAP;
   
  #** SSC-FDM-0027 - REMOVED NEXT STATEMENT, NOT APPLICABLE IN SNOWFLAKE. LOGON **
  #.logon $LOGON_STR
   
  #** SSC-EWI-TD0005 - THE STATEMENT WAS CONVERTED BUT ITS FUNCTIONALITY IS NOT IMPLEMENTED YET **
  Export.defaults()
  #** SSC-FDM-TD0014 - EXECUTION OF FILE WITH SQL STATEMENTS STOPS WHEN AN ERROR OCCURS **
  exec_file("$INPUT_SQL_FILE")
  #** SSC-EWI-TD0005 - THE STATEMENT WAS CONVERTED BUT ITS FUNCTIONALITY IS NOT IMPLEMENTED YET **
  Export.reset()
  #** SSC-FDM-0027 - REMOVED NEXT STATEMENT, NOT APPLICABLE IN SNOWFLAKE. LOGOFF **
  #.logoff
   
  snowconvert.helpers.quit_application()

if __name__ == "__main__":
  main()
```

Copy

#### Best Practices[¶](#id60 "Link to this heading")

* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0015[¶](#ssc-fdm-td0015 "Link to this heading")

Regexp\_Substr Function only supports POSIX regular expressions.

Note

This FDM is deprecated, please refer to [SSC-EWI-0009](../conversion-issues/generalEWI.html#ssc-ewi-0009) documentation

### Description[¶](#id61 "Link to this heading")

Currently, there is no support in Snowflake for extended regular expression beyond the POSIX Basic Regular Expression syntax.

This EWI is added every time a function call to *REGEX\_SUBSTR, REGEX\_REPLACE,* or *REGEX\_INSTR* is transformed to SnowFlake to warn the user about possible unsupported regular expressions. Some of the features **not supported** are lookahead, lookbehind, and non-capturing groups.

#### Example Code[¶](#id62 "Link to this heading")

##### Teradata:[¶](#id63 "Link to this heading")

```
 SELECT REGEXP_SUBSTR('qaqequ','q(?=u)', 1, 1);
```

Copy

##### Snowflake Scripting:[¶](#id64 "Link to this heading")

```
 SELECT
--** SSC-FDM-TD0015 - REGEXP_SUBSTR FUNCTION ONLY SUPPORTS POSIX REGULAR EXPRESSIONS **
REGEXP_SUBSTR('qaqequ','q(?=u)', 1, 1);
```

Copy

#### Best Practices[¶](#id65 "Link to this heading")

* Check the regular expression used in each case to determine whether it needs manual intervention. More information about expanded regex support and alternatives in SnowFlake can be found [**here**](https://community.snowflake.com/s/question/0D50Z00007ENLKsSAP/expanded-support-for-regular-expressions-regex)**.**
* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0016[¶](#ssc-fdm-td0016 "Link to this heading")

Value ‘l’ for parameter ‘match\_arg’ is not supported in Snowflake

### Description[¶](#id66 "Link to this heading")

In Teradata functions like *REGEX\_SUBSTR, REGEX\_REPLACE,* or *REGEX\_INSTR* have a parameter called *“match\_arg*”, a character argument with the following valid values:

* `'i'`: case-insensitive matching.
* `'c'`: case sensitive matching.
* `'n'`: the period character (match any character) can match the newline character.
* `'m'`: source string is treated as multiple lines instead of as a single line.
* **`'l'`**: if source\_string exceeds the current maximum allowed source\_string size (currently 16 MB), a NULL is returned instead of an error.
* `'x'`: ignore whitespace (only affects the pattern string).

The argument can contain more than one character.

In Snowflake, the equivalent argument for these functions is *`regexp_parameters.`*A *s*tring of one or more characters that specifies the regular expression parameters used for searching for matches. The supported values are:

* `c`: case-sensitive.
* `i`: case-insensitive.
* `m`: multi-line mode.
* `e`: extract sub-matches.
* `s`: the ‘.’ the wildcard also matches the newline character as well.

As it can be seen, values `'i', 'c', 'm'` are the same in both languages, and the `'n'` value in Teradata is mapped to `'s'`. However, values `'l', 'x'` don’t have an equivalent counterpart.

For the `'x'` value, the functionallity is replicated by generating a call to the `REGEXP_REPLACE` function. However, the `'l'` parameter can not be replicated so this warning is generated for these cases.

#### Input Code:[¶](#id67 "Link to this heading")

```
 SELECT REGEXP_SUBSTR('Chip Chop','ch(i|o)p', 1, 1, 'i'), 
       REGEXP_SUBSTR('Chip Chop','ch(i|o)p', 1, 1, 'c'),
       REGEXP_SUBSTR('Chip Chop','ch(i|o)p', 1, 1, 'm'),
       REGEXP_SUBSTR('Chip Chop','ch(i|o)p', 1, 1, 'n'),
       REGEXP_SUBSTR('Chip Chop','ch(i|o)p', 1, 1, 'l'),
       REGEXP_SUBSTR('Chip Chop','ch(i|o)p', 1, 1, 'x');
```

Copy

##### Generated Code:[¶](#id68 "Link to this heading")

```
 SELECT
       REGEXP_SUBSTR('Chip Chop', 'ch(i|o)p', 1, 1, 'i'),
       REGEXP_SUBSTR('Chip Chop', 'ch(i|o)p', 1, 1, 'c'),
       REGEXP_SUBSTR('Chip Chop', 'ch(i|o)p', 1, 1, 'm'),
       REGEXP_SUBSTR('Chip Chop', 'ch(i|o)p', 1, 1, 's'),
       --** SSC-FDM-TD0016 - VALUE 'l' FOR PARAMETER 'match_arg' IS NOT SUPPORTED IN SNOWFLAKE **
       REGEXP_SUBSTR('Chip Chop', 'ch(i|o)p', 1, 1),
       REGEXP_SUBSTR('Chip Chop', 'ch(i|o)p', 1, 1);
```

Copy

#### Best Practices[¶](#id69 "Link to this heading")

* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0017[¶](#ssc-fdm-td0017 "Link to this heading")

The use of foreign tables is not supported in Snowflake.

Note

This FDM is deprecated, please refer to [SSC-EWI-TD0076](../conversion-issues/teradataEWI.html#ssc-ewi-td0076) documentation

### Description[¶](#id70 "Link to this heading")

[Foreign tables](https://docs.teradata.com/r/Teradata-VantageTM-SQL-Data-Definition-Language-Syntax-and-Examples/September-2020/Table-Statements/CREATE-FOREIGN-TABLE) enable access to data in external object storage, such as semi-structured and unstructured data in Amazon S3, Azure Blob storage, and Google Cloud Storage. This syntax is not supported in Snowflake. However, there are other alternatives in Snowflake that can be used instead, such as external tables, iceberg tables, and standard tables.

#### Example code[¶](#id71 "Link to this heading")

##### Input code:[¶](#id72 "Link to this heading")

```
 SELECT cust_id, income, age FROM 
FOREIGN TABLE (SELECT cust_id, income, age FROM twm_customer)@hadoop1 T1;
```

Copy

##### Generated Code:[¶](#id73 "Link to this heading")

```
 SELECT
cust_id,
income,
age FROM
--** SSC-FDM-TD0017 - THE USE OF FOREIGN TABLES IS NOT SUPPORTED IN SNOWFLAKE. **
 FOREIGN TABLE (SELECT cust_id, income, age FROM twm_customer)@hadoop1 T1;
```

Copy

#### Best Practices[¶](#id74 "Link to this heading")

* Instead of foreign tables in Teradata, you can use [Snowflake external tables](https://docs.snowflake.com/en/user-guide/tables-external.html). External tables reference data files located in a cloud storage (Amazon S3, Google Cloud Storage, or Microsoft Azure) data lake. This enables querying data stored in files in a data lake as if it were inside a database. External tables can access data stored in any format supported by [COPY INTO <table>](https://docs.snowflake.com/en/sql-reference/sql/copy-into-table.html) statements.
* Another alternative is [Snowflake’s Iceberg tables](https://www.snowflake.com/blog/iceberg-tables-powering-open-standards-with-snowflake-innovations/?lang=es). So, you can think of Iceberg tables as tables that use open formats and customer-supplied cloud storage. This data is stored in Parquet files.
* Finally, there are the [standard Snowflake tables](https://docs.snowflake.com/en/sql-reference/sql/create-table.html) which can be an option to cover the functionality of foreign tables in Teradata
* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0018[¶](#ssc-fdm-td0018 "Link to this heading")

JSON path was not recognized

Note

This FDM is deprecated, please refer to [SSC-EWI-TD0063](../conversion-issues/teradataEWI.html#ssc-ewi-td0063) documentation

### Description[¶](#id75 "Link to this heading")

This message is shown when SnowConvert AI cannot deserialize a Json path, because the string does not have the expected format or is not supported in snowflake.

#### Example code[¶](#id76 "Link to this heading")

##### Input Code:[¶](#id77 "Link to this heading")

```
 SELECT
    *
FROM
JSON_TABLE (
    ON (
        SELECT
            id,
            trainSchedule as ts
        FROM
            demo.PUBLIC.Train T
    ) USING rowexpr('$weekShedule.Monday[*]') colexpr(
        '[{"jsonpath"  "$.time",
              "type"" : "CHAR ( 12 )"}]'
    )
) AS JT(Id, Ordinal, Time, City);
```

Copy

##### Generated Code:[¶](#id78 "Link to this heading")

```
 SELECT
    *
FROM
    --** SSC-FDM-TD0018 - UNRECOGNIZED JSON PATH $weekShedule.Monday[*] **
JSON_TABLE (
    ON
       !!!RESOLVE EWI!!! /*** SSC-EWI-0108 - THE FOLLOWING SUBQUERY MATCHES AT LEAST ONE OF THE PATTERNS CONSIDERED INVALID AND MAY PRODUCE COMPILATION ERRORS ***/!!! (
           SELECT
               id,
               trainSchedule as ts
FROM
               demo.PUBLIC.Train T
    ) USING rowexpr('$weekShedule.Monday[*]') colexpr(
        '[{"jsonpath"  "$.time",
              "type"" : "CHAR ( 12 )"}]'
    )
) AS JT(Id, Ordinal, Time, City);
```

Copy

#### Best Practices[¶](#id79 "Link to this heading")

* Check if the Json path have an unexpected character, or do not have the right format.
* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0019[¶](#ssc-fdm-td0019 "Link to this heading")

Transaction and profile level query tags not supported in Snowflake, referencing session query tag instead

### Description[¶](#id80 "Link to this heading")

Teradata allows users to define query bands at transaction, session, and profile levels, as well as consulting them with functions like GetQueryBandValue.

Snowflake equivalent for query bands is the query\_tag parameter, which can be set for session, user or account. Also, Snowflake does not have profiles.

Due to these differences, this FMD is added to warn the user that transaction or profile-level query tags can not be defined nor consulted in Snowflake and that session-level query tags will be used as a replacement, which may cause functional differences in some cases.

#### Example Code[¶](#id81 "Link to this heading")

##### Input Code:[¶](#id82 "Link to this heading")

```
 SELECT GETQUERYBANDVALUE(3, 'account');
```

Copy

##### Generated Code[¶](#id83 "Link to this heading")

```
 SELECT
--** SSC-FDM-TD0019 - TRANSACTION AND PROFILE LEVEL QUERY TAGS NOT SUPPORTED IN SNOWFLAKE, REFERENCING SESSION QUERY TAG INSTEAD **
GETQUERYBANDVALUE_UDF('account');
```

Copy

#### Best Practices[¶](#id84 "Link to this heading")

* Modify your code logic to use query bands at the session level.
* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0020[¶](#ssc-fdm-td0020 "Link to this heading")

JSON value was not recognized due to invalid format

Note

Some parts in the output code are omitted for clarity reasons.

### Description[¶](#id85 "Link to this heading")

This message is shown when SnowConvert AI needs to deserialize JSON data for a transformation context, but the JSON value didn’t have the expected format or is not valid JSON.

#### Example code[¶](#id86 "Link to this heading")

##### Input Code:[¶](#id87 "Link to this heading")

```
 SELECT
*
FROM 
 JSON_TABLE
(ON (SELECT id,
trainSchedule as ts
FROM demo.PUBLIC.Train T)
USING rowexpr('$.weekShedule.Monday[*]')
      colexpr('[ {"ordinal"  true},
                 {"jsonpath"  "$.time",
                  "type"" : "CHAR ( 12 )"},
                 {"jsonpath"  "$.city",
                  "type" : "VARCHAR ( 12 )"}]'))
AS JT(Id, Ordinal, Time, City);

SELECT
*
FROM 
 JSON_TABLE
(ON (SELECT id, 
trainSchedule as ts
FROM demo.PUBLIC.Train T)
USING rowexpr('$.weekShedule.Monday[*]')
      colexpr('{"jsonpath"  "$.time",
                  "type"" : "CHAR ( 12 )"}'))
AS JT(Id, Ordinal, Time, City);
```

Copy

##### Generated Code:[¶](#id88 "Link to this heading")

```
 SELECT
 *
 FROM
 (
  SELECT
   id
  --** SSC-FDM-TD0020 - UNRECOGNIZED JSON LITERAL [ {"ordinal" true}, {"jsonpath" "$.time", "type"" : "CHAR ( 12 )"}, {"jsonpath" "$.city", "type" : "VARCHAR ( 12 )"}] **
  FROM
   demo.PUBLIC.Train T,
   TABLE(FLATTEN(INPUT =>
   trainSchedule:weekShedule.Monday)) rowexpr
 ) JT;

 SELECT
 *
 FROM
 (
  SELECT
   id
  --** SSC-FDM-TD0020 - UNRECOGNIZED JSON LITERAL {"jsonpath" "$.time", "type"" : "CHAR ( 12 )"} **
  FROM
   demo.PUBLIC.Train T,
   TABLE(FLATTEN(INPUT =>
   trainSchedule:weekShedule.Monday)) rowexpr
 ) JT;
```

Copy

#### Best Practices[¶](#id89 "Link to this heading")

* Be sure the JSON has the expected format according to the Teradata grammar.
* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0021[¶](#ssc-fdm-td0021 "Link to this heading")

Built-in reference to {0} is not supported in Snowflake.

Note

This EWI is deprecated, please refer to [SSC-EWI-TD0046](../conversion-issues/teradataEWI.html#ssc-ewi-td0046) documentation

### Description[¶](#id90 "Link to this heading")

This error appears when a query referencing [DBC.DATABASES](https://www.docs.teradata.com/r/hNI_rA5LqqKLxP~Y8vJPQg/GqTx8VuBIkfaC4fso9f5cw) table is executed, and the selected column has no equivalence in Snowflake.

#### Example Code[¶](#id91 "Link to this heading")

##### Input:[¶](#input "Link to this heading")

```
 CREATE VIEW SAMPLE_VIEW
AS
SELECT PROTECTIONTYPE FROM DBC.DATABASES;
```

Copy

##### Output:[¶](#output "Link to this heading")

```
 CREATE OR REPLACE VIEW SAMPLE_VIEW
COMMENT = '{ "origin": "sf_sc", "name": "snowconvert", "version": {  "major": 0,  "minor": 0,  "patch": "0" }, "attributes": {  "component": "teradata",  "convertedOn": "08/14/2024" }}'
AS
SELECT
!!!RESOLVE EWI!!! /*** SSC-EWI-TD0046 - BUILT-IN REFERENCE TO PROTECTIONTYPE IS NOT SUPPORTED IN SNOWFLAKE ***/!!!
PROTECTIONTYPE FROM
INFORMATION_SCHEMA.DATABASES;
```

Copy

#### Best Practices[¶](#id92 "Link to this heading")

* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0022[¶](#ssc-fdm-td0022 "Link to this heading")

Shell variables found, running this code in a shell script is required.

### Description[¶](#id93 "Link to this heading")

In Teradata scripts, shell variables are used to store temporary values that can be accessed and manipulated throughout the script. Shell variables are defined using the dollar sign ($) followed by a name (which can be enclosed by curly braces), and their values can be set using the assignment operator (=).

```
#!/bin/bash

## define a shell variable
tablename="mytable"

## use the variable in a Teradata SQL query
bteq <<EOF
    .LOGON myhost/myuser,mypassword
    SELECT * FROM ${tablename};
    .LOGOFF
EOF
```

Copy

You can think of shell variables having the same or similar function as string interpolation. Thus, it is important to keep this functionality when transformed.  
  
When converting Scripts to Python, shell variables keep their functionality by running the converted code in a shell script (.sh file). For this reason, these shell variables must keep the same format as the input code.

### Example Code[¶](#id94 "Link to this heading")

#### Input Code:[¶](#id95 "Link to this heading")

```
 SELECT $column FROM ${tablename}
```

Copy

##### Generated Code[¶](#id96 "Link to this heading")

```
 #*** Generated code is based on the SnowConvert AI Python Helpers version 2.0.6 ***
 
import os
import sys
import snowconvert.helpers
from snowconvert.helpers import Export
from snowconvert.helpers import exec
from snowconvert.helpers import BeginLoading
con = None
#** SSC-FDM-TD0022 - SHELL VARIABLES FOUND, RUNNING THIS CODE IN A SHELL SCRIPT IS REQUIRED **
def main():
  snowconvert.helpers.configure_log()
  con = snowconvert.helpers.log_on()
  exec("""
    SELECT
      $column
    FROM
      ${tablename}
    """)
  snowconvert.helpers.quit_application()

if __name__ == "__main__":
  main()
```

Copy

#### Best Practices[¶](#id97 "Link to this heading")

* Running the converted code in a shell script is required.
* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0023[¶](#ssc-fdm-td0023 "Link to this heading")

String Similarity might have a different behavior.

### Description[¶](#id98 "Link to this heading")

This FDM is shown when SnowConvert AI transforms the Similarity Function from Teradata to Snowflake. It indicates the results might have different behavior.

#### Example Code[¶](#id99 "Link to this heading")

Given the following data as an example

| Id | a | b |
| --- | --- | --- |
| 1 |  |  |
| 2 | Gute nacht | Ich weis nicht |
| 3 | Ich weiß nicht | Ich wei? nicht |
| 4 | Ich weiß nicht | Ich wei? nicht |
| 5 | Ich weiß nicht | Ich weiss nicht |
| 6 | Snowflake | Oracle |
| 7 | święta | swieta |
| 8 | NULL |  |
| 9 | NULL | NULL |

##### Input Code:[¶](#id100 "Link to this heading")

##### Query[¶](#query "Link to this heading")

```
-- Additional Params: -q SnowScript
SELECT * FROM StringSimilarity (
  ON (
    SELECT id, CAST(a AS VARCHAR(200)) AS a, CAST(b AS VARCHAR(200)) AS b
    FROM table_1
  ) PARTITION BY ANY
  USING
  ComparisonColumnPairs ('jaro_winkler(a,b) AS sim_fn')
  Accumulate ('id')
) AS dt ORDER BY 1;
```

Copy

##### Result[¶](#result "Link to this heading")

| Id | sim\_fn |
| --- | --- |
| 1 | 0 |
| 2 | 0.565079365 |
| 3 | 1 |
| 4 | 0.959047619 |
| 5 | 0 |
| 6 | 0.611111111 |
| 7 | 0.7777777777777777 |
| 8 | 0 |
| 9 | 0 |

##### Generated Code[¶](#id101 "Link to this heading")

##### Query[¶](#id102 "Link to this heading")

```
 SELECT
* FROM
--** SSC-FDM-TD0023 - STRING SIMILARITY MIGHT HAVE A DIFFERENT BEHAVIOR. **
(
   SELECT
     id,
     JAROWINKLER_UDF(a, b) AS sim_fn
   FROM table_1
 ) dt ORDER BY 1;
```

Copy

##### Result[¶](#id103 "Link to this heading")

| ID | SIM\_FN |
| --- | --- |
| 1 | 0.000000 |
| 2 | 0.560000 |
| 3 | 0.970000 |
| 4 | 0.950000 |
| 5 | 0.000000 |
| 6 | 0.610000 |
| 7 | 0.770000 |
| 8 | 0.000000 |
| 9 | 0.000000 |

#### Best Practices[¶](#id104 "Link to this heading")

* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0024[¶](#ssc-fdm-td0024 "Link to this heading")

Set table functionality not supported.

### Description[¶](#id105 "Link to this heading")

This EWI is shown when SnowConvert AI finds a Create Table with the SET option. Since the SET TABLE is not supported in Snowflake, it is removed.

#### Example Code[¶](#id106 "Link to this heading")

##### Teradata:[¶](#id107 "Link to this heading")

```
 CREATE SET TABLE TableExample
(
ColumnExample Number
)
```

Copy



```
 CREATE SET VOLATILE TABLE SOMETABLE, LOG AS 
(SELECT ColumnExample FROM TableExample);
```

Copy

##### Snowflake Scripting:[¶](#id108 "Link to this heading")

```
 --** SSC-FDM-TD0024 - SET TABLE FUNCTIONALITY NOT SUPPORTED. TABLE MIGHT HAVE DUPLICATE ROWS **
CREATE OR REPLACE TABLE TableExample
(
ColumnExample NUMBER(38, 18)
)
COMMENT = '{"origin":"sf_sc","name":"snowconvert","version":{"major":1, "minor":0},{"attributes":{"component":"teradata"}}'
;
```

Copy



```
 --** SSC-FDM-TD0024 - SET TABLE FUNCTIONALITY NOT SUPPORTED. TABLE MIGHT HAVE DUPLICATE ROWS **
CREATE OR REPLACE TEMPORARY TABLE SOMETABLE
COMMENT = '{"origin":"sf_sc","name":"snowconvert","version":{"major":1, "minor":0},{"attributes":{"component":"teradata"}}'
AS
(
SELECT
ColumnExample FROM
TableExample
);
```

Copy

#### Best Practices[¶](#id109 "Link to this heading")

* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0025[¶](#ssc-fdm-td0025 "Link to this heading")

Teradata Database Temporal Table is not supported in Snowflake

### Description[¶](#id110 "Link to this heading")

The [Teradata Database Temporal Support](https://docs.teradata.com/r/0TSAVrLIwk23SLHbA4nUvQ/root) involves the creation of temporal tables and temporal DDL and DML objects. The support for temporal (time-aware) tables and data are not supported in Snowflake since there is not an absolute equivalent.

All these statements are recognized (parsed) by SnowConvert AI, but to execute the queries in Snowflake, these elements are removed in the translation process.

It is worth noting that in cases where an `abort` statement is encountered, it will be transformed into a `Delete` command to keep the equivalence functionality allows you to undo operations performed during a transaction and restore the database to the state it had at the beginning.

#### Example code[¶](#id111 "Link to this heading")

The following example shows a Temporal-form Select being translated to a usual Select.

##### Input code:[¶](#id112 "Link to this heading")

```
 SEQUENCED VALIDTIME  
   SELECT
   Policy_ID,
   Customer_ID
   FROM Policy
      WHERE Policy_Type = 'AU';
```

Copy

##### Generated Code:[¶](#id113 "Link to this heading")

```
 ----** SSC-FDM-TD0025 - TEMPORAL FORMS ARE NOT SUPPORTED IN SNOWFLAKE **
--SEQUENCED VALIDTIME
SELECT
   Policy_ID,
   Customer_ID
   FROM
   Policy
      WHERE
   UPPER(RTRIM( Policy_Type)) = UPPER(RTRIM('AU'));
```

Copy

Case where the `Abort` command is used in the context of a transaction.

##### Input code:[¶](#id114 "Link to this heading")

```
 CREATE OR REPLACE PROCEDURE TEST.ABORT_STATS()
BEGIN
    CURRENT VALIDTIME AND NONSEQUENCED TRANSACTIONTIME ABORT 
     FROM table_1 
     WHERE table_1.x1 = 1;
END;
```

Copy

##### Generated Code:[¶](#id115 "Link to this heading")

```
 CREATE OR REPLACE PROCEDURE TEST.ABORT_STATS ()
RETURNS VARCHAR
LANGUAGE SQL
COMMENT = '{"origin":"sf_sc","name":"snowconvert","version":{"major":1, "minor":0},{"attributes":{"component":"teradata"}}'
EXECUTE AS CALLER
AS
$$
    BEGIN
        --    CURRENT VALIDTIME AND NONSEQUENCED TRANSACTIONTIME
        --** SSC-FDM-TD0025 - TEMPORAL FORMS ARE NOT SUPPORTED IN SNOWFLAKE **
        LET _ROW_COUNT FLOAT;
        SELECT
            COUNT(*)
        INTO
            _ROW_COUNT
            FROM
            table_1
                 WHERE table_1.x1 = 1;
            IF (_ROW_COUNT > 0) THEN
            ROLLBACK;
            END IF;
    END;
$$;
```

Copy

#### [¶](#id116 "Link to this heading")

#### Best Practices[¶](#id117 "Link to this heading")

* No additional user actions are required.
* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0026[¶](#ssc-fdm-td0026 "Link to this heading")

GOTO statement was removed due to if statement inversion.

Note

Some parts in the output code are omitted for clarity reasons.

### Description [¶](#id118 "Link to this heading")

It is common to use GOTO command with IF and LABEL commands to replicate the functionality of an SQL if statement. When used in this way, it is possible to transform them directly into an if, if-else, or even an if-elseif-else statement. However, in these cases, the GOTO commands become unnecessary and should be removed to prevent them from being replaced by a LABEL section.

#### Example Code [¶](#id119 "Link to this heading")

**Input Code:**

```
 -- Additional Params: --scriptsTargetLanguage SnowScript
.If ActivityCount = 0 THEN .GOTO endIf
DROP TABLE TABLE1;
.Label endIf
SELECT A FROM TABLE1;
```

Copy

**Output Code**

```
 EXECUTE IMMEDIATE
$$
  DECLARE
    STATUS_OBJECT OBJECT := OBJECT_CONSTRUCT('SQLCODE', 0);
  BEGIN
    IF (NOT (STATUS_OBJECT['SQLROWCOUNT'] = 0)) THEN
      --** SSC-FDM-TD0026 - GOTO endIf WAS REMOVED DUE TO IF STATEMENT INVERSION **
       
      BEGIN
        DROP TABLE TABLE1;
        STATUS_OBJECT := OBJECT_CONSTRUCT('SQLROWCOUNT', SQLROWCOUNT);
      EXCEPTION
        WHEN OTHER THEN
          STATUS_OBJECT := OBJECT_CONSTRUCT('SQLCODE', SQLCODE, 'SQLERRM', SQLERRM, 'SQLSTATE', SQLSTATE);
      END;
    END IF;
    /*.Label endIf*/
    --** SSC-FDM-0027 - REMOVED NEXT STATEMENT, NOT APPLICABLE IN SNOWFLAKE.  **
     
    BEGIN
      SELECT
        A
      FROM
        TABLE1;
      STATUS_OBJECT := OBJECT_CONSTRUCT('SQLROWCOUNT', SQLROWCOUNT);
    EXCEPTION
      WHEN OTHER THEN
        STATUS_OBJECT := OBJECT_CONSTRUCT('SQLCODE', SQLCODE, 'SQLERRM', SQLERRM, 'SQLSTATE', SQLSTATE);
    END;
  END
$$
```

Copy

##### Best Practices [¶](#id120 "Link to this heading")

* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0027[¶](#ssc-fdm-td0027 "Link to this heading")

TD\_UNPIVOT transformation requires column information that could not be found, columns missing in result

Note

This FDM is deprecated, please refer to [SSC-EWI-TD0061](../conversion-issues/teradataEWI.html#ssc-ewi-td0061) documentation.

### Description[¶](#id121 "Link to this heading")

SnowConvert AI supports and transforms the [TD\_UNPIVOT](https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/SQL-Operators-and-User-Defined-Functions/Table-Operators/TD_UNPIVOT) function, which can be used to represent columns from a table as rows.

However, this transformation requires information about the table/tables columns to work, more specifically the names of the columns. When this information is not present the transformation may be left in an incomplete state where columns are missing from the result, this EWI is generated in these cases.

#### Example code[¶](#id122 "Link to this heading")

##### Input Code:[¶](#id123 "Link to this heading")

```
 CREATE TABLE unpivotTable  (
	myKey INTEGER NOT NULL PRIMARY KEY,
	firstSemesterIncome DECIMAL(10,2),
	secondSemesterIncome DECIMAL(10,2),
	firstSemesterExpenses DECIMAL(10,2),
	secondSemesterExpenses DECIMAL(10,2)
);

SELECT * FROM
 TD_UNPIVOT(
 	ON unpivotTable 
 	USING
 	VALUE_COLUMNS('Income', 'Expenses')
 	UNPIVOT_COLUMN('Semester')
 	COLUMN_LIST('firstSemesterIncome, firstSemesterExpenses', 'secondSemesterIncome, secondSemesterExpenses')
 	COLUMN_ALIAS_LIST('First', 'Second')
 )X ORDER BY mykey;

SELECT * FROM
 TD_UNPIVOT(
 	ON unknownTable
 	USING
 	VALUE_COLUMNS('MonthIncome')
 	UNPIVOT_COLUMN('Months')
 	COLUMN_LIST('januaryIncome', 'februaryIncome', 'marchIncome', 'aprilIncome')
 	COLUMN_ALIAS_LIST('January', 'February', 'March', 'April')
 )X ORDER BY yearKey;
```

Copy

##### Generated Code:[¶](#id124 "Link to this heading")

```
 CREATE TABLE unpivotTable (
	myKey INTEGER NOT NULL PRIMARY KEY,
	firstSemesterIncome DECIMAL(10,2),
	secondSemesterIncome DECIMAL(10,2),
	firstSemesterExpenses DECIMAL(10,2),
	secondSemesterExpenses DECIMAL(10,2)
)
COMMENT = '{"origin":"sf_sc","name":"snowconvert","version":{"major":1, "minor":0},{"attributes":{"component":"teradata"}}'
;

SELECT
	* FROM
	(
		SELECT
			myKey,
			TRIM(GET_IGNORE_CASE(OBJECT_CONSTRUCT('FIRSTSEMESTERINCOME', 'First', 'FIRSTSEMESTEREXPENSES', 'First', 'SECONDSEMESTERINCOME', 'Second', 'SECONDSEMESTEREXPENSES', 'Second'), Semester), '"') AS Semester,
			Income,
			Expenses
		FROM
			unpivotTable UNPIVOT(Income FOR Semester IN (
				firstSemesterIncome,
				secondSemesterIncome
			)) UNPIVOT(Expenses FOR Semester1 IN (
				firstSemesterExpenses,
				secondSemesterExpenses
			))
		WHERE
			Semester = 'FIRSTSEMESTERINCOME'
			AND Semester1 = 'FIRSTSEMESTEREXPENSES'
			OR Semester = 'SECONDSEMESTERINCOME'
			AND Semester1 = 'SECONDSEMESTEREXPENSES'
	) X ORDER BY mykey;

	SELECT
	* FROM
	--** SSC-FDM-TD0027 - TD_UNPIVOT TRANSFORMATION REQUIRES COLUMN INFORMATION THAT COULD NOT BE FOUND, COLUMNS MISSING IN RESULT **
	(
		SELECT
			TRIM(GET_IGNORE_CASE(OBJECT_CONSTRUCT('JANUARYINCOME', 'January', 'FEBRUARYINCOME', 'February', 'MARCHINCOME', 'March', 'APRILINCOME', 'April'), Months), '"') AS Months,
			MonthIncome
		FROM
			unknownTable UNPIVOT(MonthIncome FOR Months IN (
				januaryIncome,
				februaryIncome,
				marchIncome,
				aprilIncome
			))
	) X ORDER BY yearKey;
```

Copy

#### Best Practices[¶](#id125 "Link to this heading")

* There are two ways of supplying the information about columns to the conversion tool: put the table specification in the same file as the TD\_UNPIVOT call or specify a column list in the SELECT query of the ON expression instead of SELECT \* or the table name.
* This issue can be safely ignored if ALL the columns from the input table/tables are unpivoted, otherwise, the result will have missing columns.
* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0028[¶](#ssc-fdm-td0028 "Link to this heading")

JSON\_TABLE not transformed, column names could not be retrieved from semantic information

Note

This FDM is deprecated, please refer to [SSC-EWI-TD0060](../conversion-issues/teradataEWI.html#ssc-ewi-td0060) documentation.

### Description[¶](#id126 "Link to this heading")

The JSON\_TABLE function can be transformed by SnowConvert AI, however, this transformation requires knowing the name of the columns that are being selected in the JSON\_TABLE ON subquery.

This message is generated to warn the user that the column names were not explicitly put in the subquery (for example, a SELECT \* was used) and the semantic information of the tables being referenced was not found, meaning the column names could not be extracted.

#### Example code[¶](#id127 "Link to this heading")

##### Input Code:[¶](#id128 "Link to this heading")

```
 CREATE TABLE demo.Train (
    firstCol INT,
    jsonCol JSON(400),
    thirdCol VARCHAR(30)
);

SELECT * FROM JSON_TABLE 
(ON (SELECT T.*
           FROM demo.Train T)
USING rowexpr('$.schools[*]')
               colexpr('[ {"jsonpath" : "$.name",
                           "type" : "CHAR(20)"},
                          {"jsonpath" : "$.type",
                           "type" : "VARCHAR(20)"}]')
)
AS JT;

SELECT * FROM JSON_TABLE 
(ON (SELECT T.*
           FROM demo.missingTable T)
USING rowexpr('$.schools[*]')
               colexpr('[ {"jsonpath" : "$.name",
                           "type" : "CHAR(20)"},
                          {"jsonpath" : "$.type",
                           "type" : "VARCHAR(20)"}]')
)
AS JT;
```

Copy

##### Generated Code:[¶](#id129 "Link to this heading")

```
 CREATE TABLE demo.Train (
    firstCol INT,
    jsonCol VARIANT,
    thirdCol VARCHAR(30)
)
COMMENT = '{"origin":"sf_sc","name":"snowconvert","version":{"major":1, "minor":0},"attributes":{"component":"teradata"}}'
;

SELECT
    * FROM
    (
        SELECT
            firstCol,
            rowexpr.value:name :: CHAR(20) AS Column_0,
            rowexpr.value:type :: VARCHAR(20) AS Column_1,
            thirdCol
        FROM
            demo.Train T,
            TABLE(FLATTEN(INPUT => jsonCol:schools)) rowexpr
    ) JT;

    SELECT
    * FROM
    --** SSC-FDM-TD0028 - JSON_TABLE NOT TRANSFORMED, COLUMN NAMES COULD NOT BE RETRIEVED FROM SEMANTIC INFORMATION **
    JSON_TABLE
   (ON
       !!!RESOLVE EWI!!! /*** SSC-EWI-0108 - THE FOLLOWING SUBQUERY MATCHES AT LEAST ONE OF THE PATTERNS CONSIDERED INVALID AND MAY PRODUCE COMPILATION ERRORS ***/!!! (
        SELECT
            T.*
                  FROM
            demo.missingTable T)
   USING rowexpr('$.schools[*]')
                  colexpr('[ {"jsonpath" : "$.name",
                           "type" : "CHAR(20)"},
                          {"jsonpath" : "$.type",
                           "type" : "VARCHAR(20)"}]')
   )
   AS JT;
```

Copy

#### Best Practices[¶](#id130 "Link to this heading")

* Please check the code provided to SnowConvert AI is complete, if you did not provide the table definition please re-execute the code with the table definition present.
* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0029[¶](#ssc-fdm-td0029 "Link to this heading")

Snowflake supported formats for TO\_CHAR differ from Teradata and may fail or have different behavior

### Format elements that depend on session parameters[¶](#format-elements-that-depend-on-session-parameters "Link to this heading")

Some Teradata format elements are mapped to Snowflake functions that depend on the value of session parameters. To avoid functional differences in the results you should set these session parameters to the same values they have in Teradata. Identified format elements that are mapped to this kind of functions are:

* **D**: Mapped to `DAYOFWEEK` function, the results of this function depend on the `WEEK_START` session parameter, by default Teradata considers Sunday as the first day of the week, while in Snowflake it is Monday.
* **WW**: Mapped to `WEEK` function, this function depends on the session parameter `WEEK_OF_YEAR_POLICY` which by default is set to use the ISO standard (the first week of year is the first to contain at least four days of January) but in Teradata is set to consider January first as the start of the first week.

To modify session parameters, use `ALTER SESSION SET parameter_name = value`. for more information about session parameters visit [this page](https://docs.snowflake.com/en/sql-reference/parameters.html).

#### Single parameter version of TO\_CHAR[¶](#single-parameter-version-of-to-char "Link to this heading")

The single parameter version of `TO_CHAR(Datetime)` makes use of the default formats specified in the session parameters `TIMESTAMP_LTZ_OUTPUT_FORMAT`, `TIMESTAMP_NTZ_OUTPUT_FORMAT`, `TIMESTAMP_TZ_OUTPUT_FORMAT` and `TIME_OUTPUT_FORMAT`. To avoid differences in behavior please set them to the same values used in Teradata.

For `TO_CHAR(Numeric)` Snowflake generates the varchar representation using either the `TM9` or `TME` formats to get a compact representation of the number, Teradata also generates compact representations of the numbers so no action is required.

#### Example Code[¶](#id131 "Link to this heading")

##### Input Code:[¶](#id132 "Link to this heading")

```
 select to_char(date '2008-09-13', 'DD/RM/YYYY');

select to_char(date '2010-10-20', 'DS');

select to_char(1255.495, 'SC9999.9999', 'nls_iso_currency = ''EUR''');

select to_char(45620);
```

Copy

##### Generated Code:[¶](#id133 "Link to this heading")

```
 SELECT
TO_CHAR(date '2008-09-13', 'DD/') || PUBLIC.ROMAN_NUMERALS_MONTH_UDF(date '2008-09-13') || TO_CHAR(date '2008-09-13', '/YYYY') /*** SSC-FDM-TD0029 - SNOWFLAKE SUPPORTED FORMATS FOR TO_CHAR DIFFER FROM TERADATA AND MAY FAIL OR HAVE DIFFERENT BEHAVIOR ***/;

SELECT
TO_CHAR(date '2010-10-20', 'MM/DD/YYYY') /*** SSC-FDM-TD0029 - SNOWFLAKE SUPPORTED FORMATS FOR TO_CHAR DIFFER FROM TERADATA AND MAY FAIL OR HAVE DIFFERENT BEHAVIOR ***/;

SELECT
PUBLIC.INSERT_CURRENCY_UDF(TO_CHAR(1255.495, 'S9999.0000'), 2, 'EUR') /*** SSC-FDM-TD0029 - SNOWFLAKE SUPPORTED FORMATS FOR TO_CHAR DIFFER FROM TERADATA AND MAY FAIL OR HAVE DIFFERENT BEHAVIOR ***/;

SELECT
TO_CHAR(45620) /*** SSC-FDM-TD0029 - SNOWFLAKE SUPPORTED FORMATS FOR TO_CHAR DIFFER FROM TERADATA AND MAY FAIL OR HAVE DIFFERENT BEHAVIOR ***/;
```

Copy

### Best Practices[¶](#id134 "Link to this heading")

* When using FF either try to use DateTime types with the same precision that you use in Teradata or add a precision to the format element to avoid the different behavior.
* When using timezone-related format elements, use the first parameter of type `TIMESTAMP_TZ` to avoid different behavior. Also remember that the `TIME` type cannot have time zone information in Snowflake.
* Set the necessary session parameters with the default values from Teradata to avoid different behavior.
* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0030[¶](#ssc-fdm-td0030 "Link to this heading")

A return statement was added at the end of the label section to ensure the same execution flow

### Description[¶](#id135 "Link to this heading")

When a Goto statement is replaced with a Label section and does not contain a return statement, one is added at the end of the section to ensure the same execution flow.

BTEQ after a Goto command is executed, the statements between the goto command and the label command with the same name are ignored. So, to avoid those statements being executed the label section should contain a return statement.

In addition, it is worth value mentioning the Goto command skips all the other statements except for the Label with the same name, which is when the execution resumes. Therefore, the execution will never resume in a label section defined before the Goto command.

#### Example Code[¶](#id136 "Link to this heading")

##### Input Code:[¶](#id137 "Link to this heading")

```
 -- Additional Params: --scriptsTargetLanguage SnowScript
.LOGON dbc,dbc;
select 'STATEMENTS';
.GOTO LABEL_B
select 'IGNORED STATEMENTS';
.label LABEL_B
select 'LABEL_B STATEMENTS';
```

Copy

##### Generated Code[¶](#id138 "Link to this heading")

```
 EXECUTE IMMEDIATE
$$
  DECLARE
    STATUS_OBJECT OBJECT := OBJECT_CONSTRUCT('SQLCODE', 0);
  BEGIN
    -- Additional Params: --scriptsTargetLanguage SnowScript
    --.LOGON dbc,dbc
    !!!RESOLVE EWI!!! /*** SSC-EWI-0073 - PENDING FUNCTIONAL EQUIVALENCE REVIEW FOR 'BTLogOn' NODE ***/!!!
    null;
    BEGIN
      SELECT
        'STATEMENTS';
      STATUS_OBJECT := OBJECT_CONSTRUCT('SQLROWCOUNT', SQLROWCOUNT);
    EXCEPTION
      WHEN OTHER THEN
        STATUS_OBJECT := OBJECT_CONSTRUCT('SQLCODE', SQLCODE, 'SQLERRM', SQLERRM, 'SQLSTATE', SQLSTATE);
    END;
     
    /*.label LABEL_B*/
     
    BEGIN
      SELECT
        'LABEL_B STATEMENTS';
      STATUS_OBJECT := OBJECT_CONSTRUCT('SQLROWCOUNT', SQLROWCOUNT);
    EXCEPTION
      WHEN OTHER THEN
        STATUS_OBJECT := OBJECT_CONSTRUCT('SQLCODE', SQLCODE, 'SQLERRM', SQLERRM, 'SQLSTATE', SQLSTATE);
    END;
    --** SSC-FDM-TD0030 - A RETURN STATEMENT WAS ADDED AT THE END OF THE LABEL SECTION LABEL_B TO ENSURE THE SAME EXECUTION FLOW **
    RETURN 0;
    BEGIN
      SELECT
        'IGNORED STATEMENTS';
      STATUS_OBJECT := OBJECT_CONSTRUCT('SQLROWCOUNT', SQLROWCOUNT);
    EXCEPTION
      WHEN OTHER THEN
        STATUS_OBJECT := OBJECT_CONSTRUCT('SQLCODE', SQLCODE, 'SQLERRM', SQLERRM, 'SQLSTATE', SQLSTATE);
    END;
    /*.label LABEL_B*/
    --** SSC-FDM-0027 - REMOVED NEXT STATEMENT, NOT APPLICABLE IN SNOWFLAKE.  **
     
    BEGIN
      SELECT
        'LABEL_B STATEMENTS';
      STATUS_OBJECT := OBJECT_CONSTRUCT('SQLROWCOUNT', SQLROWCOUNT);
    EXCEPTION
      WHEN OTHER THEN
        STATUS_OBJECT := OBJECT_CONSTRUCT('SQLCODE', SQLCODE, 'SQLERRM', SQLERRM, 'SQLSTATE', SQLSTATE);
    END;
  END
$$
```

Copy

#### Best Practices[¶](#id139 "Link to this heading")

* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0031[¶](#ssc-fdm-td0031 "Link to this heading")

ST\_DISTANCE results are slightly different from ST\_SPHERICALDISTANCE

### Description[¶](#id140 "Link to this heading")

The Teradata function ST\_SPHERICALDISTANCE calculates the distance between two spherical coordinates on the planet using the Haversine formula, on the other side, the Snowflake ST\_DISTANCE function does not utilize the haversine formula to calculate the minimum distance between two geographical points.

#### Example Code[¶](#id141 "Link to this heading")

##### Input Code:[¶](#id142 "Link to this heading")

```
 --The distance between New York and Los Angeles
Select Cast('POINT(-73.989308 40.741895)' As ST_GEOMETRY) As location1,
	Cast('POINT(40.741895 34.053691)' As ST_GEOMETRY) As location2,
	location1.ST_SPHERICALDISTANCE(location2) As Distance_In_km;
```

Copy

##### Teradata Output[¶](#teradata-output "Link to this heading")

| location1 | location2 | Distance\_In\_Km |
| --- | --- | --- |
| POINT (-73.989308 40.741895) | POINT (40.741895 34.053691) | 9351139.978062356 |

##### Generated Code[¶](#id143 "Link to this heading")

```
 --The distance between New York and Los Angeles
SELECT
	TO_GEOGRAPHY('POINT(-73.989308 40.741895)') As location1,
	TO_GEOGRAPHY('POINT(40.741895 34.053691)') As location2,
	--** SSC-FDM-TD0031 - ST_DISTANCE RESULTS ARE SLIGHTLY DIFFERENT FROM ST_SPHERICALDISTANCE **
	ST_DISTANCE(
	location1, location2) As Distance_In_km;
```

Copy

##### Snowflake Output[¶](#snowflake-output "Link to this heading")

| LOCATION1 | LOCATION2 | DISTANCE\_IN\_KM |
| --- | --- | --- |
| { “coordinates”: [ -73.989308, 40.741895 ], “type”: “Point” } | { “coordinates”: [ 40.741895, 34.053691 ], “type”: “Point” } | 9351154.65572674 |

#### Best Practices[¶](#id144 "Link to this heading")

* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0032[¶](#ssc-fdm-td0032 "Link to this heading")

CASESPECIFIC clause was removed from LIKE expression

Note

Some parts in the output code are omitted for clarity reasons.

### Description[¶](#id145 "Link to this heading")

This error appears when the `LIKE` expression is accompanied by the `[NOT] CASESPECIFIC` clause.

#### Example Code[¶](#id146 "Link to this heading")

##### Input Code:[¶](#id147 "Link to this heading")

```
 SELECT * FROM MY_TABLE
WHERE Name Like 'Marco%' (NOT CASESPECIFIC);
```

Copy

##### Generated Code[¶](#id148 "Link to this heading")

```
 SELECT
    * FROM
    MY_TABLE
WHERE Name ILIKE 'Marco%' /*** SSC-FDM-TD0032 - NOT CASESPECIFIC CLAUSE WAS REMOVED ***/;
```

Copy

#### Best Practices[¶](#id149 "Link to this heading")

* Case-Specific Behavior in TERADATA depends on TMODE system configuration.
* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0033[¶](#ssc-fdm-td0033 "Link to this heading")

ACTIVITY\_COUNT transformation might require manual adjustments

### Description[¶](#id150 "Link to this heading")

The `ACTIVITY_COUNT` status variable returns the number of rows affected by an SQL DML statement in an embedded SQL or stored procedure application. For more information check [here](https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/SQL-Stored-Procedures-and-Embedded-SQL/Result-Code-Variables/ACTIVITY_COUNT).

As explained in its translation specification, there is a workaround to emulate `ACTIVITY_COUNT`’s behavior through:

```
 SELECT $1 FROM TABLE(RESULT_SCAN(LAST_QUERY_ID()));
```

Copy

However, this presents some limitations listed below.

### Limitations [¶](#limitations "Link to this heading")

#### First case[¶](#first-case "Link to this heading")

If `ACTIVITY_COUNT` is called twice or more times before executing another DML statement, the transformation might not return the expected values.

##### Teradata[¶](#id151 "Link to this heading")

```
 REPLACE PROCEDURE InsertEmployeeSalaryAndLog_1 ()
BEGIN
    DECLARE row_count1 INT;

    INSERT INTO employees (employee_id, first_name, last_name, department_id, salary)
    VALUES (101, 'Alice', 'Smith', 10, 70000.00);

    -- Get the ACTIVITY_COUNT
    SET row_count1 = ACTIVITY_COUNT;
    SET row_count1 = ACTIVITY_COUNT;

    -- Insert the ACTIVITY_COUNT into the activity_log table
    INSERT INTO activity_log (operation, row_count)
    VALUES ('INSERT PROCEDURE', row_count1);
END;

REPLACE PROCEDURE InsertEmployeeSalaryAndLog_2 ()
BEGIN
    DECLARE row_count1 INT;
    DECLARE message VARCHAR(100);

    INSERT INTO employees (employee_id, first_name, last_name, department_id, salary)
    VALUES (101, 'Alice', 'Smith', 10, 70000.00);

    -- Get the ACTIVITY_COUNT
    SET row_count1 = ACTIVITY_COUNT + 1;
    SET row_count1 = ACTIVITY_COUNT;

    -- Insert the ACTIVITY_COUNT into the activity_log table
    INSERT INTO activity_log (operation, row_count)
    VALUES ('INSERT PROCEDURE', row_count1);
END;
```

Copy

##### Snowflake[¶](#snowflake "Link to this heading")

```
 CREATE OR REPLACE PROCEDURE InsertEmployeeSalaryAndLog_1 ()
RETURNS VARCHAR
LANGUAGE SQL
COMMENT = '{ "origin": "sf_sc", "name": "snowconvert", "version": {  "major": 0,  "minor": 0,  "patch": "0" }, "attributes": {  "component": "teradata",  "convertedOn": "07/15/2024" }}'
EXECUTE AS CALLER
AS
$$
    DECLARE
        row_count1 INT;
    BEGIN
         
        INSERT INTO employees (employee_id, first_name, last_name, department_id, salary)
        VALUES (101, 'Alice', 'Smith', 10, 70000.00);

           -- Get the ACTIVITY_COUNT
        row_count1 := (
            SELECT
                $1
            FROM
                TABLE(RESULT_SCAN(LAST_QUERY_ID()))
        ) /*** SSC-FDM-TD0033 - 'ACTIVITY_COUNT' TRANSFORMATION MIGHT REQUIRE MANUAL ADJUSTMENTS ***/;
        row_count1 := (
            SELECT
                $1
            FROM
                TABLE(RESULT_SCAN(LAST_QUERY_ID()))
        ) /*** SSC-FDM-TD0033 - 'ACTIVITY_COUNT' TRANSFORMATION MIGHT REQUIRE MANUAL ADJUSTMENTS ***/;

        -- Insert the ACTIVITY_COUNT into the activity_log table
        INSERT INTO activity_log (operation, row_count)
        VALUES ('INSERT PROCEDURE', :row_count1);
    END;
$$;

CREATE OR REPLACE PROCEDURE InsertEmployeeSalaryAndLog_2 ()
RETURNS VARCHAR
LANGUAGE SQL
COMMENT = '{ "origin": "sf_sc", "name": "snowconvert", "version": {  "major": 0,  "minor": 0,  "patch": "0" }, "attributes": {  "component": "teradata",  "convertedOn": "07/15/2024" }}'
EXECUTE AS CALLER
AS
$$
    DECLARE
        row_count1 INT;
        message VARCHAR(100);
    BEGIN
         
         
        INSERT INTO employees (employee_id, first_name, last_name, department_id, salary)
        VALUES (101, 'Alice', 'Smith', 10, 70000.00);

           -- Get the ACTIVITY_COUNT
        row_count1 := (
            SELECT
                $1
            FROM
                TABLE(RESULT_SCAN(LAST_QUERY_ID()))
        ) /*** SSC-FDM-TD0033 - 'ACTIVITY_COUNT' TRANSFORMATION MIGHT REQUIRE MANUAL ADJUSTMENTS ***/ + 1;
        row_count1 := (
            SELECT
                $1
            FROM
                TABLE(RESULT_SCAN(LAST_QUERY_ID()))
        ) /*** SSC-FDM-TD0033 - 'ACTIVITY_COUNT' TRANSFORMATION MIGHT REQUIRE MANUAL ADJUSTMENTS ***/;

        -- Insert the ACTIVITY_COUNT into the activity_log table
        INSERT INTO activity_log (operation, row_count)
        VALUES ('INSERT PROCEDURE', :row_count1);
    END;
$$;
```

Copy

In both procedures, `ACTIVITY_COUNT` is called twice before another DML statement is called. In Teradata, `ACTIVITY_COUNT` will return the number of rows in the `INSERT` statement above them, even when called twice. However, since the Snowflake transformation uses `LAST_QUERY_ID()`, the result depends on the result set held by `LAST_QUERY_ID()`.

`InsertEmployeeSalaryAndLog_1()` requires no manual adjustments. Check the Query History (bottom-up):

![](../../../../../.gitbook/assets/image (461).png)

Query History when calling InsertEmployeeSalaryAndLog\_1()

1. `INSERT` statement is executed. `LAST_QUERY_ID()` will point to this statement.
2. `SELECT` (first `ACTIVITY_COUNT`) is executed, and `$1` will be `1`. `LAST_QUERY_ID()` will point to this statement.
3. `SELECT` (second `ACTIVITY_COUNT`) is executed; since the last statement result was `1`, `$1` will be `1` for this `SELECT` as well.
4. Finally, `row_count1` holds the value `1`, which is inserted in `activity_log`.

On the other side, `InsertEmployeeSalaryAndLog_2()` does require manual adjustments. Check the Query History (bottom-up):

![](../../../../../.gitbook/assets/image (460).png)

Query History when calling InsertEmployeeSalaryAndLog\_2()

1. `INSERT` statement is executed. `LAST_QUERY_ID()` will point to this statement.
2. SELECT (first `ACTIVITY_COUNT`) is executed, and `$1` will be `1`. However, notice how `QUERY_TEXT` has the `+ 10`; this will affect the result that will be scanned. `LAST_QUERY_ID()` will point to this statement.
3. `SELECT` (second `ACTIVITY_COUNT`) is executed. The result for the last query is `11`; thus `$1` will hold `11` instead of the expected `1`.
4. Finally, `row_count1` holds the value `11`, which is inserted in `activity_log`.

These are the values inserted in `activity_log`:

| LOG\_ID | OPERATION | ROW\_COUNT | LOG\_TIMESTAMP |
| --- | --- | --- | --- |
| 1 | INSERT PROCEDURE | 1 | 2024-07-15 09:22:21.725 |
| 101 | INSERT PROCEDURE | 11 | 2024-07-15 09:22:26.248 |

#### Adjustments for the first case[¶](#adjustments-for-the-first-case "Link to this heading")

As per Snowflake’s documentation for [LAST\_QUERY\_ID](https://docs.snowflake.com/en/sql-reference/functions/last_query_id), you can specify the query to return, based on the position of the query. `LAST_QUERY_ID(-1)` returns the latest query, `(-2)` the second last query, and so on.

The fix for the problem in `InsertEmployeeSalaryAndLog_2()` will be to simply specify `LAST_QUERY_ID(-2)` in the second use of `ACTIVITY_COUNT` (second `SELECT`) so that it gets the results from the `INSERT` statement instead:

```
 ...
INSERT INTO employees (employee_id, first_name, last_name, department_id, salary)
        VALUES (101, 'Alice', 'Smith', 10, 70000.00);

           -- Get the ACTIVITY_COUNT
        row_count1 := (
            SELECT
                $1
            FROM
                TABLE(RESULT_SCAN(LAST_QUERY_ID()))
        ) /*** SSC-FDM-TD0033 - 'ACTIVITY_COUNT' TRANSFORMATION MIGHT REQUIRE MANUAL ADJUSTMENTS ***/ + 1;
        row_count1 := (
            SELECT
                $1
            FROM
                TABLE(RESULT_SCAN(LAST_QUERY_ID(-2)))
        ) /*** SSC-FDM-TD0033 - 'ACTIVITY_COUNT' TRANSFORMATION MIGHT REQUIRE MANUAL ADJUSTMENTS ***/;
...
```

Copy

#### Second case[¶](#second-case "Link to this heading")

If `ACTIVITY_COUNT` is called after a non DML statement was executed, the transformation will not return the expected values.

##### Teradata[¶](#id152 "Link to this heading")

```
REPLACE PROCEDURE InsertEmployeeSalaryAndLog_3 ()
BEGIN
    DECLARE row_count1 INT;
    DECLARE emp_id INT;
    DECLARE message VARCHAR(100);

    INSERT INTO employees (employee_id, first_name, last_name, department_id, salary)
    VALUES (101, 'Alice', 'Smith', 10, 70000.00);

    SELECT employee_id INTO emp_id FROM employees;
    -- Get the ACTIVITY_COUNT
    SET row_count1 = ACTIVITY_COUNT;
    SET message = 'EMPLOYEE INSERTED - ID: ' || emp_id;

    -- Insert the ACTIVITY_COUNT into the activity_log table
    INSERT INTO activity_log (operation, row_count)
    VALUES (message, row_count1);
END;
```

Copy

##### Snowflake[¶](#id153 "Link to this heading")

```
 CREATE OR REPLACE PROCEDURE InsertEmployeeSalaryAndLog_3 ()
RETURNS VARCHAR
LANGUAGE SQL
COMMENT = '{ "origin": "sf_sc", "name": "snowconvert", "version": {  "major": 0,  "minor": 0,  "patch": "0" }, "attributes": {  "component": "teradata",  "convertedOn": "07/15/2024" }}'
EXECUTE AS CALLER
AS
$$
    DECLARE
        row_count1 INT;
        emp_id INT;
        message VARCHAR(100);
    BEGIN
         
         
         
        INSERT INTO employees (employee_id, first_name, last_name, department_id, salary)
        VALUES (101, 'Alice', 'Smith', 10, 70000.00);
        SELECT
            employee_id INTO
            :emp_id
        FROM
            employees;
               -- Get the ACTIVITY_COUNT
               row_count1 := (
            SELECT
                $1
            FROM
                TABLE(RESULT_SCAN(LAST_QUERY_ID()))
               ) /*** SSC-FDM-TD0033 - 'ACTIVITY_COUNT' TRANSFORMATION MIGHT REQUIRE MANUAL ADJUSTMENTS ***/;
               message := 'EMPLOYEE INSERTED - ID: ' || emp_id;

               -- Insert the ACTIVITY_COUNT into the activity_log table
               INSERT INTO activity_log (operation, row_count)
               VALUES (:message, :row_count1);
    END;
$$;
```

Copy

Similar to the previous, `LAST_QUERY_ID` does not point to the correct query and thus returns an incorrect value, which is assigned to row\_count1. Check the Query History (bottom-up):

![](../../../../../.gitbook/assets/image (462).png)

Query History when calling InsertEmployeeSalaryAndLog\_3()

1. `INSERT` statement is executed. `LAST_QUERY_ID()` will point to this statement.
2. `SELECT INTO` is executed, and $1 will be 101. `LAST_QUERY_ID()` will point to this statement.
3. `SELECT` (`ACTIVITY_COUNT`) is executed. The result for the last query is `101`; thus `$1` will hold `101` instead of the expected 1.
4. Finally, `row_count1` holds the value `101`, which is inserted in `activity_log`.

These are the values inserted in activity\_log:

| LOG\_ID | OPERATION | ROW\_COUNT | LOG\_TIMESTAMP |
| --- | --- | --- | --- |
| 1 | EMPLOYEE INSERTED - ID: 101 | 101 | 2024-07-15 11:00:38.000 |

#### Adjustments for the second case[¶](#adjustments-for-the-second-case "Link to this heading")

1. One possible fix is to specify the correct query to return by `LAST_QUERY_ID`. For example, here `LAST_QUERY_ID(-2)` will be the correct query to point to.

```
 ...
row_count1 := (
            SELECT
                $1
            FROM
                TABLE(RESULT_SCAN(LAST_QUERY_ID(-2)))
               ) /*** SSC-FDM-TD0033 - 'ACTIVITY_COUNT' TRANSFORMATION MIGHT REQUIRE MANUAL ADJUSTMENTS ***/;
               ...
```

Copy

2. Another possible fix is to use `ACTIVITY_COUNT` (`SELECT`) immediately after executing the `INSERT` statement.

```
...
INSERT INTO employees (employee_id, first_name, last_name, department_id, salary)
VALUES (101, 'Alice', 'Smith', 10, 70000.00);
-- Get the ACTIVITY_COUNT
       row_count1 := (
    SELECT
        $1
    FROM
        TABLE(RESULT_SCAN(LAST_QUERY_ID()))
       ) /*** SSC-FDM-TD0033 - 'ACTIVITY_COUNT' TRANSFORMATION MIGHT REQUIRE MANUAL ADJUSTMENTS ***/;
SELECT
    employee_id INTO
    :emp_id
FROM
    employees;
       message := 'EMPLOYEE INSERTED - ID: ' || emp_id;
...
```

Copy

#### Best Practices[¶](#id154 "Link to this heading")

* Make sure to point to the correct query when using `LAST_QUERY_ID`.
* Make sure `ACTIVITY_COUNT` is used immediately after the DML statement to evaluate.
* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0034[¶](#ssc-fdm-td0034 "Link to this heading")

Period contains transformed to user defined function.

### Description[¶](#id155 "Link to this heading")

The Teradata `CONTAINS` expression performs a validation indicating whether the element at the right is contained in the element at the left which is supposed to be of `PERIOD` type. The CONTAINS only applies for `DATE`, `TIME`, `TIMESTAMP` or `PERIOD`. Since `PERIOD` is not supported in Snowflake, an user-defined function will emulate the logic of the native `CONTAINS` behavior.

#### Example Code[¶](#id156 "Link to this heading")

##### Input Code:[¶](#id157 "Link to this heading")

```
  UPDATE TABLE1
  SET COL1 = CURRENT_TIMESTAMP
  WHERE COL3 CONTAINS CURRENT_TIMESTAMP;
```

Copy

##### Generated Code[¶](#id158 "Link to this heading")

```
  UPDATE TABLE1
  SET
    COL1 = CURRENT_TIMESTAMP()
  WHERE
    PUBLIC.PERIOD_CONTAINS_UDF(COL3, CURRENT_TIMESTAMP()) /*** SSC-FDM-TD0034 - PERIOD CONTAINS EXPRESSION TRANSFORMED TO USER DEFINED FUNCTION. ***/
```

Copy

#### Best Practices[¶](#id159 "Link to this heading")

* The `VARCHAR` used instead of `PERIOD` assumes `<PERIOD_BEGIN>*<PERIOD_END>` format in all the values. If the values are split by a token different than `*`, you can change the value returned from the `PUBLIC.GET_PERIOD_SEPARATOR` UDF provided by SnowConvert AI. Notice that the structure should have a token that marks the begin and end of a PERIOD, so the two dates, times or timestamps should be always separated with the same token.
* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0035[¶](#ssc-fdm-td0035 "Link to this heading")

Statistics function not needed in Snowflake.

Note

This FDM is deprecated, please refer to [SSC-EWI-0037](generalFDM.html#ssc-fdm-0037) documentation

### Description[¶](#id160 "Link to this heading")

DROP, COLLECT, or HELP statistics are not needed in Snowflake. Snowflake already collects statistics used for automatic query optimization, which is why these statistics statements are used in Teradata.

#### Example Code[¶](#id161 "Link to this heading")

##### Input Code:[¶](#id162 "Link to this heading")

```
  HELP STATISTICS TestName;
```

Copy

##### Generated Code[¶](#id163 "Link to this heading")

```
  ----** SSC-FDM-TD0035 - HELP STATISTICS NOT NEEDED. SNOWFLAKE AUTOMATICALLY COLLECTS STATISTICS. **
  --HELP STATISTICS TestName
```

Copy

#### Best Practices[¶](#id164 "Link to this heading")

* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

## SSC-FDM-TD0036[¶](#ssc-fdm-td0036 "Link to this heading")

Snowflake does not support the period datatype, all periods are handled as varchar instead

Note

Some parts in the output code are omitted for clarity reasons.

### Precision of generated varchar representations[¶](#precision-of-generated-varchar-representations "Link to this heading")

PERIOD\_UDF generates the varchar representation of a period using the default formats for timestamps and time specified in Snowflake, this means timestamps will have three precision digits and time variables will have zero, because of this you may find that the results have a higher/lower precision from the expected, there are two options to modify how many precision digits are included in the resulting string:

* Use the three parameters version of PERIOD\_UDF: This overload of the function takes the`PRECISIONDIGITS`parameter, an integer between 0 and 9 to control how many digits of the fractional time part will be included in the result. Note that even if Snowflake supports up to nine digits of precision the maximum in Teradata is six. Example:

| Call | Result |
| --- | --- |
| `PUBLIC.PERIOD_UDF(time '13:30:45.870556', time '15:35:20.344891', 0)` | `'13:30:45*15:35:20'` |
| `PUBLIC.PERIOD_UDF(time '13:30:45.870556', time '15:35:20.344891', 2)` | `'13:30:45.87*15:35:20.34'` |
| `PUBLIC.PERIOD_UDF(time '13:30:45.870556', time '15:35:20.344891', 5)` | `'13:30:45.87055*15:35:20.34489'` |

* Alter the session parameters `TIMESTAMP_NTZ_OUTPUT_FORMAT` and `TIME_OUTPUT_FORMAT`: The commands `ALTER SESSION SET TIMESTAMP_NTZ_OUTPUT_FORMAT = <format>` and`ALTER SESSION SET TIME_OUTPUT_FORMAT = <format>`

  can be used to modify the formats Snowflake uses by default for the current session, modifying them to include the desired number of precision digits changes the result of future executions of PERIOD\_UDF for the current session.

#### Example code[¶](#id165 "Link to this heading")

##### Input code:[¶](#id166 "Link to this heading")

```
 create table vacations (
    employeeName varchar(50),
    duration period(date)
);

insert into vacations values ('Richard', period(date '2021-05-15', date '2021-06-15'));

select end(duration) from vacations;
```

Copy

##### Generated Code:[¶](#id167 "Link to this heading")

```
 CREATE OR REPLACE TABLE vacations (
    employeeName varchar(50),
    duration VARCHAR(24) /*** SSC-FDM-TD0036 - SNOWFLAKE DOES NOT SUPPORT THE PERIOD DATATYPE, ALL PERIODS ARE HANDLED AS VARCHAR INSTEAD ***/
)
COMMENT = '{"origin":"sf_sc","name":"snowconvert","version":{"major":1, "minor":0},"attributes":{"component":"teradata"}}'
;

INSERT INTO vacations
VALUES ('Richard', PUBLIC.PERIOD_UDF(date '2021-05-15', date '2021-06-15') /*** SSC-FDM-TD0036 - SNOWFLAKE DOES NOT SUPPORT THE PERIOD DATATYPE, ALL PERIODS ARE HANDLED AS VARCHAR INSTEAD ***/);

SELECT
    PUBLIC.PERIOD_END_UDF(duration) /*** SSC-FDM-TD0036 - SNOWFLAKE DOES NOT SUPPORT THE PERIOD DATATYPE, ALL PERIODS ARE HANDLED AS VARCHAR INSTEAD ***/ from
    vacations;
```

Copy

#### Best Practices[¶](#id168 "Link to this heading")

* Since the behavior of`PERIOD`and its related functions is emulated using varchar, we recommend reviewing the results obtained to ensure its correctness.
* If you need more support, you can email us at [snowconvert-support@snowflake.com](mailto:snowconvert-support%40snowflake.com)

Was this page helpful?

YesNo

[Visit Snowflake](https://www.snowflake.com)

[Join the conversation](https://community.snowflake.com/s/)

[Develop with Snowflake](https://developers.snowflake.com)

[Share your feedback](/feedback)

[Read the latest on our blog](https://www.snowflake.com/blog/)

[Get your own certification](https://learn.snowflake.com)

[Privacy Notice](https://www.snowflake.com/privacy-policy/)[Site Terms](https://www.snowflake.com/legal/snowflake-site-terms/)Cookies Settings© 2026 Snowflake, Inc. All Rights Reserved.

Terms of Use

The SnowConvert AI tool is subject to the [Conversion Software Terms of Use](https://www.snowflake.com/en/legal/technical-services-and-education/conversion-software-terms/).

On this page

1. [SSC-FDM-TD0001](#ssc-fdm-td0001)
2. [SSC-FDM-TD0002](#ssc-fdm-td0002)
3. [SSC-FDM-TD0003](#ssc-fdm-td0003)
4. [SSC-FDM-TD0004](#ssc-fdm-td0004)
5. [SSC-FDM-TD0005](#ssc-fdm-td0005)
6. [SSC-FDM-TD0006](#ssc-fdm-td0006)
7. [SSC-FDM-TD0007](#ssc-fdm-td0007)
8. [SSC-FDM-TD0008](#ssc-fdm-td0008)
9. [SSC-FDM-TD0009](#ssc-fdm-td0009)
10. [SSC-FDM-TD0010](#ssc-fdm-td0010)
11. [SSC-FDM-TD0011](#ssc-fdm-td0011)
12. [SSC-FDM-TD0012](#ssc-fdm-td0012)
13. [SSC-FDM-TD0013](#ssc-fdm-td0013)
14. [SSC-FDM-TD0014](#ssc-fdm-td0014)
15. [SSC-FDM-TD0015](#ssc-fdm-td0015)
16. [SSC-FDM-TD0016](#ssc-fdm-td0016)
17. [SSC-FDM-TD0017](#ssc-fdm-td0017)
18. [SSC-FDM-TD0018](#ssc-fdm-td0018)
19. [SSC-FDM-TD0019](#ssc-fdm-td0019)
20. [SSC-FDM-TD0020](#ssc-fdm-td0020)
21. [SSC-FDM-TD0021](#ssc-fdm-td0021)
22. [SSC-FDM-TD0022](#ssc-fdm-td0022)
23. [SSC-FDM-TD0023](#ssc-fdm-td0023)
24. [SSC-FDM-TD0024](#ssc-fdm-td0024)
25. [SSC-FDM-TD0025](#ssc-fdm-td0025)
26. [SSC-FDM-TD0026](#ssc-fdm-td0026)
27. [SSC-FDM-TD0027](#ssc-fdm-td0027)
28. [SSC-FDM-TD0028](#ssc-fdm-td0028)
29. [SSC-FDM-TD0029](#ssc-fdm-td0029)
30. [SSC-FDM-TD0030](#ssc-fdm-td0030)
31. [SSC-FDM-TD0031](#ssc-fdm-td0031)
32. [SSC-FDM-TD0032](#ssc-fdm-td0032)
33. [SSC-FDM-TD0033](#ssc-fdm-td0033)
34. [SSC-FDM-TD0034](#ssc-fdm-td0034)
35. [SSC-FDM-TD0035](#ssc-fdm-td0035)
36. [SSC-FDM-TD0036](#ssc-fdm-td0036)