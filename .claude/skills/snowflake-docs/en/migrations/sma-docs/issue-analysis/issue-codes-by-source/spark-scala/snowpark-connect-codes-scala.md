---
auto_generated: true
description: Message The element < element > is not supported for Snowpark Connect.
last_scraped: '2026-01-14T16:51:27.968753+00:00'
scraper_version: 1.1.0
source_url: https://docs.snowflake.com/en/migrations/sma-docs/issue-analysis/issue-codes-by-source/spark-scala/snowpark-connect-codes-scala
title: 'Snowpark Migration Accelerator: Snowpark Connect Issue Codes for Scala | Snowflake
  Documentation'
---

1. [Overview](../../../../../guides/README.md)
2. [Snowflake Horizon Catalog](../../../../../user-guide/snowflake-horizon.md)
4. [Applications and tools for connecting to Snowflake](../../../../../guides/overview-connecting.md)
6. [Virtual warehouses](../../../../../user-guide/warehouses.md)
7. [Databases, Tables, & Views](../../../../../guides/overview-db.md)
8. [Data types](../../../../../data-types.md)
10. Data Integration

    - [Snowflake Openflow](../../../../../user-guide/data-integration/openflow/about.md)
    - Apache Iceberg™

      - [Apache Iceberg™ Tables](../../../../../user-guide/tables-iceberg.md)
      - [Snowflake Open Catalog](../../../../../user-guide/opencatalog/overview.md)
11. Data engineering

    - [Data loading](../../../../../guides/overview-loading-data.md)
    - [Dynamic Tables](../../../../../user-guide/dynamic-tables-about.md)
    - [Streams and Tasks](../../../../../user-guide/data-pipelines-intro.md)
    - [dbt Projects on Snowflake](../../../../../user-guide/data-engineering/dbt-projects-on-snowflake.md)
    - [Data Unloading](../../../../../guides/overview-unloading-data.md)
12. [Storage Lifecycle Policies](../../../../../user-guide/storage-management/storage-lifecycle-policies.md)
13. [Migrations](../../../../README.md)

    * Tools

      * [SnowConvert AI](../../../../snowconvert-docs/overview.md)
      * [Snowpark Migration Accelerator](../../../README.md)

        + General

          + [Introduction](../../../general/introduction.md)
          + [Getting started](../../../general/getting-started/README.md)
          + [Conversion software terms of use](../../../general/conversion-software-terms-of-use/README.md)
          + [Release notes](../../../general/release-notes/README.md)
          + [Roadmap](../../../general/roadmap.md)
        + User guide

          + [Overview](../../../user-guide/overview.md)
          + [Before using the SMA](../../../user-guide/before-using-the-sma/README.md)
          + [Project overview](../../../user-guide/project-overview/README.md)
          + [Technical discovery](../../../user-guide/project-overview/optional-technical-discovery.md)
          + [AI assistant](../../../user-guide/chatbot.md)
          + [Assessment](../../../user-guide/assessment/README.md)
          + [Conversion](../../../user-guide/conversion/README.md)
          + [Using the SMA CLI](../../../user-guide/using-the-sma-cli/README.md)
        + Use cases

          + Snowflake VS Code extension

            + [SMA checkpoints walkthrough](../../../use-cases/sma-checkpoints-walkthrough/README.md)
            + [SMA EWI Assistant walkthrough](../../../use-cases/sma-ewi-assistant-walkthrough/README.md)
          + [Assessment walkthrough](../../../use-cases/assessment-walkthrough/README.md)
          + [Conversion walkthrough](../../../use-cases/conversion-walkthrough.md)
          + [Migration lab](../../../use-cases/migration-lab/README.md)
          + [Sample project](../../../use-cases/sample-project.md)
          + [Using SMA in an Ubuntu Docker image](../../../use-cases/using-snowconvert-in-a-ubuntu-docker-image.md)
          + [SMA CLI walkthrough](../../../use-cases/sma-cli-walkthrough.md)
          + [Snowpark Connect](../../../use-cases/snowpark-connect/README.md)
        + Issue analysis

          + [Approach](../../approach.md)
          + [Issue code categorization](../../issue-code-categorization.md)
          + [Issue codes by source](../README.md)

            - [General](../general.md)
            - [Python](../python/README.md)
            - [Spark Scala](README.md)
            - [SQL](../sql/README.md)
            - [Pandas](../pandas/README.md)
            - [Snowpark Connect Python](../python/snowpark-connect-codes-python.md)
            - [Snowpark Connect Scala](snowpark-connect-codes-scala.md)
          + [Troubleshooting the output code](../../troubleshooting-the-output-code/README.md)
          + [Workarounds](../../workarounds.md)
          + [Deploying the output code](../../deploying-the-output-code.md)
        + Translation reference

          + [Translation reference overview](../../../translation-reference/translation-reference-overview.md)
          + [SIT tagging](../../../translation-reference/sit-tagging/README.md)
          + [SQL embedded code](../../../translation-reference/sql-embedded-code.md)
          + [HiveSQL](../../../translation-reference/hivesql/README.md)
          + [Spark SQL](../../../translation-reference/spark-sql/README.md)
        + Workspace estimator

          + [Overview](../../../workspace-estimator/overview.md)
          + [Getting started](../../../workspace-estimator/getting-started.md)
        + Interactive assessment application

          + [Overview](../../../interactive-assessment-application/overview.md)
          + [Installation guide](../../../interactive-assessment-application/installation-guide.md)
        + Support

          + [General troubleshooting](../../../support/general-troubleshooting/README.md)
          + [Frequently asked questions](../../../support/frequently-asked-questions-faq/README.md)
          + [Glossary](../../../support/glossary.md)
          + [Contact us](../../../support/contact-us.md)
    * Guides

      * [Teradata](../../../../guides/teradata.md)
      * [Databricks](../../../../guides/databricks.md)
      * [SQL Server](../../../../guides/sqlserver.md)
      * [Amazon Redshift](../../../../guides/redshift.md)
      * [Oracle](../../../../guides/oracle.md)
      * [Azure Synapse](../../../../guides/azuresynapse.md)
15. [Queries](../../../../../guides/overview-queries.md)
16. [Listings](../../../../../collaboration/collaboration-listings-about.md)
17. [Collaboration](../../../../../guides/overview-sharing.md)
19. [Snowflake AI & ML](../../../../../guides/overview-ai-features.md)
21. [Snowflake Postgres](../../../../../user-guide/snowflake-postgres/about.md)
23. [Alerts & Notifications](../../../../../guides/overview-alerts.md)
25. [Security](../../../../../guides/overview-secure.md)
26. [Data Governance](../../../../../guides/overview-govern.md)
27. [Privacy](../../../../../guides/overview-privacy.md)
29. [Organizations & Accounts](../../../../../guides/overview-manage.md)
30. [Business continuity & data recovery](../../../../../user-guide/replication-intro.md)
32. [Performance optimization](../../../../../guides/overview-performance.md)
33. [Cost & Billing](../../../../../guides/overview-cost.md)

[Guides](../../../../../guides/README.md)[Migrations](../../../../README.md)Tools[Snowpark Migration Accelerator](../../../README.md)Issue analysis[Issue codes by source](../README.md)Snowpark Connect Scala

# Snowpark Migration Accelerator: Snowpark Connect Issue Codes for Scala[¶](#snowpark-migration-accelerator-snowpark-connect-issue-codes-for-scala "Link to this heading")

## SPRKCNTSCL1000[¶](#sprkcntscl1000 "Link to this heading")

**Message** The element < ***element*** > is not supported for Snowpark Connect.

**Category** Conversion Error

### Description[¶](#description "Link to this heading")

This issue appears when the tool detects the usage of an element that is not supported in Snowpark Connect and does not have its own error code associated with it. This is the generic error code used by the SMA for an unsupported element.

### Scenario[¶](#scenario "Link to this heading")

#### Input[¶](#input "Link to this heading")

The tool found an unidentified element of the `org.apache.spark` library.

```
import org.apache.spark.NotSupportedElement
import org.apache.spark.rdd.RDD
import org.apache.spark.{SparkConf, SparkContext}

val conf = new SparkConf().setAppName("GraphXExample").setMaster("local")
val sc = new SparkContext(conf)
val vertices: RDD[(VertexId, String)] = sc.parallelize(Seq((1L, "A"), (2L, "B")))
val edges: RDD[Edge[String]] = sc.parallelize(Seq(Edge(1L, 2L, "edge")))
val graph = NotSupportedElement(vertices, edges)
```

Copy

#### Output[¶](#output "Link to this heading")

The tool adds the comment to the statement pointing to the unsupported element.

```
import org.apache.spark.NotSupportedElement
import org.apache.spark.rdd.RDD
import org.apache.spark.{SparkConf, SparkContext}

val conf = new SparkConf().setAppName("GraphXExample").setMaster("local")
val sc = new SparkContext(conf)
val vertices: RDD[(VertexId, String)] = sc.parallelize(Seq((1L, "A"), (2L, "B")))
val edges: RDD[Edge[String]] = sc.parallelize(Seq(Edge(1L, 2L, "edge")))
// EWI SPRKCNTSCL1000: The element 'NotSupportedElement' is not supported for Snowpark Connect
val graph = NotSupportedElement(vertices, edges)
```

Copy

### Recommended fix[¶](#recommended-fix "Link to this heading")

Since this is a generic error code that applies to a range of unsupported functions, there is no single and specific fix. The appropriate action depends on the particular element in use.

### Additional recommendations[¶](#additional-recommendations "Link to this heading")

* Even though the option or the element on the message is not supported, this does not mean that a solution cannot be found. It means only that the tool itself cannot find the solution.
* If you believe that Snowpark Connect already supports this element or that there is a workaround, please report that you encountered a conversion error on that particular element using [the Report an Issue option](../../../user-guide/project-overview/configuration-and-settings.html#report-an-issue) in the SMA and include any additional information that you think may be helpful.
* For more support, email support at [sma-support@snowflake.com](mailto:sma-support%40snowflake.com) or post an issue [in the SMA](../../../user-guide/project-overview/configuration-and-settings.html#report-an-issue).

## SPRKCNTSCL1500[¶](#sprkcntscl1500 "Link to this heading")

**Message** The element < ***element*** > of the library RDD is not supported for Snowpark Connect.

**Category** Conversion Error

### Description[¶](#id1 "Link to this heading")

This issue appears when the tool determines that the usage instance of an RDD element is not supported in Snowpark Connect and does not have its own error code associated with it. This is the generic error code used by the SMA for RDD unsupported elements.

### Scenario[¶](#id2 "Link to this heading")

#### Input[¶](#id3 "Link to this heading")

The tool found an unidentified element of the `org.apache.spark.rdd` library.

```
import org.apache.spark.rdd.RDD

val rdd: RDD[Int] = ???
rdd.NotSupportedElement()
```

Copy

#### Output[¶](#id4 "Link to this heading")

The SMA adds the EWI `SPRKCNTSCL1500` to the output code to let you know that this RDD element is not supported by Snowpark Connect.

```
import snowflake.snowpark.snowpark_connect
import org.apache.spark.rdd.RDD

val rdd: RDD[Int] = ???
/*EWI: SPRKCNTSCL1500 => The element 'org.apache.spark.rdd.RDD.NotSupportedElement' of the library RDD is not supported for Snowpark Connect*/
rdd.NotSupportedElement()
```

Copy

### Recommended fix[¶](#id5 "Link to this heading")

* Convert RDD operations to DataFrame operations.
* The key recommendation is to completely abandon RDD patterns and redesign your data processing logic using Snowpark’s DataFrame API and SQL capabilities, leveraging Snowflake’s distributed computing architecture rather than trying to replicate RDD functionality.
* Since this is a generic error code that applies to a range of unsupported functions, there is no single and specific fix. The appropriate action depends on the particular element in use.
* Please note that even though the element is not supported, it does not necessarily mean that a solution or workaround cannot be found. It means only that the SMA itself cannot find the solution.

### Additional recommendations[¶](#id6 "Link to this heading")

* Even though the option or the element on the message is not supported, this does not mean that a solution cannot be found. It means only that the tool itself cannot find the solution.
* If you believe that Snowpark Connect already supports this element or that there is a workaround, please report that you encountered a conversion error on that particular element using [the Report an Issue option](../../../user-guide/project-overview/configuration-and-settings.html#report-an-issue) in the SMA and include any additional information that you think may be helpful.
* For more support, email support at [sma-support@snowflake.com](mailto:sma-support%40snowflake.com) or post an issue [in the SMA](../../../user-guide/project-overview/configuration-and-settings.html#report-an-issue).

## SPRKCNTSCL2000[¶](#sprkcntscl2000 "Link to this heading")

**Message** The element < ***element*** > of the library Streaming is not supported for Snowpark Connect.

**Category** Conversion Error

### Description[¶](#id7 "Link to this heading")

This issue appears when the tool determines that the usage instance of a Streaming element is not supported in Snowpark Connect, and does not have its own error code associated with it. This is the generic error code used by the SMA for Streaming unsupported elements.

### Scenario[¶](#id8 "Link to this heading")

#### Input[¶](#id9 "Link to this heading")

The tool found an unidentified element of the `org.apache.spark.streaming` library.

```
import org.apache.spark.SparkConf
import org.apache.spark.streaming.{Seconds, NotSupportedElement}

val conf = new SparkConf().setAppName("NetworkWordCount").setMaster("local[2]")
val ssc = new NotSupportedElement(conf, Seconds(1))
```

Copy

#### Output[¶](#id10 "Link to this heading")

The SMA adds the EWI `SPRKCNTSCL2000` to the output code to let you know that this Streaming element is not supported by Snowpark Connect.

```
import org.apache.spark.SparkConf
import org.apache.spark.streaming.{Seconds, NotSupportedElement}

val conf = new SparkConf().setAppName("NetworkWordCount").setMaster("local[2]")
// EWI SPRKCNTSCL2000: The element 'NotSupportedElement' of the library Streaming is not supported for Snowpark Connect
val ssc = new NotSupportedElement(conf, Seconds(1))
```

Copy

### Recommended fix[¶](#id11 "Link to this heading")

* The key recommendation is to completely redesign streaming architecture to use external streaming platforms for real-time processing combined with Snowpark Connect for analytical batch processing, rather than trying to replicate Spark Streaming functionality.
* Since this is a generic error code that applies to a range of unsupported functions, there is no single and specific fix. The appropriate action depends on the particular element in use.
* Please note that even though the element is not supported, it does not necessarily mean that a solution or workaround cannot be found. It means only that the SMA itself cannot find the solution.

### Additional recommendations[¶](#id12 "Link to this heading")

* Even though the option or the element on the message is not supported, this does not mean that a solution cannot be found. It means only that the tool itself cannot find the solution.
* If you believe that Snowpark Connect already supports this element or that there is a workaround, please report that you encountered a conversion error on that particular element using [the Report an Issue option](../../../user-guide/project-overview/configuration-and-settings.html#report-an-issue) in the SMA and include any additional information that you think may be helpful.
* For more support, email support at [sma-support@snowflake.com](mailto:sma-support%40snowflake.com) or post an issue [in the SMA](../../../user-guide/project-overview/configuration-and-settings.html#report-an-issue).

## SPRKCNTSCL2500[¶](#sprkcntscl2500 "Link to this heading")

**Message** The element < ***element*** > of the library ML is not supported for Snowpark Connect.

**Category** Conversion Error

### Description[¶](#id13 "Link to this heading")

This issue appears when the tool determines that the usage instance of an ML element is not supported in Snowpark Connect, and does not have its own error code associated with it. This is the generic error code used by the SMA for ML unsupported elements.

### Scenario[¶](#id14 "Link to this heading")

#### Input[¶](#id15 "Link to this heading")

The tool found an unidentified element of the `org.apache.spark.ml` library.

```
import org.apache.spark.ml.feature.NotSupportedElement
import org.apache.spark.sql.SparkSession

val spark = SparkSession.builder.appName("Example").getOrCreate()
val data = spark.read.format("libsvm").load("data.txt")
val scaler = new NotSupportedElement().setInputCol("features").setOutputCol("scaledFeatures")
```

Copy

#### Output[¶](#id16 "Link to this heading")

The SMA adds the EWI `SPRKCNTSCL2500` to the output code to let you know that this ML element is not supported by Snowpark Connect.

```
import org.apache.spark.ml.feature.NotSupportedElement
import org.apache.spark.sql.SparkSession

val spark = SparkSession.builder.appName("Example").getOrCreate()
val data = spark.read.format("libsvm").load("data.txt")
// EWI SPRKCNTSCL2500: The element 'NotSupportedElement' of the library ML is not supported for Snowpark Connect
val scaler = new NotSupportedElement().setInputCol("features").setOutputCol("scaledFeatures")
```

Copy

### Recommended fix[¶](#id17 "Link to this heading")

* Use the Snowpark ML library.

  ```
  // Spark ML Pipeline (NOT supported)
  import org.apache.spark.ml.Pipeline
  import org.apache.spark.ml.classification.LogisticRegression
  import org.apache.spark.ml.feature.{HashingTF, Tokenizer}

  // Snowpark ML equivalent
  import com.snowflake.snowpark.ml.modeling.linear_model.LogisticRegression
  import com.snowflake.snowpark.ml.preprocessing.StandardScaler

  val lr = new LogisticRegression()
      .setInputCols(Array("feature1", "feature2"))
      .setLabelCols(Array("label"))
  val model = lr.fit(trainingData)
  ```

  Copy
* Since this is a generic error code that applies to a range of unsupported functions, there is no single and specific fix. The appropriate action depends on the particular element in use.
* Please note that even though the element is not supported, it does not necessarily mean that a solution or workaround cannot be found. It means only that the SMA itself cannot find the solution.

### Additional recommendations[¶](#id18 "Link to this heading")

* Even though the option or the element on the message is not supported, this does not mean that a solution cannot be found. It means only that the tool itself cannot find the solution.
* If you believe that Snowpark Connect already supports this element or that there is a workaround, please report that you encountered a conversion error on that particular element using [the Report an Issue option](../../../user-guide/project-overview/configuration-and-settings.html#report-an-issue) in the SMA and include any additional information that you think may be helpful.
* For more support, email support at [sma-support@snowflake.com](mailto:sma-support%40snowflake.com) or post an issue [in the SMA](../../../user-guide/project-overview/configuration-and-settings.html#report-an-issue).

## SPRKCNTSCL3000[¶](#sprkcntscl3000 "Link to this heading")

**Message** The element < ***element*** > of the library MLLIB is not supported for Snowpark Connect.

**Category** Conversion Error

### Description[¶](#id19 "Link to this heading")

This issue appears when the tool determines the the usage instance of an MLLIB element is not supported in Snowpark Connect, and does not have its own error code associated with it. This is the generic error code used by the SMA for ML unsupported elements.

### Scenario[¶](#id20 "Link to this heading")

#### Input[¶](#id21 "Link to this heading")

The tool found an unidentified element of the `org.apache.spark.mllib` library.

```
import org.apache.spark.mllib.recommendation.NotSupportedElement
import org.apache.spark.mllib.recommendation.Rating
import org.apache.spark.{SparkConf, SparkContext}

val conf = new SparkConf().setAppName("ALSExample").setMaster("local")
val sc = new SparkContext(conf)
val data = sc.textFile("data.txt")
val ratings = data.map(_.split(',') match { case Array(user, item, rate) =>
  Rating(user.toInt, item.toInt, rate.toDouble)
})
val model = NotSupportedElement.train(ratings, 10, 10, 0.01)
```

Copy

#### Output[¶](#id22 "Link to this heading")

The SMA adds the EWI `SPRKCNTSCL3000` to the output code to let you know that this MLLIB element is not supported by Snowpark Connect.

```
import org.apache.spark.mllib.recommendation.NotSupportedElement
import org.apache.spark.mllib.recommendation.Rating
import org.apache.spark.{SparkConf, SparkContext}

val conf = new SparkConf().setAppName("ALSExample").setMaster("local")
val sc = new SparkContext(conf)
val data = sc.textFile("data.txt")
val ratings = data.map(_.split(',') match { case Array(user, item, rate) =>
  Rating(user.toInt, item.toInt, rate.toDouble)
})
// EWI SPRKCNTSCL3000: The element 'NotSupportedElement' of the library MLLIB is not supported for Snowpark Connect
val model = NotSupportedElement.train(ratings, 10, 10, 0.01)
```

Copy

### Recommended fix[¶](#id23 "Link to this heading")

* The key recommendation is to completely abandon MLlib patterns and redesign machine learning workflows using Snowpark ML, SQL-based ML functions, or hybrid approaches that leverage Snowflake distributed architecture rather than trying to replicate RDD-based MLlib functionality.

  ```
  // MLlib approach (NOT supported)
  import org.apache.spark.mllib.classification.LogisticRegressionWithSGD
  import org.apache.spark.mllib.regression.LabeledPoint

  val training = rdd.map { line =>
      val parts = line.split(',')
      LabeledPoint(parts(0).toDouble, Vectors.dense(parts(1).split(' ').map(_.toDouble)))
  }
  val model = LogisticRegressionWithSGD.train(training, numIterations)

  // Snowpark ML equivalent
  import com.snowflake.snowpark.ml.modeling.linear_model.LogisticRegression

  val model = new LogisticRegression()
      .setInputCols(Array("feature1", "feature2", "feature3"))
      .setLabelCols(Array("target"))
  val trainedModel = model.fit(trainingDataFrame)
  ```

  Copy
* Since this is a generic error code that applies to a range of unsupported functions, there is no single and specific fix. The appropriate action depends on the particular element in use.
* Please note that even though the element is not supported, it does not necessarily mean that a solution or workaround cannot be found. It means only that the SMA itself cannot find the solution.

### Additional recommendations[¶](#id24 "Link to this heading")

* Even though the option or the element on the message is not supported, this does not mean that a solution cannot be found. It means only that the tool itself cannot find the solution.
* If you believe that Snowpark Connect already supports this element or that there is a workaround, please report that you encountered a conversion error on that particular element using [the Report an Issue option](../../../user-guide/project-overview/configuration-and-settings.html#report-an-issue) in the SMA and include any additional information that you think may be helpful.
* For more support, email support at [sma-support@snowflake.com](mailto:sma-support%40snowflake.com) or post an issue [in the SMA](../../../user-guide/project-overview/configuration-and-settings.html#report-an-issue).

## SPRKCNTSCL3500[¶](#sprkcntscl3500 "Link to this heading")

**Message** The element < ***element*** > of the library Spark Session is not supported for Snowpark Connect.

**Category** Conversion Error

### Description[¶](#id25 "Link to this heading")

This issue appears when the tool determines that the usage instance of a Spark Session element is not supported in Snowpark Connect, and does not have its own error code associated with it. This is the generic error code used by the SMA for ML unsupported elements.

### Scenario[¶](#id26 "Link to this heading")

#### Input[¶](#id27 "Link to this heading")

The tool found an unidentified element of the `org.apache.spark.sql.SparkSession` library.

```
import org.apache.spark.sql.SparkSession.NotSupportedElement

val spark = SparkSession.builder.appName("Example").getOrCreate()
SparkSession.NotSupportedElement()
```

Copy

#### Output[¶](#id28 "Link to this heading")

The SMA adds the EWI `SPRKCNTSCL3500` to the output code to let you know that this Spark Session element is not supported by Snowpark Connect.

```
import org.apache.spark.sql.SparkSession

val spark = SparkSession.builder.appName("Example").getOrCreate()
// EWI SPRKCNTSCL3500: The element 'NotSupportedElement' of the library Spark Session is not supported for Snowpark Connect
SparkSession.NotSupportedElement()
```

Copy

### Recommended fix[¶](#id29 "Link to this heading")

* The key is to replace `SparkSession` patterns with equivalent Snowpark `Session` operations while leveraging Snowflake’s unique capabilities like warehouses, stages, and native SQL functions.

  ```
  // Spark SparkSession
  import org.apache.spark.sql.SparkSession

  val spark = SparkSession.builder()
      .appName("MySparkApp")
      .master("local[*]")
      .getOrCreate()

  // Snowpark Session
  import com.snowflake.snowpark.Session

  val session = Session.builder
      .configs(Map(
          "URL" -> "https://account.snowflakecomputing.com",
          "USER" -> "username",
          "PASSWORD" -> "password",
          "ROLE" -> "role_name",
          "WAREHOUSE" -> "warehouse_name",
          "DB" -> "database_name",
          "SCHEMA" -> "schema_name"
      ))
      .create
  ```

  Copy
* Since this is a generic error code that applies to a range of unsupported functions, there is no single and specific fix. The appropriate action depends on the particular element in use.
* Please note that even though the element is not supported, it does not necessarily mean that a solution or workaround cannot be found. It means only that the SMA itself cannot find the solution.

### Additional recommendations[¶](#id30 "Link to this heading")

* Even though the option or the element on the message is not supported, this does not mean that a solution cannot be found. It means only that the tool itself cannot find the solution.
* If you believe that Snowpark Connect already supports this element or that there is a workaround, please report that you encountered a conversion error on that particular element using [the Report an Issue option](../../../user-guide/project-overview/configuration-and-settings.html#report-an-issue) in the SMA and include any additional information that you think may be helpful.
* For more support, email support at [sma-support@snowflake.com](mailto:sma-support%40snowflake.com) or post an issue [in the SMA](../../../user-guide/project-overview/configuration-and-settings.html#report-an-issue).

Was this page helpful?

YesNo

[Visit Snowflake](https://www.snowflake.com)

[Join the conversation](https://community.snowflake.com/s/)

[Develop with Snowflake](https://developers.snowflake.com)

[Share your feedback](/feedback)

[Read the latest on our blog](https://www.snowflake.com/blog/)

[Get your own certification](https://learn.snowflake.com)

[Privacy Notice](https://www.snowflake.com/privacy-policy/)[Site Terms](https://www.snowflake.com/legal/snowflake-site-terms/)Cookies Settings© 2026 Snowflake, Inc. All Rights Reserved.

On this page

1. [SPRKCNTSCL1000](#sprkcntscl1000)
2. [SPRKCNTSCL1500](#sprkcntscl1500)
3. [SPRKCNTSCL2000](#sprkcntscl2000)
4. [SPRKCNTSCL2500](#sprkcntscl2500)
5. [SPRKCNTSCL3000](#sprkcntscl3000)
6. [SPRKCNTSCL3500](#sprkcntscl3500)