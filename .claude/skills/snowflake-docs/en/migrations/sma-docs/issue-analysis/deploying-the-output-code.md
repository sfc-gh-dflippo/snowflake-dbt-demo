---
auto_generated: true
description: To run the output code generated by the Snowpark Migration Accelerator
  (SMA), follow these environment-specific recommendations based on your source platform.
last_scraped: '2026-01-14T16:51:21.877320+00:00'
scraper_version: 1.1.0
source_url: https://docs.snowflake.com/en/migrations/sma-docs/issue-analysis/deploying-the-output-code
title: 'Snowpark Migration Accelerator:  Deploying the Output Code | Snowflake Documentation'
---

1. [Overview](../../../guides/README.md)
2. [Snowflake Horizon Catalog](../../../user-guide/snowflake-horizon.md)
4. [Applications and tools for connecting to Snowflake](../../../guides/overview-connecting.md)
6. [Virtual warehouses](../../../user-guide/warehouses.md)
7. [Databases, Tables, & Views](../../../guides/overview-db.md)
8. [Data types](../../../data-types.md)
10. Data Integration

    - [Snowflake Openflow](../../../user-guide/data-integration/openflow/about.md)
    - Apache Iceberg™

      - [Apache Iceberg™ Tables](../../../user-guide/tables-iceberg.md)
      - [Snowflake Open Catalog](../../../user-guide/opencatalog/overview.md)
11. Data engineering

    - [Data loading](../../../guides/overview-loading-data.md)
    - [Dynamic Tables](../../../user-guide/dynamic-tables-about.md)
    - [Streams and Tasks](../../../user-guide/data-pipelines-intro.md)
    - [dbt Projects on Snowflake](../../../user-guide/data-engineering/dbt-projects-on-snowflake.md)
    - [Data Unloading](../../../guides/overview-unloading-data.md)
12. [Storage Lifecycle Policies](../../../user-guide/storage-management/storage-lifecycle-policies.md)
13. [Migrations](../../README.md)

    * Tools

      * [SnowConvert AI](../../snowconvert-docs/overview.md)
      * [Snowpark Migration Accelerator](../README.md)

        + General

          + [Introduction](../general/introduction.md)
          + [Getting started](../general/getting-started/README.md)
          + [Conversion software terms of use](../general/conversion-software-terms-of-use/README.md)
          + [Release notes](../general/release-notes/README.md)
          + [Roadmap](../general/roadmap.md)
        + User guide

          + [Overview](../user-guide/overview.md)
          + [Before using the SMA](../user-guide/before-using-the-sma/README.md)
          + [Project overview](../user-guide/project-overview/README.md)
          + [Technical discovery](../user-guide/project-overview/optional-technical-discovery.md)
          + [AI assistant](../user-guide/chatbot.md)
          + [Assessment](../user-guide/assessment/README.md)
          + [Conversion](../user-guide/conversion/README.md)
          + [Using the SMA CLI](../user-guide/using-the-sma-cli/README.md)
        + Use cases

          + Snowflake VS Code extension

            + [SMA checkpoints walkthrough](../use-cases/sma-checkpoints-walkthrough/README.md)
            + [SMA EWI Assistant walkthrough](../use-cases/sma-ewi-assistant-walkthrough/README.md)
          + [Assessment walkthrough](../use-cases/assessment-walkthrough/README.md)
          + [Conversion walkthrough](../use-cases/conversion-walkthrough.md)
          + [Migration lab](../use-cases/migration-lab/README.md)
          + [Sample project](../use-cases/sample-project.md)
          + [Using SMA in an Ubuntu Docker image](../use-cases/using-snowconvert-in-a-ubuntu-docker-image.md)
          + [SMA CLI walkthrough](../use-cases/sma-cli-walkthrough.md)
          + [Snowpark Connect](../use-cases/snowpark-connect/README.md)
        + Issue analysis

          + [Approach](approach.md)
          + [Issue code categorization](issue-code-categorization.md)
          + [Issue codes by source](issue-codes-by-source/README.md)
          + [Troubleshooting the output code](troubleshooting-the-output-code/README.md)
          + [Workarounds](workarounds.md)
          + [Deploying the output code](deploying-the-output-code.md)
        + Translation reference

          + [Translation reference overview](../translation-reference/translation-reference-overview.md)
          + [SIT tagging](../translation-reference/sit-tagging/README.md)
          + [SQL embedded code](../translation-reference/sql-embedded-code.md)
          + [HiveSQL](../translation-reference/hivesql/README.md)
          + [Spark SQL](../translation-reference/spark-sql/README.md)
        + Workspace estimator

          + [Overview](../workspace-estimator/overview.md)
          + [Getting started](../workspace-estimator/getting-started.md)
        + Interactive assessment application

          + [Overview](../interactive-assessment-application/overview.md)
          + [Installation guide](../interactive-assessment-application/installation-guide.md)
        + Support

          + [General troubleshooting](../support/general-troubleshooting/README.md)
          + [Frequently asked questions](../support/frequently-asked-questions-faq/README.md)
          + [Glossary](../support/glossary.md)
          + [Contact us](../support/contact-us.md)
    * Guides

      * [Teradata](../../guides/teradata.md)
      * [Databricks](../../guides/databricks.md)
      * [SQL Server](../../guides/sqlserver.md)
      * [Amazon Redshift](../../guides/redshift.md)
      * [Oracle](../../guides/oracle.md)
      * [Azure Synapse](../../guides/azuresynapse.md)
15. [Queries](../../../guides/overview-queries.md)
16. [Listings](../../../collaboration/collaboration-listings-about.md)
17. [Collaboration](../../../guides/overview-sharing.md)
19. [Snowflake AI & ML](../../../guides/overview-ai-features.md)
21. [Snowflake Postgres](../../../user-guide/snowflake-postgres/about.md)
23. [Alerts & Notifications](../../../guides/overview-alerts.md)
25. [Security](../../../guides/overview-secure.md)
26. [Data Governance](../../../guides/overview-govern.md)
27. [Privacy](../../../guides/overview-privacy.md)
29. [Organizations & Accounts](../../../guides/overview-manage.md)
30. [Business continuity & data recovery](../../../user-guide/replication-intro.md)
32. [Performance optimization](../../../guides/overview-performance.md)
33. [Cost & Billing](../../../guides/overview-cost.md)

[Guides](../../../guides/README.md)[Migrations](../../README.md)Tools[Snowpark Migration Accelerator](../README.md)Issue analysisDeploying the output code

# Snowpark Migration Accelerator: Deploying the Output Code[¶](#snowpark-migration-accelerator-deploying-the-output-code "Link to this heading")

To run the output code generated by the Snowpark Migration Accelerator (SMA), follow these environment-specific recommendations based on your source platform.

## Spark Scala[¶](#spark-scala "Link to this heading")

Before executing your migrated Apache Spark code in Snowpark, please review these important considerations:

### Add snowpark and snowpark extensions library reference[¶](#add-snowpark-and-snowpark-extensions-library-reference "Link to this heading")

The migrated project must include references to both the Snowpark library and its extensions.

### Snowpark Extensions[¶](#snowpark-extensions "Link to this heading")

Snowpark Extensions is a library that adds Apache Spark features to the standard Snowpark library. These features are not currently available in Snowpark. This library helps developers migrate their projects from Apache Spark to Snowpark more easily.

Follow these steps to reference Snowpark and Snowpark Extensions libraries in your migrated code:

1. Add the Snowpark library reference to your project
2. Add the Snowpark Extensions library reference to your project
3. Update your code to use these libraries

### Step 1 - Add snowpark and snowpark extensions library references to the project configuration file[¶](#step-1-add-snowpark-and-snowpark-extensions-library-references-to-the-project-configuration-file "Link to this heading")

The tool automatically adds these dependencies to your project configuration file. After the dependencies are added, your build tool will handle resolving them.

Based on the file extension of your project configuration file, the tool automatically adds the appropriate references in the following way:

#### build.gradle[¶](#build-gradle "Link to this heading")

```
dependencies {
    implementation 'com.snowflake:snowpark:1.6.2'
    implementation 'net.mobilize.snowpark-extensions:snowparkextensions:0.0.9'
    ...
}
```

Copy

#### build.sbt[¶](#build-sbt "Link to this heading")

```
...
libraryDependencies += "com.snowflake" % "snowpark" % "1.6.2"
libraryDependencies += "net.mobilize.snowpark-extensions" % "snowparkextensions" % "0.0.9"
...
```

Copy

#### pom.xml[¶](#pom-xml "Link to this heading")

```
<dependencies>
    <dependency>
        <groupId>com.snowflake</groupId>
        <artifactId>snowpark</artifactId>
        <version>1.6.2</version>
    </dependency>
    <dependency>
        <groupId>net.mobilize.snowpark-extensions</groupId>
        <artifactId>snowparkextensions</artifactId>
        <version>0.0.9</version>
    </dependency>
    ...
</dependencies>
```

Copy

### Step 2 - Add snowpark extensions library import statements[¶](#step-2-add-snowpark-extensions-library-import-statements "Link to this heading")

The tool automatically adds these two import statements to every generated .scala file.

```
import com.snowflake.snowpark_extensions.Extensions._
import com.snowflake.snowpark_extensions.Extensions.functions._
```

Copy

### Code example[¶](#code-example "Link to this heading")

The code below uses **hex** and **isin** functions, which are native to Spark but not to Snowpark. However, the code will still execute successfully because these functions are provided through Snowpark extensions.

#### Input code[¶](#input-code "Link to this heading")

```
package com.mobilize.spark

import org.apache.spark.sql._

object Main {

   def main(args: Array[String]) : Unit = {

      var languageArray = Array("Java");

      var languageHex = hex(col("language"));

      col("language").isin(languageArray:_*);
   }

}
```

Copy

#### Output code[¶](#output-code "Link to this heading")

```
package com.mobilize.spark

import com.snowflake.snowpark._
import com.snowflake.snowpark_extensions.Extensions._
import com.snowflake.snowpark_extensions.Extensions.functions._

object Main {

   def main(args: Array[String]) : Unit = {

      var languageArray = Array("Java");
      
      // hex does not exist on Snowpark. It is a extension.
      var languageHex = hex(col("language"));
      
      // isin does not exist on Snowpark. It is a extension.
      col("language").isin(languageArray :_*)

   }

}
```

Copy

## PySpark[¶](#pyspark "Link to this heading")

Before running your migrated PySpark code in Snowpark, please review these important considerations:

### Install snowpark and snowpark extensions libraries[¶](#install-snowpark-and-snowpark-extensions-libraries "Link to this heading")

The migrated project must include references to both the Snowpark library and its extensions.

### Snowpark Extensions[¶](#id1 "Link to this heading")

Snowpark Extensions is a library that adds PySpark-like features to the standard Snowpark library. These features are currently not available in Snowpark. This library helps developers migrate their projects from PySpark to Snowpark more easily.

Follow these steps to reference Snowpark and Snowpark Extensions libraries in your migrated code:

1. Add Snowpark library references to your migrated code
2. Include Snowpark Extensions library references where needed

#### Step 1 - Install snowpark library[¶](#step-1-install-snowpark-library "Link to this heading")

```
pip install snowpark-extensions
```

Copy

#### Step 2 - Install snowpark extensions library[¶](#step-2-install-snowpark-extensions-library "Link to this heading")

```
pip install snowflake-snowpark-python
```

Copy

#### Step 3 - Add snowpark extensions library import statements[¶](#step-3-add-snowpark-extensions-library-import-statements "Link to this heading")

The tool automatically adds the PySpark import statement to every file that requires PySpark functionality.

```
import snowpark_extensions
```

Copy

### Code example[¶](#id2 "Link to this heading")

The `create_map` function is not available in PySpark but is supported in Snowpark through its extensions. This means your code will work correctly in Snowpark without any modifications.

#### Input code[¶](#id3 "Link to this heading")

```
import pyspark.sql.functions as df
df.select(create_map('name', 'age').alias("map")).collect()
```

Copy

#### Output code[¶](#id4 "Link to this heading")

```
import snowpark_extensions
import snowflake.snowpark.functions as df
df.select(create_map('name', 'age').alias("map")).collect()
```

Copy

Was this page helpful?

YesNo

[Visit Snowflake](https://www.snowflake.com)

[Join the conversation](https://community.snowflake.com/s/)

[Develop with Snowflake](https://developers.snowflake.com)

[Share your feedback](/feedback)

[Read the latest on our blog](https://www.snowflake.com/blog/)

[Get your own certification](https://learn.snowflake.com)

[Privacy Notice](https://www.snowflake.com/privacy-policy/)[Site Terms](https://www.snowflake.com/legal/snowflake-site-terms/)Cookies Settings© 2026 Snowflake, Inc. All Rights Reserved.

Terms of Use

The Snowpark Migration Accelerator tool (SMA) is subject to the [Conversion Software Terms of Use](https://www.snowflake.com/en/legal/technical-services-and-education/conversion-software-terms/).

On this page

1. [Spark Scala](#spark-scala)
2. [PySpark](#pyspark)