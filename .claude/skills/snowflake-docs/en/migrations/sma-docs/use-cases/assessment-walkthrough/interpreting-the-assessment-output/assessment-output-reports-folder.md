---
auto_generated: true
description: A complete set of output files and reports will be generated when you
  use the Snowpark Migration Accelerator (SMA). To see the full list of generated
  files and reports, please refer to the Output Repo
last_scraped: '2026-01-14T16:51:59.804460+00:00'
scraper_version: 1.1.0
source_url: https://docs.snowflake.com/en/migrations/sma-docs/use-cases/assessment-walkthrough/interpreting-the-assessment-output/assessment-output-reports-folder
title: 'Snowpark Migration Accelerator: Assessment Output - Reports Folder | Snowflake
  Documentation'
---

1. [Overview](../../../../../guides/README.md)
2. [Snowflake Horizon Catalog](../../../../../user-guide/snowflake-horizon.md)
4. [Applications and tools for connecting to Snowflake](../../../../../guides/overview-connecting.md)
6. [Virtual warehouses](../../../../../user-guide/warehouses.md)
7. [Databases, Tables, & Views](../../../../../guides/overview-db.md)
8. [Data types](../../../../../data-types.md)
10. Data Integration

    - [Snowflake Openflow](../../../../../user-guide/data-integration/openflow/about.md)
    - Apache Iceberg™

      - [Apache Iceberg™ Tables](../../../../../user-guide/tables-iceberg.md)
      - [Snowflake Open Catalog](../../../../../user-guide/opencatalog/overview.md)
11. Data engineering

    - [Data loading](../../../../../guides/overview-loading-data.md)
    - [Dynamic Tables](../../../../../user-guide/dynamic-tables-about.md)
    - [Streams and Tasks](../../../../../user-guide/data-pipelines-intro.md)
    - [dbt Projects on Snowflake](../../../../../user-guide/data-engineering/dbt-projects-on-snowflake.md)
    - [Data Unloading](../../../../../guides/overview-unloading-data.md)
12. [Storage Lifecycle Policies](../../../../../user-guide/storage-management/storage-lifecycle-policies.md)
13. [Migrations](../../../../README.md)

    * Tools

      * [SnowConvert AI](../../../../snowconvert-docs/overview.md)
      * [Snowpark Migration Accelerator](../../../README.md)

        + General

          + [Introduction](../../../general/introduction.md)
          + [Getting started](../../../general/getting-started/README.md)
          + [Conversion software terms of use](../../../general/conversion-software-terms-of-use/README.md)
          + [Release notes](../../../general/release-notes/README.md)
          + [Roadmap](../../../general/roadmap.md)
        + User guide

          + [Overview](../../../user-guide/overview.md)
          + [Before using the SMA](../../../user-guide/before-using-the-sma/README.md)
          + [Project overview](../../../user-guide/project-overview/README.md)
          + [Technical discovery](../../../user-guide/project-overview/optional-technical-discovery.md)
          + [AI assistant](../../../user-guide/chatbot.md)
          + [Assessment](../../../user-guide/assessment/README.md)
          + [Conversion](../../../user-guide/conversion/README.md)
          + [Using the SMA CLI](../../../user-guide/using-the-sma-cli/README.md)
        + Use cases

          + Snowflake VS Code extension

            + [SMA checkpoints walkthrough](../../sma-checkpoints-walkthrough/README.md)
            + [SMA EWI Assistant walkthrough](../../sma-ewi-assistant-walkthrough/README.md)
          + [Assessment walkthrough](../README.md)

            - [Walkthrough setup](../walkthrough-setup/README.md)
            - [Running the tool](../running-the-tool.md)
            - [Interpreting the assessment output](README.md)

              * [Assessment output in application](assessment-output-in-application.md)
              * [Assessment output reports folder](assessment-output-reports-folder.md)
            - [Running the SMA again](../running-the-sma-again.md)
          + [Conversion walkthrough](../../conversion-walkthrough.md)
          + [Migration lab](../../migration-lab/README.md)
          + [Sample project](../../sample-project.md)
          + [Using SMA in an Ubuntu Docker image](../../using-snowconvert-in-a-ubuntu-docker-image.md)
          + [SMA CLI walkthrough](../../sma-cli-walkthrough.md)
          + [Snowpark Connect](../../snowpark-connect/README.md)
        + Issue analysis

          + [Approach](../../../issue-analysis/approach.md)
          + [Issue code categorization](../../../issue-analysis/issue-code-categorization.md)
          + [Issue codes by source](../../../issue-analysis/issue-codes-by-source/README.md)
          + [Troubleshooting the output code](../../../issue-analysis/troubleshooting-the-output-code/README.md)
          + [Workarounds](../../../issue-analysis/workarounds.md)
          + [Deploying the output code](../../../issue-analysis/deploying-the-output-code.md)
        + Translation reference

          + [Translation reference overview](../../../translation-reference/translation-reference-overview.md)
          + [SIT tagging](../../../translation-reference/sit-tagging/README.md)
          + [SQL embedded code](../../../translation-reference/sql-embedded-code.md)
          + [HiveSQL](../../../translation-reference/hivesql/README.md)
          + [Spark SQL](../../../translation-reference/spark-sql/README.md)
        + Workspace estimator

          + [Overview](../../../workspace-estimator/overview.md)
          + [Getting started](../../../workspace-estimator/getting-started.md)
        + Interactive assessment application

          + [Overview](../../../interactive-assessment-application/overview.md)
          + [Installation guide](../../../interactive-assessment-application/installation-guide.md)
        + Support

          + [General troubleshooting](../../../support/general-troubleshooting/README.md)
          + [Frequently asked questions](../../../support/frequently-asked-questions-faq/README.md)
          + [Glossary](../../../support/glossary.md)
          + [Contact us](../../../support/contact-us.md)
    * Guides

      * [Teradata](../../../../guides/teradata.md)
      * [Databricks](../../../../guides/databricks.md)
      * [SQL Server](../../../../guides/sqlserver.md)
      * [Amazon Redshift](../../../../guides/redshift.md)
      * [Oracle](../../../../guides/oracle.md)
      * [Azure Synapse](../../../../guides/azuresynapse.md)
15. [Queries](../../../../../guides/overview-queries.md)
16. [Listings](../../../../../collaboration/collaboration-listings-about.md)
17. [Collaboration](../../../../../guides/overview-sharing.md)
19. [Snowflake AI & ML](../../../../../guides/overview-ai-features.md)
21. [Snowflake Postgres](../../../../../user-guide/snowflake-postgres/about.md)
23. [Alerts & Notifications](../../../../../guides/overview-alerts.md)
25. [Security](../../../../../guides/overview-secure.md)
26. [Data Governance](../../../../../guides/overview-govern.md)
27. [Privacy](../../../../../guides/overview-privacy.md)
29. [Organizations & Accounts](../../../../../guides/overview-manage.md)
30. [Business continuity & data recovery](../../../../../user-guide/replication-intro.md)
32. [Performance optimization](../../../../../guides/overview-performance.md)
33. [Cost & Billing](../../../../../guides/overview-cost.md)

[Guides](../../../../../guides/README.md)[Migrations](../../../../README.md)Tools[Snowpark Migration Accelerator](../../../README.md)Use cases[Assessment walkthrough](../README.md)[Interpreting the assessment output](README.md)Assessment output reports folder

# Snowpark Migration Accelerator: Assessment Output - Reports Folder[¶](#snowpark-migration-accelerator-assessment-output-reports-folder "Link to this heading")

A complete set of output files and reports will be generated when you use the Snowpark Migration Accelerator (SMA). To see the full list of generated files and reports, please refer to the [Output Reports section of this documentation](../../../user-guide/assessment/output-reports/README).

The assessment generates .csv files that can be opened with any spreadsheet software. The [detailed report](#the-detailed-report) provides a summary of these files and serves as a starting point for evaluating the results. While we’ll examine some key .csv files to understand the migration requirements, we won’t cover all of them. For a complete list of inventory files generated by the Snowpark Migration Accelerator (SMA), please refer to [the SMA Inventories section of this documentation](../../../user-guide/assessment/output-reports/sma-inventories).

To view the reports, click the “VIEW REPORTS” button at the bottom of the screen. This will open your file explorer to the directory containing the reports.

![View Reports and the Reports Folder](../../../../../_images/ViewReportsandtheReportsFolder.png)

Let’s examine what information we can gather from the Detailed Report.

Note

The version of the detailed report and other inventories shown on this page may differ from what you see when running SMA. The report shown here reflects the tool version available when this walkthrough was created. If you notice significant differences or issues in your results, please contact the SMA team at [sma-support@snowflake.com](mailto:sma-support%40snowflake.com) or [report an issue in the tool](../../../user-guide/project-overview/configuration-and-settings.html#report-an-issue). You can also use the SMA tool to report documentation issues.

## The Detailed Report[¶](#the-detailed-report "Link to this heading")

The Detailed Report (.docx) provides a comprehensive summary of the information found in the inventory files. This report is essential for evaluating how well-suited your codebase is for Snowpark migration. While a complete description of the report’s contents is available in the [detailed documentation](../../../user-guide/assessment/output-reports/curated-reports.html#detailed-report), this guide focuses on three key aspects:

1. Important elements to review
2. Their impact on readiness scores
3. How to interpret the results

Review all readiness scores available in your report to understand your migration readiness status.

![Readiness Score Summary in the Detailed Report](../../../../../_images/image%28543%29.png)

### The Spark API Readiness Score[¶](#the-spark-api-readiness-score "Link to this heading")

Let’s clarify what the Spark API Readiness score means and how it’s calculated. This score is the main readiness indicator produced by the Snowpark Migration Accelerator (SMA). It’s important to note that this score only considers Spark API usage and doesn’t account for third-party libraries or other factors in your code. While this limitation means the score might not tell the complete story, it still serves as a useful starting point for your migration assessment. For more information about third-party library compatibility, please refer to the [Third Party API Readiness section](#third-party-libraries-readiness-score).

![Spark API Readiness Score in the Detailed Report](../../../../../_images/image%28545%29.png)

The Conversion Score represents the ratio of Spark API references that can be automatically converted to Snowpark API, compared to the total number of Spark API references found in your code. In this case, 3541 out of 3746 references can be converted. A higher score indicates that more of your code can be automatically migrated to Snowpark. While unconverted code can still be manually adapted to work with Snowpark, this score provides a reliable indication of how well-suited your workload is for automatic migration.

### Third Party Libraries Readiness Score[¶](#third-party-libraries-readiness-score "Link to this heading")

The Third Party Libraries Readiness Score helps you understand which external APIs are used in your code. This score provides a clear overview of all external dependencies in your codebase.

### Summary Page[¶](#summary-page "Link to this heading")

The Summary page displays your readiness score and provides an overview of your execution results.

**What to Look For**
Check the readiness score to evaluate how prepared your codebase is for converting Spark API references to Snowpark API references. A high readiness score indicates that the Spark code is well-suited for migration to Snowpark.

![Readiness score](../../../../../_images/readinessScore.png)

### File Summary[¶](#file-summary "Link to this heading")

The file summary provides an overview of your codebase, including:

* Total lines of code per file extension
* Notebook cell information (if notebooks were analyzed)
* Number of files containing embedded SQL queries

**What Should You Watch For?**

The number and content of files. When you find many files but only a few contain Spark API references, this could mean:

* The application uses Spark minimally (perhaps only for data extraction and loading)
* The source code includes external library dependencies
* The use case needs further investigation to understand how Spark is being utilized

In either scenario, it’s important to thoroughly analyze the use case before proceeding.

![File size](../../../../../_images/fileSize.png)

![File content](../../../../../_images/fileContent.png)

### Spark Usage Summary[¶](#spark-usage-summary "Link to this heading")

The Spark Usage Summary provides a detailed breakdown of Spark API references found in your code and identifies which ones can be converted to the Snowpark API. The summary categorizes these references into different types, including DataFrame operations, column manipulations, SparkSession calls, and other API functions.

Each reference is classified into one of seven support statuses. These statuses indicate whether and how a reference can be supported in Snowpark. The detailed definitions of these statuses can be found in the report’s appendixes.

* **Direct:** The function exists in both PySpark and Snowpark and can be used without changes.
* **Rename**: The function exists in both frameworks, but requires a name change in Snowpark.
* **Helper**: The function requires a small modification in Snowpark that can be solved by creating an equivalent helper function.
* **Transformation**: The function needs to be completely rebuilt in Snowpark using different methods or multiple steps to achieve the same result.
* **Workaround**: The function cannot be automatically converted, but there is a documented manual solution available.
* **NotSupported**: The function cannot be converted because Snowflake does not have an equivalent feature. The tool will add an error message to the code.
* **NotDefined**: The PySpark element is not yet included in the conversion tool’s database and will be added in a future update.

What Should You Watch For?

The readiness score is displayed in this section. You can review how many code references will need workarounds versus direct translations. If your code requires many workarounds, helpers, and transformations, we recommend using Snowpark Migration Accelerator (SMA) to help migrate your codebase efficiently.

![Readiness Score label](../../../../../_images/readinessScoreLabel.png)

![Spark usages by support category](../../../../../_images/usagesBySupportedCategory.png)

### Import Calls:[¶](#import-calls "Link to this heading")

SMA tracks each package or library import as an individual import call. Common and recognized import calls are displayed in the import summary section of the detailed report page. All import calls are recorded in both the local output inventories folder and the assessment database. Please note that these import calls have not yet been classified as supported or unsupported in Snowflake.

**What Should You Watch For?**

Third-party libraries not supported by Snowflake can significantly impact your migration readiness. If your code imports libraries like mllib, streaming, or third-party libraries such as graphs, subprocess, or smtplib, you may face migration challenges. While the presence of these libraries doesn’t automatically make migration impossible, it requires a deeper analysis of your use case. In such situations, we recommend consulting with the WLS team for a detailed assessment.

![Third-party Libraries](../../../../../_images/pythonImportsCall.png)

### Snowpark Migration Accelerator Issue Summary[¶](#snowpark-migration-accelerator-issue-summary "Link to this heading")

This section provides an overview of potential issues and errors that may occur during workload migration. While detailed information about unconvertible elements is available elsewhere, this section is particularly valuable during the initial stages of the conversion process.

**Common Issues to Watch For**

To find elements that were not converted or have known workarounds, check the Spark reference inventory in your local inventories folder. You can compare these elements with existing mappings by querying the database.

![Issue summary](../../../../../_images/issueSummary.png)

---

## Summary:[¶](#summary "Link to this heading")

The readiness score indicates how prepared your codebase is for Snowpark migration. A score of 80% or higher means your code is mostly ready for migration. If your score is below 60%, you will need to make additional modifications to your code before proceeding.

For this workload, the score exceeds 90%, which indicates excellent compatibility for migration.

The next indicator is **size**. A workload with extensive code but few Spark API references might suggest heavy reliance on third-party libraries. Even if a project has a low readiness score, it can be quickly converted manually if it contains only about 100 lines of code or 5 Spark API references, regardless of automation tools.

For this workload, the size is reasonable and easy to handle. The codebase contains more than 100 files with fewer than 5,000 Spark API references and under 10,000 lines of code. Approximately 98% of these files contain Spark API references, indicating that most of the Python code is Spark-related.

The third indicator to examine is **imported libraries**. The inventory of import statements helps identify which external packages the code uses. If the code relies heavily on third-party libraries, it may require additional analysis. In cases with numerous external dependencies, consult the Workload Services (WLS) team to better understand how these libraries are being used.

In this example, we have some referenced third-party libraries, but none of them are related to Machine Learning, Streaming, or other complex libraries that would be challenging to implement in Snowpark.

Since this workload is suitable for migration to Snowpark, proceed to the next step in the Spark migration process.

Was this page helpful?

YesNo

[Visit Snowflake](https://www.snowflake.com)

[Join the conversation](https://community.snowflake.com/s/)

[Develop with Snowflake](https://developers.snowflake.com)

[Share your feedback](/feedback)

[Read the latest on our blog](https://www.snowflake.com/blog/)

[Get your own certification](https://learn.snowflake.com)

[Privacy Notice](https://www.snowflake.com/privacy-policy/)[Site Terms](https://www.snowflake.com/legal/snowflake-site-terms/)Cookies Settings© 2026 Snowflake, Inc. All Rights Reserved.

Terms of Use

The Snowpark Migration Accelerator tool (SMA) is subject to the [Conversion Software Terms of Use](https://www.snowflake.com/en/legal/technical-services-and-education/conversion-software-terms/).

On this page

1. [The Detailed Report](#the-detailed-report)
2. [Summary:](#summary)